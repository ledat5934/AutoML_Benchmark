from __future__ import annotations

from typing import Dict, List, Optional
import json  # Added to parse dataset JSON

from src.data_analyzer import ProjectInfo
from src.utils.logger import get_logger


logger = get_logger(__name__)


class PromptBuilder:
    """Constructs ChatCompletion messages without relying on external Jinja templates.

    The prompt now relies primarily on the *dataset JSON* file that is produced in the
    `DataAnalyzer.generate_dataset_json` step.  This removes the maintenance burden of
    template files while still keeping the prompt informative and structured.
    """

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def build_stage_prompt(
        self,
        stage: int,
        project: ProjectInfo,
        analysis_report: str,
        prev_code: str = "",
        accelerator: Optional[str] = None,
        dataset_json: str = "",
    ) -> List[Dict[str, str]]:
        """Return a list of messages (system + user) for the requested *stage*.

        Parameters
        ----------
        stage : int
            The stage number (1, 2 or 3) that we are generating code for.
        project : ProjectInfo
            Describes the project folder and metadata.
        analysis_report : str
            A short EDA text report created earlier – this gives the LLM
            additional context about the dataset.
        prev_code : str, optional
            Concatenation of all previously-generated stages (empty for stage 1).
        accelerator : str, optional
            Which Kaggle accelerator the user requested (TPU, T4x2, P100).
        dataset_json : str, optional
            Content of the JSON file generated by `DataAnalyzer.generate_dataset_json`.
        """

        # ------------------------------------------------------------------
        # Extract base_path from dataset_json for cross-platform path handling
        # ------------------------------------------------------------------
        # Ensure we always have a _base_path attribute to prevent AttributeError
        self._base_path = getattr(self, "_base_path", ".")  # default fallback

        if dataset_json:
            try:
                # The dataset_json string may contain extra whitespace/newlines – load safely
                dataset_meta = json.loads(dataset_json)
                self._base_path = dataset_meta.get("dataset_info", {}).get("base_path", ".") or "."
            except json.JSONDecodeError:
                # If JSON parsing fails, keep the previous (or default) base path
                logger.warning("Failed to parse dataset_json – falling back to '.' for base_path")

        
        # ------------------------------------------------------------------
        # Build the USER prompt piece-by-piece
        # ------------------------------------------------------------------
        prompt_sections: list[str] = []

        if dataset_json:
            prompt_sections.append(f"### Dataset Metadata JSON\n**NOTE: This JSON file is GENERATED by the AutoML pipeline and does NOT exist in the original dataset. It contains structured metadata about the dataset for code generation purposes only.**\n\n{dataset_json}")

        if analysis_report:
            prompt_sections.append(f"### EDA Report\n{analysis_report}")

        if prev_code:
            prompt_sections.append(f"### Previously Generated Code (for context)\n{prev_code}")

        # Stage-specific instruction block
        stage_instr = self._stage_instructions(stage, project)
        prompt_sections.append("### Instructions\n" + stage_instr)

        if accelerator:
            prompt_sections.append(
                f"The user would like to run this on Kaggle with accelerator **{accelerator}**. "
                "Optimise the code to make full use of the requested hardware."
            )

        # Join everything together – keep blank lines between major sections
        prompt_text = "\n\n".join(prompt_sections)

        messages: List[Dict[str, str]] = [
            {"role": "system", "content": "You are a senior ML engineer."},
            {"role": "user", "content": prompt_text},
        ]

        return messages

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _stage_instructions(self, stage: int, project: ProjectInfo) -> str:
        """Return human-readable instructions for the given stage."""

        # NOTE: Removed unused imports and constants to keep the prompt builder lean

        # ------------------------------------------------------------------
        # Mẫu “file-paths constants” mới cho mọi script
        # ------------------------------------------------------------------
        base = self._base_path
        pathlib_instruction = (
            "IMPORTANT: Use **pathlib** for all paths and ensure the code runs identically on Kaggle notebooks, Linux CLI, and Windows.\n"
            "Determine the project root like this (handles the Jupyter/Kaggle `__file__` absence):\n"
            "```python\n"
            "try:\n"
            "    ROOT_DIR = Path(__file__).resolve().parent.parent\n"
            "except NameError:  # __file__ is not defined inside Kaggle/Jupyter\n"
            "    ROOT_DIR = Path.cwd()\n"
            "```\n"
            f"Then set `BASE_PATH = (ROOT_DIR / '{base}').resolve()`; if that path doesn't exist, fall back to `Path('{base}').resolve()`.\n"
            "Always print the resolved BASE_PATH so users can verify."
        )

        if stage == 1:
            return (
                f"{pathlib_instruction}\n\n"
                "IMPORTANT: The *dataset metadata JSON* provided above is for reference only. Use it to infer file paths and dataset structure, **but DO NOT copy or embed the JSON (or any large dictionaries) inside the generated Python code**. Your script should read data files directly from disk instead.\n\n"
                "Declare **file-path constants** at the top of the script so they can be overridden easily when running outside Kaggle. Defaults should mirror the standard Kaggle notebook directory layout _but allow automatic fallback_: "
                "Stage 1 focuses on **data loading, cleaning, prepprocessing**. "
                "Write Python compatible code that: (1) loads the dataset (tabular, CV or NLP) "
                "according to the metadata JSON, (2) performs appropriate preprocessing steps according to the task and the given JSON, for example: "
                """
                • Identify numerical vs. categorical vs. text vs. image columns automatically.
                • Impute missing numerical values with the median, categorical with the mode (or constant "missing").
                • One-hot-encode categorical columns (drop_first=False).
                • For free-text columns, create TF-IDF (or a tokenizer compatible with transformers if Stage 2 plans to use them).
                • For image paths, implement a lightweight loader - either a PyTorch `Dataset` **or** a TensorFlow `tf.data` pipeline that loads, resizes (e.g. 224×224), and normalizes images; optionally extract embeddings via a pre-trained backbone (e.g. EfficientNet-B0) so they can be merged later.
                • Scale numerical features with `StandardScaler` (store the scaler for later reuse).
                • Handle any other preprocessing steps as needed (feature selection, feature engineering, etc.).
                • These are just examples; you can choose any preprocessing steps that you think is appropriate.
                """
                "Keep the code modular and wrap everything "
                "inside a `main()` function.  "
                "Return ONLY the complete Python code for Stage 1, "
                "enclosed in triple backticks, with no additional explanatory text."
            )
        elif stage == 2:
            return (
                f"{pathlib_instruction}\n\n"
                "IMPORTANT: The *dataset metadata JSON* provided above is for reference only. Use it to infer file paths and dataset structure, **but DO NOT copy or embed the JSON (or any large dictionaries) inside the generated Python code**. Your script should read data files directly from disk instead.\n\n"
                """
                 Declare **file-path constants** at the top of the script so they can be overridden easily when running outside Kaggle. Defaults should mirror the standard Kaggle notebook directory layout _but allow automatic fallback_: 
                1. Perform an **80 / 20 stratified split** into training and validation sets using `train_test_split(random_state=42, stratify=y), using variables name from the preprocessing step if available`.
                2. Build a **model automatically suited to the task type**. Examples:
                    • **Tabular**: Gradient Boosting (`LightGBM`, `CatBoost`, `XGBoost`), `RandomForest`.
                    • **Image**: Fine-tune a pre-trained CNN (e.g. EfficientNet, ResNet, ConvNeXt) or use a Vision Transformer – you may implement in **PyTorch** *or* **TensorFlow/Keras**.
                    • **Text**: Fine-tune a transformer (e.g. BERT, RoBERTa) using HuggingFace (either PyTorch or TensorFlow backend).
                    • **Multimodal**: Combine extracted embeddings or use a fusion network.
                    • You may choose deep learning frameworks (PyTorch, TensorFlow/Keras) when beneficial.
                    • These are just examples; you can choose any model that you think is appropriate.
                3. Fit the model on the training split. Use early stopping on the validation split (100 rounds).
                4. Evaluate and **print** multiple metrics **and also persist them to a JSON file**:
                    • Classification → Accuracy, F1, LogLoss, ROC_AUC.
                    • Regression → RMSE, MAE, R², Accuracy, F1, LogLoss, ROC_AUC.
                    • Save a dictionary of metrics per target (and overall) to `METRICS_PATH = "./outputs/metrics.json"` (override-able). Use `json.dump(metrics_dict, open(..., "w"), indent=2)`.
                5. At the top of the script declare `MODEL_PATH = "./models/<dataset_name>_model.pkl"` (override-able); persist the trained model there using `joblib.dump`.
                6. Return the trained model instance as `trained_model`.
               """
               "\nReturn ONLY the complete Python code for Stage 2, enclosed in triple backticks. "
               "Do not include any additional text or explanations."
            )
        elif stage == 3:
            return (
                f"{pathlib_instruction}\n\n"
                "IMPORTANT: The *dataset metadata JSON* provided above is for reference only. Use it to infer file paths and dataset structure, **but DO NOT copy or embed the JSON (or any large dictionaries) inside the generated Python code**. Your script should read data files directly from disk instead.\n\n"
                '''
                Declare **file-path constants** at the top of the script so they can be overridden easily when running outside Kaggle. Defaults should mirror the standard Kaggle notebook directory layout _but allow automatic fallback_: 
                1. Ensure `trained_model` is available. If it is `None`, load the model from `models/model.pkl` using `joblib.load`.
                2. Declare `TEST_PROCESSED_PATH = "./processed/test_processed.csv"` at the top, then load `test_df_processed` from that path (or memory).
                3. Generate predictions:
                    • Classification → `predict_proba` probabilities or class labels depending on competition format.
                    • Regression → continuous predictions.
                    • These are just examples; you must generate appropriate predictions for the task.
                4. Build `submission_df` following the sample submission format (column names and index order).
                    • If a sample submission is provided (path detected by analyzer), respect its structure.
                    • Use **exactly** the column names from the sample submission, including any prefixes (e.g. `target_0` … `target_6`). Do NOT replace them with plain integers or alternative names – the Kaggle evaluation expects an exact match.
                5. Declare `SUBMISSION_PATH = "./outputs/submission.csv"` at the top and save the submission there.
                6. Print a short confirmation message with the path to the generated file.
                '''
                "\nReturn ONLY the complete Python code for Stage 3, enclosed in triple backticks. "
                "Do not include any additional text or explanations."
            )
        else:
            # Fallback – shouldn't happen
            return "Generate production-ready ML code for the specified stage." 