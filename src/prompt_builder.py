from __future__ import annotations

from typing import Dict, List, Optional

from src.data_analyzer import ProjectInfo
from src.utils.logger import get_logger


logger = get_logger(__name__)


class PromptBuilder:
    """Constructs ChatCompletion messages without relying on external Jinja templates.

    The prompt now relies primarily on the *dataset JSON* file that is produced in the
    `DataAnalyzer.generate_dataset_json` step.  This removes the maintenance burden of
    template files while still keeping the prompt informative and structured.
    """

    # ------------------------------------------------------------------
    # Public API
    # ------------------------------------------------------------------
    def build_stage_prompt(
        self,
        stage: int,
        project: ProjectInfo,
        analysis_report: str,
        prev_code: str = "",
        accelerator: Optional[str] = None,
        dataset_json: str = "",
    ) -> List[Dict[str, str]]:
        """Return a list of messages (system + user) for the requested *stage*.

        Parameters
        ----------
        stage : int
            The stage number (1, 2 or 3) that we are generating code for.
        project : ProjectInfo
            Describes the project folder and metadata.
        analysis_report : str
            A short EDA text report created earlier – this gives the LLM
            additional context about the dataset.
        prev_code : str, optional
            Concatenation of all previously-generated stages (empty for stage 1).
        accelerator : str, optional
            Which Kaggle accelerator the user requested (TPU, T4x2, P100).
        dataset_json : str, optional
            Content of the JSON file generated by `DataAnalyzer.generate_dataset_json`.
        """

        # ------------------------------------------------------------------
        # Build the USER prompt piece-by-piece
        # ------------------------------------------------------------------
        prompt_sections: list[str] = []

        if dataset_json:
            prompt_sections.append(f"### Dataset Metadata JSON\n{dataset_json}")

        if analysis_report:
            prompt_sections.append(f"### EDA Report\n{analysis_report}")

        if prev_code:
            prompt_sections.append(f"### Previously Generated Code (for context)\n{prev_code}")

        # Stage-specific instruction block
        stage_instr = self._stage_instructions(stage)
        prompt_sections.append("### Instructions\n" + stage_instr)

        if accelerator:
            prompt_sections.append(
                f"The user would like to run this on Kaggle with accelerator **{accelerator}**. "
                "Optimise the code to make full use of the requested hardware."
            )

        # Join everything together – keep blank lines between major sections
        prompt_text = "\n\n".join(prompt_sections)

        messages: List[Dict[str, str]] = [
            {"role": "system", "content": "You are a senior ML engineer."},
            {"role": "user", "content": prompt_text},
        ]

        return messages

    # ------------------------------------------------------------------
    # Helpers
    # ------------------------------------------------------------------
    def _stage_instructions(self, stage: int) -> str:
        """Return human-readable instructions for the given stage."""

        if stage == 1:
            return (
                "Declare **file-path constants** at the top of the script so they can be overridden easily when running outside Kaggle. Defaults should mirror the standard Kaggle notebook directory layout _but allow automatic fallback_: "
                "Stage 1 focuses on **data loading, cleaning, prepprocessing**. "
                "Write Python compatible code that: (1) loads the dataset (tabular, CV or NLP) "
                "according to the metadata JSON, (2) performs appropriate preprocessing steps according to the task and the given JSON, for example: "
                """
                • Identify numerical vs. categorical vs. text vs. image columns automatically.
                • Impute missing numerical values with the median, categorical with the mode (or constant "missing").
                • One-hot-encode categorical columns (drop_first=False).
                • For free-text columns, create TF-IDF (or a tokenizer compatible with transformers if Stage 2 plans to use them).
                • For image paths, implement a lightweight loader - either a PyTorch `Dataset` **or** a TensorFlow `tf.data` pipeline that loads, resizes (e.g. 224×224), and normalizes images; optionally extract embeddings via a pre-trained backbone (e.g. EfficientNet-B0) so they can be merged later.
                • Scale numerical features with `StandardScaler` (store the scaler for later reuse).
                • Handle any other preprocessing steps as needed (feature selection, feature engineering, etc.).
                """
                "Keep the code modular and wrap everything "
                "inside a `main()` function.  Enclose the entire Python script in triple backticks."
            )
        elif stage == 2:
            return (
                """
                 Declare **file-path constants** at the top of the script so they can be overridden easily when running outside Kaggle. Defaults should mirror the standard Kaggle notebook directory layout _but allow automatic fallback_: 
                1 Perform an **80 / 20 stratified split** into training and validation sets using `train_test_split(random_state=42, stratify=y), using variables name from the preprocessing step if available`.
                2. Build a **model automatically suited to the task type**. Examples:
                    • **Tabular**: Gradient Boosting (`LightGBM`, `CatBoost`, `XGBoost`), `RandomForest`.
                    • **Image**: Fine-tune a pre-trained CNN (e.g. EfficientNet, ResNet, ConvNeXt) or use a Vision Transformer – you may implement in **PyTorch** *or* **TensorFlow/Keras**.
                    • **Text**: Fine-tune a transformer (e.g. BERT, RoBERTa) using HuggingFace (either PyTorch or TensorFlow backend).
                    • **Multimodal**: Combine extracted embeddings or use a fusion network.
                    • You may choose deep learning frameworks (PyTorch, TensorFlow/Keras) when beneficial.
                    • These are just examples; you can choose any model that you think is appropriate.
                3. Fit the model on the training split. Use early stopping on the validation split (100 rounds).
                4. Evaluate and **print** multiple metrics:
                    • Classification → Accuracy, F1, LogLoss.
                    • Regression → RMSE, MAE, R², Accuracy, F1, LogLoss.
                5. At the top of the script declare `MODEL_PATH = "./models/<dataset_name>_model.pkl"` (override-able); persist the trained model there using `joblib.dump`.
                6. Return the trained model instance as `trained_model`.
               """
            )
        elif stage == 3:
            return (
                '''
                Declare **file-path constants** at the top of the script so they can be overridden easily when running outside Kaggle. Defaults should mirror the standard Kaggle notebook directory layout _but allow automatic fallback_: 
                1. Ensure `trained_model` is available. If it is `None`, load the model from `models/model.pkl` using `joblib.load`.
                2. Declare `TEST_PROCESSED_PATH = "./processed/test_processed.csv"` at the top, then load `test_df_processed` from that path (or memory).
                3. Generate predictions:
                    • Classification → `predict_proba` probabilities or class labels depending on competition format.
                    • Regression → continuous predictions.
                    • These are just examples; you must generate appropriate predictions for the task.
                4. Build `submission_df` following the sample submission format (column names and index order).
                    • If a sample submission is provided (path detected by analyzer), respect its structure.
                5. Declare `SUBMISSION_PATH = "./outputs/submission.csv"` at the top and save the submission there.
                6. Print a short confirmation message with the path to the generated file.
                '''
            )
        else:
            # Fallback – shouldn't happen
            return "Generate production-ready ML code for the specified stage." 