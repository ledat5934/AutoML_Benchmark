You are an expert programmer with years of experience in writing codes for machine learning (ML) tasks on Kaggle. Your goal is to write an end-to-end executable program that can solve the ML task based on the provided instructions. The user is trying to create a Python program for a supervised machine learning task. Your goal is to assist the user in creating the program. The user might provide the following information for the task:

A description of the input data:The input data is multimodal, consisting of two parts for each sample:
-Image Data: A JPEG image file.
-Text Data (Optional): A short text caption that summarizes the image.

A description of the output data: The output is a set of one or more labels for each image. There are 18 possible labels in total, represented by integers ranging from 1 to 19 (with the number 12 missing).

The task objective: For each given sample, predict all applicable labels. Since a single image can have multiple labels simultaneously, this is a multi-label classification task. The model should be trained on images and can optionally use the text captions as additional input.

The evaluation metrics: The evaluation metric for this competition is the Mean F1-Score.

A description of the available files:

train.csv: The training set file. It contains three columns: ImageID (the filename of the image), Labels (a space-separated string of label numbers for that image), and Caption (the text caption).

test.csv: The test set file. It contains ImageID and Caption for the test samples.

data/: A directory containing all the image files in .jpg format.

split the train to evaluate by these folowing metrics: accuracy log_loss f1_macro f1_weighted roc_auc_ovr roc_auc_ovr_weighted
run on Kaggle, GPU T4 x 2
use the newest library you have
example:
import torch
from collections import Counter
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
from torch.optim import lr_scheduler
import torchvision
from torchvision import models, transforms
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from PIL import Image
from tqdm import tqdm
import pandas as pd
import matplotlib.pyplot as plt
import os
from transformers import AutoImageProcessor, AutoModelForImageClassification
!pip install timm
import timm
import random
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
device
#Set Seed
random.seed(540446740)
torch.manual_seed(540446740)
torch.cuda.manual_seed(540446740)
root_dir = "/kaggle/input/multi-label-classification-competition-2024/COMP5329S1A2Dataset"
images_path = os.path.join(root_dir,'data')
labels_path = os.path.join(root_dir, 'train.csv')
df = pd.read_csv(labels_path, usecols = [0, 1])
df.head()
#one-hot encoding
label = np.zeros((df.shape[0], 19))
for i in range(len(df['Labels'])):
cur_label = [int(i) for i in df['Labels'][i].split(' ')]
for j in cur_label:
label[i, j-1] = 1
#calculate count of different categories
#Delete columns with entirely zero
non_zero_cols = np.any(label, axis=0)
label = label[:, non_zero_cols]
counts = np.sum(label, axis = 0)
print(counts)

Now plot all the counts together

plt.bar([i for i in range(18)], counts)
plt.title('Count of 1s in Each Column')
plt.xlabel('Columns')
plt.ylabel('Count of 1s')
plt.xticks(np.arange(0, 18, step=1))
plt.show()
class MultiLabelDataset(Dataset):
def init(self, images_path, df, labels, transform=None):
"""
Initializes the MultiLabelDataset.

Generated code
Args:
        images_path (str): Path to the directory containing the images.
        df (DataFrame): Pandas DataFrame containing image information.
        labels (numpy array): Array containing labels for each image.
        transform (callable, optional): optional transform to be applied on a sample.
    """
    self.images_path = images_path
    self.df = df
    self.labels = labels
    self.transform = transform

def __len__(self):
    return len(self.df)

def __getitem__(self, idx):
    """
    Gets a sample from the dataset by index.

    Args:
        idx (int): Index of the sample to retrieve.

    Returns:
        tuple: Tuple containing the image and its labels.
    """
    img_name = self.df.iloc[idx, 0]
    img_path = os.path.join(self.images_path, img_name)
    image = Image.open(img_path).convert('RGB')

    labels = self.labels[idx, :].astype('float')

    # Apply transformations
    if self.transform:
        image = self.transform(image)

    # Return the image and its labels
    return image, labels


transform = transforms.Compose([
transforms.Resize((224, 224)),  # Resize images to 256x256
transforms.RandomHorizontalFlip(),  # Randomly flip images horizontally
transforms.RandomRotation(10),  # Randomly rotate images by up to 10 degrees
transforms.ToTensor(),  # Convert images to PyTorch tensors
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #normalization using ImageNet mean and std
])
dataset = MultiLabelDataset(images_path, df, label, transform=transform)
import torchvision.transforms.functional as F

idx = random.randint(1, 30000)
image, label = dataset[idx]

Convert the tensor to a PIL image for display

image = F.to_pil_image(image)

Display the image

plt.imshow(image)
plt.title(f'Label: {label}')
plt.show()
from torch.utils.data import DataLoader, random_split

Calculate the partition rate

total_size = 30000
train_size = int(0.8 * total_size)
valid_size = int(0.15 * total_size)
test_size = total_size - train_size - valid_size

Split the dataset

train_dataset, valid_dataset, test_dataset = random_split(dataset, [train_size, valid_size, test_size])
#After hypaermater tuning, using the full dataset as training data.
train_all = False
if train_all:
train_dataset = dataset
#After hypaermater tuning, using the full dataset as training data.
train_all = False
if train_all:
train_dataset = dataset
model = timm.create_model('vit_small_patch16_224', pretrained=True)
#replace the output layer as a MLP layer with an output shape of (batchsize, 18)
last_layer = model.head
num_features= last_layer.out_features
fc = nn.Sequential(
last_layer,
nn.ReLU(),
nn.Dropout(0.5),
nn.Linear(num_features, 18),
)
model.head = fc
model.to(device)
name = "vit_small_patch16_224"
file_path = name + ".pth"

load local weights

if os.path.exists(file_path):
model.load_state_dict(torch.load(file_path))
print(f"Model weights loaded successfully from '{file_path}'.")
else:
print(f"File '{file_path}' not found. Skipping weight loading.")
from torch.nn import BCEWithLogitsLoss

Define the loss function and optimizer

loss_function = BCEWithLogitsLoss()
optimizer = optim.Adam(model.parameters(), lr=0.00008)
num_epochs = 3
train_losses = []
valid_losses = []
train_accuracies = []
valid_accuracies = []

for epoch in range(num_epochs):
# Training
model.train()
train_loss = 0.0
correct = 0
total = 0
# Explicitly create a tqdm object for the training loader
train_tqdm = tqdm(train_loader, desc=f"Epoch {epoch+1} Training")
for images, labels in train_tqdm:
images, labels = images.to(device), labels.to(device)
optimizer.zero_grad()
outputs = model(images)
loss = loss_function(outputs, labels)
loss.backward()
optimizer.step()

Generated code
train_loss += loss.item()
    predicted = torch.sigmoid(outputs).data > 0.5  # Applying sigmoid and thresholding to get predictions
    correct += (predicted == labels).sum().item()
    total += labels.numel()

train_losses.append(train_loss / len(train_loader))
train_accuracies.append(correct / total)

# Validation
model.eval()
valid_loss = 0.0
correct = 0
total = 0
# Explicitly create a tqdm object for the validation loader
valid_tqdm = tqdm(valid_loader, desc=f"Epoch {epoch+1} Validation")
with torch.no_grad():
    for images, labels in valid_tqdm:
        images, labels = images.to(device), labels.to(device)
        outputs = model(images)
        loss = loss_function(outputs, labels)
        valid_loss += loss.item()
        predicted = torch.sigmoid(outputs).data > 0.5
        correct += (predicted == labels).sum().item()
        total += labels.numel()

valid_losses.append(valid_loss / len(valid_loader))
valid_accuracies.append(correct / total)

print(f'Epoch {epoch+1}, Train Loss: {train_losses[-1]}, Train Accuracy: {train_accuracies[-1]}, Validation Loss: {valid_losses[-1]}, Validation Accuracy: {valid_accuracies[-1]}')
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

torch.cuda.empty_cache()
torch.save(model.state_dict(), '{}.pth'.format(name))
epochs = range(1, len(train_losses) + 1)

Plotting training and validation loss

plt.figure(figsize=(10, 5))
plt.subplot(1, 2, 1)
plt.plot(epochs, train_losses, label='Training Loss')
plt.plot(epochs, valid_losses, label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

Plotting training and validation accuracy

plt.subplot(1, 2, 2)
plt.plot(epochs, train_accuracies, label='Training Accuracy')
plt.plot(epochs, valid_accuracies, label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

plt.tight_layout()
plt.show()
model.eval()  # Set the model to evaluation mode
test_loss = 0.0
correct = 0
total = 0

with torch.no_grad():  # No gradients needed
for images, labels in test_loader:
images, labels = images.to(device), labels.to(device)
outputs = model(images)
loss = loss_function(outputs, labels)
test_loss += loss.item()
predicted = torch.sigmoid(outputs).data > 0.5  # Apply sigmoid and threshold
correct += (predicted == labels).sum().item()
total += labels.numel()

Calculate average loss and accuracy

test_loss /= len(test_loader)
test_accuracy = correct / total

print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')
transform_predict = transforms.Compose([
transforms.Resize((224, 224)),  # Resize images to 256x256
transforms.ToTensor(),  # Convert images to PyTorch tensors
transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])
predict_label_path = os.path.join(root_dir, 'test.csv')
df_predict = pd.read_csv(predict_label_path, usecols = [0, 1])
df_predict.head()
predict_dataset = MultiLabelDataset(images_path, df_predict, label, transform=transform)
predict_loader = DataLoader(predict_dataset, batch_size=batch_size, shuffle=False, num_workers=0, drop_last = False)
names = pd.read_csv(predict_label_path, usecols = [0, 1])['ImageID']
model.eval()
result = []
j = 0
with torch.no_grad():
for images, labels in predict_loader:
images = images.to(device)
outputs = model(images)
probabilities = torch.sigmoid(outputs)
predictions = probabilities.data > 0.5  # Apply sigmoid and threshold

Generated code
# Iterate over each row, if all probabilities are less than 0.5, set the maximum value in that row to 1 and others to 0
    for i in range(predictions.size(0)):
        if torch.all(probabilities[i] < 0.5):
            max_prob_index = torch.argmax(probabilities[i])
            predictions[i] = torch.zeros_like(predictions[i])
            predictions[i, max_prob_index] = 1.0

    labels = [torch.nonzero(predictions[i]).squeeze(1) for i in range(predictions.shape[0])]
    for _ in range(len(labels)):
        result.append([names[_+j], labels[_]])
    j += batch_size
IGNORE_WHEN_COPYING_START
content_copy
download
Use code with caution.
IGNORE_WHEN_COPYING_END

#show results
str_data = [str(row[1].tolist()) for row in result]
total_value_counts = Counter(str_data)
print(total_value_counts)
#tensor to df
final_output = pd.DataFrame(result, columns = ["ImageID","Labels"])
for _ in range(len(result)):
cur_name = result[][0]
vector = result[][1]
tmp = ""
for i in range(len(vector)):
num = vector[i].item()
if num >= 11:
num += 1
tmp = tmp + str(num+1) + " "
final_output.iloc[_, :] = [cur_name, tmp.strip()]
#save output
final_output.to_csv("{}.csv".format(name), index=False)