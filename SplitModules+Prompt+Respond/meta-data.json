[
  {
    "id": "2",
    "name": "Toxic comment classification",
    "input_data": "The primary input data is a single text field, `comment_text`, which contains the content of an online comment. A key characteristic of this task is the cross-lingual setting: the training data is entirely in English",
    "output_data": "The output is a single probability value between 0.0 and 1.0. This value represents the likelihood that the given `comment_text` is \"toxic\", where 1.0 indicates a toxic comment and 0.0 indicates a non-toxic comment.",
    "task": "The objective is to build a model that can classify whether an online comment is toxic. Predict the toxicity of the comment in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
      "jigsaw-toxic-comment-train.csv and jigsaw-unintended-bias-train.csv": "These are the primary training files, containing a large number of comments in English, each with a `comment_text` and a `toxic` label (0 or 1).",
      "test.csv": "The test dataset, evaluate the model on this dataset.This file does not contain the `toxic` label.",
      "sample_submission.csv": "An example file showing the required submission format, which includes an `id` column and a `toxic` probability column."
    },
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/toxic_cmt_classify/jigsaw-toxic-comment-train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/toxic_cmt_classify/jigsaw-unintended-bias-train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/toxic_cmt_classify/test.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/toxic_cmt_classify/sample_submission.csv"
    ]
  },
  {
    "id": "3",
    "name": "Domain classification",
    "input_data": "The input data for each sample consists of 1 text fields:`Title`: The title of the paper.",
    "output_data": "The output is a probability distribution across numbers of domains.",
    "task": "The objective is to build a model that can classify the domain of a paper based on its title.Predict the domain of the paper in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": "`train.csv`: Contains the training data. Each row represents a paper and includes its `Title` and `Domain`, `train.csv` is the training dataset, `test.csv` is the test dataset, `sample_submission.csv` is the sample submission file",
    "link to the dataset": [
      "\\Datasets\\datasets\\query_domain_classification\\train.csv",
      "\\Datasets\\datasets\\query_domain_classification/test.csv",
      "\\Datasets\\datasets\\query_domain_classification/sample_submission.csv"
    ]
  },
  {
    "id": "4",
    "name": "Predict LLM",
    "input_data": "The input data for each sample consists of two text fields: `Question` (the original prompt or question that was given to a language model) and `Response` (the text output that was generated by one of the language models in response to the `Question`).",
    "output_data": "The output is a probability distribution across 7 possible classes. Each class corresponds to one of the 7 different LLM models that could have generated the `Response`. The final submission requires predicting the probability for each of the 7 models (target_0 to target_6).",
    "task": " For each given pair of `Question` and `Response`, identify which of the 7 LLM models generated the `Response`. This is a multi-class classification task where the output is a set of probabilities for each class, predict the probability for each of the 7 models (target_0 to target_6) in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
		"train.csv": "Contains the training data with three columns: `Question`, `Response`, and `target` (an integer from 0 to 6 indicating the correct model).",
		"test.csv": "Contains the test data with three columns: `id`, `Question`, and `Response`. The goal is to predict the target probabilities for these samples.",
		"sample_submission.csv": "An example submission file showing the required format, which includes an `id` column and 7 probability columns (`target_0` through `target_6`)"
	},
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_the_llm/train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_the_llm/test.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_the_llm/sample_submission.csv"
    ]
  },
  {
    "id": "5",
    "name": "Multilabel classification",
    "input_data": "The input data is multimodal, consisting of two parts for each sample: Image Data (A JPEG image file) and Text Data (Optional: A short text caption that summarizes the image).",
    "output_data": "The output is a set of one or more labels for each image. There are 18 possible labels in total, represented by integers ranging from 1 to 19 (with the number 12 missing).",
    "task": "For each given sample, predict all applicable labels. Since a single image can have multiple labels simultaneously, this is a multi-label classification task. The model should be trained on images and can optionally use the text captions as additional input. Predict the labels for all the images in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description":{
		"train.csv": "The training set file. It contains three columns: `ImageID` (the filename of the image), `Labels` (a space-separated string of label numbers for that image), and `Caption` (the text caption)",
		"data/": "A directory containing all the image files in `.jpg` format.",
		"test.csv": "The test set file. It contains `ImageID` and `Caption` for the test samples.",
		"sample_submission.csv": "Example of an submission file, notice that the rows number is not the same as the test.csv"
	},
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/multi_label_classification/data",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/multi_label_classification/train.csv",
	  "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/multi_label_classification/test.csv"
    ]
  },
  {
    "id": "6",
    "name": "Plant Traits 2024",
    "input_data": "The input data is multimodal, consisting of two main types for each sample: 1) Image Data: A crowd-sourced photograph of a plant (`.jpeg`). 2) Tabular Ancillary Data: A set of geographical and environmental features associated with the image's location. This includes climate data (WORLDCLIM), soil data (SOIL), and multi-temporal satellite data (MODIS, VOD).",
    "output_data": "The output consists of 6 continuous numerical values. Each value is a prediction for one of the 6 vital plant traits , representing properties like leaf area or plant height.",
    "task": "For each sample, predict the values for all 6 plant traits based on the plant image and its associated ancillary data. This is a multi-output regression task that requires a multi-modal model to handle both image and tabular inputs. Predict the values for all 6 plant traits based on the plant image and its associated ancillary data in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
		"train.csv": "Contains the training data. For each `id`, it includes the target values for the 6 plant traits (columns named `X[*]_mean`) and all the ancillary tabular data (columns like `WORLDCLIM_BIO[*]`, `SOIL_[*]`, etc.)",
		"train_images/": "A directory containing the training images, with filenames corresponding to the `id` in `train.csv`",
		"target_name_meta.tsv": "A helper file providing the full names and descriptions for each trait ID.",
		"test.csv": "Contains the ancillary tabular data for the test set. It does not contain the target trait values.",
		"test_images/": "A directory containing the test images.",
		"sample_submission.csv": "An example file showing the required submission format, which includes an `id` column and a prediction column for each of the 6 traits."
	},
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/plant_traits_2024/train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/plant_traits_2024/train_images",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/plant_traits_2024/target_name_meta.tsv",
	    "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/plant_traits_2024/test.csv",
	    "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/plant_traits_2024/test_images",
	    "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/plant_traits_2024/sample_submission.csv"
    ]
  },
  {
    "id": "7",
    "name": "Predict Effective Arguement",
    "input_data": "The input data for each sample is a specific argumentative \"discourse element\" from a student's essay. To provide full context, the input consists of three parts:\n- `discourse_text`: The text of the specific discourse element itself.\n- `discourse_type`: The type of the element (e.g., 'Lead', 'Position', 'Claim', 'Evidence', etc.).\n- `essay_text`: The full text of the essay from which the discourse element was extracted.",
    "output_data": "The output is a probability distribution across 3 possible quality ratings for the discourse element. The three classes are: \"Ineffective\", \"Adequate\", and \"Effective\".",
    "task": "For each given argumentative discourse element, predict the quality rating of the discourse element. Predict the quality rating of the discourse element in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": "- `train.csv`: Contains the training data. Each row represents an annotated discourse element and includes its `discourse_id`, the `essay_id` it belongs to, the `discourse_text`, the `discourse_type`, and the target label `discourse_effectiveness`.\n- `test.csv`: Contains the test data with the same fields as `train.csv`, except for the target label.\n- `train/`: A directory containing the full text of each training essay, stored in `.txt` files. The filename of each `.txt` file corresponds to an `essay_id` in `train.csv`.\n- `test/`: A directory containing the full text of each test essay.\n- `sample_submission.csv`: An example file showing the required submission format, which includes `discourse_id` and a probability column for each of the 3 classes.",
    "link to the dataset":[
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_effective_arguments/train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_effective_arguments/test.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_effective_arguments/sample_submission.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_effective_arguments/train",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/predict_effective_arguments/test"
    ]
  },
  {
    "id": "8",
    "name": "Pet Finder",
    "input_data": "The input data is multimodal, containing tabular data, text descriptions, and images for each pet profile,The tabular data in 'train.csv' includes the following fields:,`PetID`: Unique hash ID for the pet profile,`Type`: Type of animal (1 for Dog, 2 for Cat),`Name`: Name of the pet (can be empty),`Age`: Age of the pet in months when listed,`Breed1`: ID for the primary breed of the pet,`Breed2`: ID for the secondary breed if the pet is a mixed breed,`Gender`: Gender of the pet (1 for Male, 2 for Female, 3 for Mixed group),`Color1`, `Color2`, `Color3`: IDs for the primary, secondary, and tertiary colors of the pet,`MaturitySize`: Size at maturity (1=Small, 2=Medium, 3=Large, 4=Extra Large, 0=Not Specified),`FurLength`: Fur length (1=Short, 2=Medium, 3=Long, 0=Not Specified),`Vaccinated`: Vaccination status (1=Yes, 2=No, 3=Not Sure),`Dewormed`: Deworming status (1=Yes, 2=No, 3=Not Sure),`Sterilized`: Spayed/neutered status (1=Yes, 2=No, 3=Not Sure),`Health`: Health condition (1=Healthy, 2=Minor Injury, 3=Serious Injury, 0=Not Specified),`Quantity`: Number of pets represented in this profile,`Fee`: Adoption fee in Malaysian Ringgit (0 for Free),`State`: ID for the state location in Malaysia,`RescuerID`: Unique hash ID of the rescuer,`VideoAmt`: The number of videos uploaded for the pet,`PhotoAmt`: The number of photos uploaded for the pet,The text data consists of:`Description`: A profile write-up for the pet, primarily in English, with some in Malay or Chinese,The image and metadata consist of:Photos for each pet.Supplementary JSON files containing metadata from Google Vision API (image analysis) and Google Natural Language API (sentiment analysis of the description).",
    "output_data": "The output is a single categorical value named 'AdoptionSpeed'. This value is an integer ranging from 0 to 4, representing how quickly a pet was adopted:\n- 0: Same day.\n- 1: 1-7 days.\n- 2: 8-30 days.\n- 3: 31-90 days.\n- 4: Not adopted after 100 days.",
    "task": "For each pet profile, predict the adoption speed category (0-4) based on the pet's characteristics, description, and images. Predict the adoption speed for pets in the test dataset and output the result in submission.csv which should have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
      "train.csv": "Contains the primary tabular and text data for training, including all features mentioned above and the 'AdoptionSpeed' label.",
      "test.csv": "Contains the tabular and text data for testing, without the 'AdoptionSpeed' label.",
      "breed_labels.csv": "Helper CSV file that maps the Breed IDs to their respective human-readable names.",
      "color_labels.csv": "Helper CSV file that maps the Color IDs to their respective human-readable names.",
      "state_labels.csv": "Helper CSV file that maps the State IDs to their respective human-readable names.",
      "train_images/": "Directory containing image files for each pet in the training set.",
      "test_images/": "Directory containing image files for each pet in the test set.",
      "sample_submission.csv": "An example file showing the required submission format, which includes an `PetID` column and a `AdoptionSpeed` column."
    },
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/test/test.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/test/sample_submission.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/train_images",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/test_images",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/breed_labels.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/color_labels.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/pet_finder/state_labels.csv"
    ]
  },
  {
    "id": "9",
    "name": "Dog breed identification",
    "input_data": "The input data is a single color image of a dog.",
    "output_data": "The output is a probability distribution across 120 possible classes. Each class represents a specific dog breed. For each input image, the model must predict the probability that the dog belongs to each of the 120 breeds.",
    "task":"For each given image of a dog, create a classifier to determine the dog's breed. This is a multi-class classification problem with 120 classes. Predict the probability for each of the 120 breeds in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
      "train": "A folder file containing the training set of dog images.",
      "test": "A folder file containing the test set of dog images.",
      "labels.csv": "The main training metadata file. It contains two columns: `id` (which corresponds to the image filename) and `breed` (the correct breed label for that image).",
      "sample_submission.csv": "An example file showing the required submission format, which includes an `id` column and a probability column for each of the 120 breeds."
    },
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/dog_breed_classification/kaggle/working/custom_competition_data/train",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/dog_breed_classification/kaggle/working/custom_competition_data/test",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/dog_breed_classification/kaggle/working/custom_competition_data/labels.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/dog_breed_classification/kaggle/working/custom_competition_data/sample_submission.csv"
    ]
  },
  {
    "id": "10",
    "name": "Paddy Disease Classification",
    "input_data": "The input data is multimodal, consisting of an image of a paddy leaf and its associated tabular metadata.\n- Image Data: A color photograph of a single paddy leaf.\n- Tabular Metadata: For each image, there are two additional features: `variety` (the name of the paddy variety) and `age` (the age of the paddy plant in days).",
    "output_data": "The output is a single categorical label that identifies the condition of the paddy leaf. There are 10 possible classes: nine different disease categories and one 'normal' category for a healthy leaf.",
    "task": "For each given image in test_images/, develop a model to accurately classify the paddy leaf into one of the ten possible classes (nine diseases or normal). This is a multi-class classification problem. Predict the class for each paddy leaf in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
      "train.csv": "The main training metadata file. It contains the columns `image_id`, `label` (the target class), `variety`, and `age`.(Note that the image_id contain .jpg)",
      "train_images/": "A directory containing 10,407 training images. The filenames correspond to the `image_id` in `train.csv`.",
      "test_images/": "A directory containing 3,469 test images for which predictions are required.",
      "sample_submission.csv": "An example file showing the required submission format, which includes `image_id` and `label`.",
	  "test.csv": "Test file contains the image_id to predict and label which are you need to predict"
    },
    "link to the dataset":[
      "/kaggle/input/paddy-disease-classification/paddy_disease_classification/train.csv",
      "/kaggle/input/paddy-disease-classification/paddy_disease_classification/test.csv",
      "/kaggle/input/paddy-disease-classification/paddy_disease_classification/train_images",
      "/kaggle/input/paddy-disease-classification/paddy_disease_classification/test_images",
	  "/kaggle/input/paddy-disease-classification/paddy_disease_classification/sample_submission.csv"
    ]
  },
  {
    "id": "11",
    "name": "Steel plate defect detection",
    "input_data": "The input data is tabular, consisting of a set of numerical and/or categorical features generated from a model trained on the original Steel Plates Faults dataset. These features describe the characteristics of steel plates.",
    "output_data": "The output consists of 7 independent probability values,one for each of the 7 possible defect types. The 7 defect types are: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, and Other_Faults. Each of these is a binary target (1 if the defect is present, 0 if not).",
    "task": "For each steel plate sample, predict the probability of each of the 7 defect types occurring. Since a single plate can have multiple defects simultaneously, this is a multi-label classification problem. Predict the probability of each of the 7 defect types occurring in the test dataset and output the result in submission.csv which have the same format but not the same number of rows as sample_submission.csv",
    "data file description": {
      "train.csv": "The training dataset, which contains the input features and the 7 binary target columns (Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults).",
      "test.csv": "The test dataset, which contains the input features but not the target columns. The goal is to predict the probabilities for these samples.",
      "sample_submission.csv": "An example submission file showing the required format, which includes an `id` column and a probability column for each of the 7 defects."
    },
    "link to the dataset": [
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/steel_plate_defect_prediction/train.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/steel_plate_defect_prediction/test.csv",
      "/kaggle/input/jadon-sancho-datasets/Datasets/datasets/steel_plate_defect_prediction/sample_submission.csv"
    ]
  }
]
