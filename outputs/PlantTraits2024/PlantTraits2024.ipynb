{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2705484",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "# Determine the project root\n",
    "try:\n",
    "    ROOT_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:  # __file__ is not defined inside Kaggle/Jupyter\n",
    "    ROOT_DIR = Path.cwd()\n",
    "\n",
    "# Define base path with fallback\n",
    "# The error indicates that the image path is incorrect.\n",
    "# It's trying to find '/kaggle/input/planttraits2024/PlantTraits2024/train_images/192154313.0.jpeg'\n",
    "# The current BASE_PATH logic might be resolving to a path that doesn't include 'kaggle/input'\n",
    "# or the structure is slightly different.\n",
    "# Let's explicitly set the base path to match the Kaggle environment's typical input structure.\n",
    "# Assuming the dataset is mounted at /kaggle/input/planttraits2024\n",
    "BASE_PATH = Path('/kaggle/input/planttraits2024')\n",
    "\n",
    "print(f\"Resolved BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "# File path constants\n",
    "TRAIN_CSV_PATH = BASE_PATH / 'train.csv'\n",
    "TEST_CSV_PATH = BASE_PATH / 'test.csv'\n",
    "TARGET_NAME_META_PATH = BASE_PATH / 'target_name_meta.tsv'\n",
    "SAMPLE_SUBMISSION_PATH = BASE_PATH / 'sample_submission.csv'\n",
    "TRAIN_IMAGES_PATH = BASE_PATH / 'train_images'\n",
    "TEST_IMAGES_PATH = BASE_PATH / 'test_images'\n",
    "DATASET_METADATA_PATH = BASE_PATH / 'PlantTraits2024.json' # Assuming this is the metadata file itself\n",
    "\n",
    "# Image preprocessing constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The error message indicates the image name is '192154313.0.jpeg'\n",
    "        # The 'id' column is numeric, and when converted to string, it might append '.0'\n",
    "        # We need to ensure the image name matches the actual file names.\n",
    "        # The metadata states 'id' is an integer, so we should convert it to int before forming the filename.\n",
    "        img_id = int(self.dataframe.iloc[idx]['id'])\n",
    "        img_name = f\"{img_id}.jpeg\"\n",
    "        img_path = self.img_dir / img_name\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return image and tabular data (excluding 'id' and target columns if present)\n",
    "        # For training, targets will be handled separately\n",
    "        tabular_data = self.dataframe.iloc[idx].drop(\n",
    "            columns=['id'] + [col for col in self.dataframe.columns if col.startswith('X') and '_mean' in col],\n",
    "            errors='ignore'\n",
    "        )\n",
    "        return image, tabular_data.values.astype(np.float32) # Ensure numeric type\n",
    "\n",
    "def load_metadata(metadata_path):\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_data():\n",
    "    # Load metadata\n",
    "    metadata = load_metadata(DATASET_METADATA_PATH)\n",
    "    target_columns = metadata['task_definition']['target_columns']\n",
    "\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "    # Separate features and targets for training data\n",
    "    X_train = train_df.drop(columns=target_columns)\n",
    "    y_train = train_df[target_columns]\n",
    "    X_test = test_df.copy() # Test set does not have target columns\n",
    "\n",
    "    # Identify numerical and categorical columns from profiling summary\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "\n",
    "    # Get all columns from train_df and test_df excluding 'id' and target columns\n",
    "    train_feature_cols_no_id = [col for col in X_train.columns if col != 'id']\n",
    "    test_feature_cols_no_id = [col for col in X_test.columns if col != 'id']\n",
    "\n",
    "    # Find common feature columns present in both train and test (excluding 'id')\n",
    "    common_feature_cols = list(set(train_feature_cols_no_id) & set(test_feature_cols_no_id))\n",
    "\n",
    "    for col in common_feature_cols:\n",
    "        if col in metadata['profiling_summary']['variables']:\n",
    "            var_info = metadata['profiling_summary']['variables'][col]\n",
    "            if var_info['type'] == 'Numeric':\n",
    "                numerical_cols.append(col)\n",
    "            # If there were categorical features, they would be added here.\n",
    "            # For this dataset, all relevant features are numeric.\n",
    "\n",
    "    # Sort numerical_cols for consistency (optional but good practice)\n",
    "    numerical_cols.sort()\n",
    "\n",
    "    # Imputation\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    X_train_numerical_imputed = numerical_imputer.fit_transform(X_train[numerical_cols])\n",
    "    X_test_numerical_imputed = numerical_imputer.transform(X_test[numerical_cols])\n",
    "\n",
    "    # Scaling numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_numerical_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_numerical_imputed)\n",
    "\n",
    "    # Create DataFrames with only the processed numerical columns and original 'id'\n",
    "    X_train_processed = pd.DataFrame(X_train_scaled, columns=numerical_cols, index=X_train['id'])\n",
    "    X_test_processed = pd.DataFrame(X_test_scaled, columns=numerical_cols, index=X_test['id'])\n",
    "\n",
    "    # Ensure y_train index matches X_train_processed index\n",
    "    y_train = y_train.set_index(train_df['id']) # Use original train_df 'id' for y_train index\n",
    "    y_train_processed = y_train.loc[X_train_processed.index] # Align y_train to processed X_train\n",
    "\n",
    "    return X_train_processed, y_train_processed, X_test_processed, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns\n",
    "\n",
    "def main():\n",
    "    X_train_processed, y_train_processed, X_test_processed, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns = preprocess_data()\n",
    "\n",
    "    print(\"\\n--- Preprocessing Summary ---\")\n",
    "    print(f\"Shape of X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"Shape of y_train_processed: {y_train_processed.shape}\")\n",
    "    print(f\"Shape of X_test_processed: {X_test_processed.shape}\")\n",
    "    print(f\"Number of training images (from original train_df): {len(pd.read_csv(TRAIN_CSV_PATH))}\")\n",
    "    print(f\"Number of test images (from original test_df): {len(pd.read_csv(TEST_CSV_PATH))}\")\n",
    "    print(f\"Numerical columns processed: {numerical_cols[:5]}...\")\n",
    "    print(f\"Categorical columns processed: {categorical_cols}\") # Expected to be empty for this dataset\n",
    "    print(f\"Missing values in X_train_processed after imputation: {X_train_processed.isnull().sum().sum()}\")\n",
    "    print(f\"Missing values in X_test_processed after imputation: {X_test_processed.isnull().sum().sum()}\")\n",
    "\n",
    "    # Example of accessing data from the image dataset\n",
    "    # For Stage 1, we just need to ensure the PlantDataset can be initialized.\n",
    "    # The actual image loading and combining with tabular data will be done in later stages.\n",
    "\n",
    "    # Create DataFrames for image dataset, including 'id' for image lookup\n",
    "    train_image_df = pd.read_csv(TRAIN_CSV_PATH)[['id']]\n",
    "    test_image_df = pd.read_csv(TEST_CSV_PATH)[['id']]\n",
    "\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    train_image_dataset = PlantDataset(train_image_df, TRAIN_IMAGES_PATH, transform=image_transform)\n",
    "    test_image_dataset = PlantDataset(test_image_df, TEST_IMAGES_PATH, transform=image_transform)\n",
    "\n",
    "    # first_image, _ = train_image_dataset[0]\n",
    "    # print(f\"Shape of first image in training dataset: {first_image.shape}\")\n",
    "\n",
    "    return X_train_processed, y_train_processed, X_test_processed, train_image_dataset, test_image_dataset, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train_processed, y_train_processed, X_test_processed, train_image_dataset, test_image_dataset, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2fdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import joblib\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "import warnings\n",
    "from tqdm import tqdm # Import tqdm for progress bar\n",
    "\n",
    "# Suppress specific warnings from LightGBM\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightgbm\")\n",
    "\n",
    "# Determine the project root\n",
    "try:\n",
    "    ROOT_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:  # __file__ is not defined inside Kaggle/Jupyter\n",
    "    ROOT_DIR = Path.cwd()\n",
    "\n",
    "# Define base path with fallback\n",
    "# The error indicates that the image path is incorrect.\n",
    "# It's trying to find '/kaggle/input/planttraits2024/PlantTraits2024/train_images/192154313.0.jpeg'\n",
    "# The current BASE_PATH logic might be resolving to a path that doesn't include 'kaggle/input'\n",
    "# or the structure is slightly different.\n",
    "# Let's explicitly set the base path to match the Kaggle environment's typical input structure.\n",
    "# Assuming the dataset is mounted at /kaggle/input/planttraits2024\n",
    "BASE_PATH = Path('/kaggle/input/planttraits2024')\n",
    "\n",
    "print(f\"Resolved BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "# File path constants\n",
    "TRAIN_CSV_PATH = BASE_PATH / 'train.csv'\n",
    "TEST_CSV_PATH = BASE_PATH / 'test.csv'\n",
    "TARGET_NAME_META_PATH = BASE_PATH / 'target_name_meta.tsv'\n",
    "SAMPLE_SUBMISSION_PATH = BASE_PATH / 'sample_submission.csv'\n",
    "TRAIN_IMAGES_PATH = BASE_PATH / 'train_images'\n",
    "TEST_IMAGES_PATH = BASE_PATH / 'test_images'\n",
    "DATASET_METADATA_PATH = BASE_PATH / 'PlantTraits2024.json' # Assuming this is the metadata file itself\n",
    "\n",
    "# Model and metrics paths\n",
    "MODEL_PATH = Path(\"./models/PlantTraits2024_model.pth\") # Changed to .pth for PyTorch state_dict\n",
    "METRICS_PATH = Path(\"./outputs/metrics.json\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Image preprocessing constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_train=True, target_columns=None, tabular_features_df=None):\n",
    "        self.dataframe = dataframe # This dataframe is primarily for image IDs and targets if is_train\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.target_columns = target_columns if target_columns is not None else []\n",
    "        self.tabular_features_df = tabular_features_df # Pre-processed tabular features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The error message indicates the image name is '192154313.0.jpeg'\n",
    "        # The 'id' column is numeric, and when converted to string, it might append '.0'\n",
    "        # We need to ensure the image name matches the actual file names.\n",
    "        # The metadata states 'id' is an integer, so we should convert it to int before forming the filename.\n",
    "        img_id = int(self.dataframe.iloc[idx]['id'])\n",
    "        img_name = f\"{img_id}.jpeg\"\n",
    "        img_path = self.img_dir / img_name\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get tabular data from the pre-processed dataframe using the same index\n",
    "        # Ensure that the index of self.tabular_features_df matches self.dataframe\n",
    "        # This is crucial for correct alignment of image and tabular data.\n",
    "        # The `tabular_features_df` is indexed by 'id'. We need to use the `img_id` to lookup.\n",
    "        tabular_data_row = self.tabular_features_df.loc[img_id]\n",
    "        tabular_data_tensor = torch.tensor(tabular_data_row.values.astype(np.float32))\n",
    "\n",
    "        if self.is_train:\n",
    "            targets = self.dataframe.iloc[idx][self.target_columns].values.astype(np.float32)\n",
    "            return image, tabular_data_tensor, torch.tensor(targets)\n",
    "        else:\n",
    "            return image, tabular_data_tensor\n",
    "\n",
    "def load_metadata(metadata_path):\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_data():\n",
    "    # Load metadata\n",
    "    metadata = load_metadata(DATASET_METADATA_PATH)\n",
    "    target_columns = metadata['task_definition']['target_columns']\n",
    "\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "    # Separate features and targets for training data\n",
    "    X_train = train_df.drop(columns=target_columns)\n",
    "    y_train = train_df[target_columns]\n",
    "    X_test = test_df.copy() # Test set does not have target columns\n",
    "\n",
    "    # Identify numerical and categorical columns from profiling summary\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "\n",
    "    # Get all columns from train_df and test_df excluding 'id' and target columns\n",
    "    train_feature_cols_no_id = [col for col in X_train.columns if col != 'id']\n",
    "    test_feature_cols_no_id = [col for col in X_test.columns if col != 'id']\n",
    "\n",
    "    # Find common feature columns present in both train and test (excluding 'id')\n",
    "    common_feature_cols = list(set(train_feature_cols_no_id) & set(test_feature_cols_no_id))\n",
    "\n",
    "    for col in common_feature_cols:\n",
    "        if col in metadata['profiling_summary']['variables']:\n",
    "            var_info = metadata['profiling_summary']['variables'][col]\n",
    "            if var_info['type'] == 'Numeric':\n",
    "                numerical_cols.append(col)\n",
    "            # If there were categorical features, they would be added here.\n",
    "            # For this dataset, all relevant features are numeric.\n",
    "\n",
    "    # Sort numerical_cols for consistency (optional but good practice)\n",
    "    numerical_cols.sort()\n",
    "\n",
    "    # Imputation\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    X_train_numerical_imputed = numerical_imputer.fit_transform(X_train[numerical_cols])\n",
    "    X_test_numerical_imputed = numerical_imputer.transform(X_test[numerical_cols])\n",
    "\n",
    "    # Scaling numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_numerical_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_numerical_imputed)\n",
    "\n",
    "    # Create DataFrames with only the processed numerical columns and original 'id'\n",
    "    # This is the crucial fix: ensure X_train_processed and X_test_processed only contain the selected features.\n",
    "    X_train_processed = pd.DataFrame(X_train_scaled, columns=numerical_cols, index=X_train['id'])\n",
    "    X_test_processed = pd.DataFrame(X_test_scaled, columns=numerical_cols, index=X_test['id'])\n",
    "\n",
    "    # Ensure y_train index matches X_train_processed index\n",
    "    y_train = y_train.set_index(train_df['id']) # Use original train_df 'id' for y_train index\n",
    "    y_train_processed = y_train.loc[X_train_processed.index] # Align y_train to processed X_train\n",
    "\n",
    "    return X_train_processed, y_train_processed, X_test_processed, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, num_tabular_features, num_targets):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        # Image branch: Pre-trained ResNet\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Identity() # Remove the final classification layer\n",
    "\n",
    "        # Tabular branch\n",
    "        self.tabular_fc = nn.Sequential(\n",
    "            nn.Linear(num_tabular_features, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Fusion and output layer\n",
    "        # ResNet18 outputs 512 features\n",
    "        self.fusion_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_targets)\n",
    "        )\n",
    "\n",
    "    def forward(self, image_input, tabular_input):\n",
    "        image_features = self.resnet(image_input)\n",
    "        tabular_features = self.tabular_fc(tabular_input)\n",
    "\n",
    "        combined_features = torch.cat((image_features, tabular_features), dim=1)\n",
    "        output = self.fusion_fc(combined_features)\n",
    "        return output\n",
    "\n",
    "def main():\n",
    "    X_train_processed, y_train_processed, X_test_processed, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns = preprocess_data()\n",
    "\n",
    "    print(\"\\n--- Preprocessing Summary ---\")\n",
    "    print(f\"Shape of X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"Shape of y_train_processed: {y_train_processed.shape}\")\n",
    "    print(f\"Shape of X_test_processed: {X_test_processed.shape}\")\n",
    "    print(f\"Numerical columns processed: {numerical_cols[:5]}...\")\n",
    "    print(f\"Categorical columns processed: {categorical_cols}\") # Expected to be empty for this dataset\n",
    "    print(f\"Missing values in X_train_processed after imputation: {X_train_processed.isnull().sum().sum()}\")\n",
    "    print(f\"Missing values in X_test_processed after imputation: {X_test_processed.isnull().sum().sum()}\")\n",
    "\n",
    "    # Stratified split for training and validation\n",
    "    # For regression, stratification is typically done on binned target values.\n",
    "    # Given multiple targets, a simple split is often used, or a more complex multi-output stratification.\n",
    "    # For simplicity and given the instruction, we'll use a direct split.\n",
    "    # The instruction mentions `stratify=y`, which is problematic for multi-output regression.\n",
    "    # We will proceed with a non-stratified split for multi-output regression.\n",
    "    # If stratification is strictly required, target values would need to be binned or a single representative target chosen.\n",
    "\n",
    "    # Combine X and y for splitting to ensure correct row alignment\n",
    "    train_combined_df = pd.concat([X_train_processed, y_train_processed], axis=1)\n",
    "\n",
    "    # Split train_combined_df into training and validation sets\n",
    "    train_ids = train_combined_df.index\n",
    "    train_idx, val_idx = train_test_split(train_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create separate dataframes for image dataset initialization, ensuring 'id' is a column\n",
    "    # and that they contain the target columns for is_train=True\n",
    "    original_train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    original_test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "    # Filter original_train_df by split indices for image dataset\n",
    "    train_image_df_split = original_train_df[original_train_df['id'].isin(train_idx)].reset_index(drop=True)\n",
    "    val_image_df_split = original_train_df[original_train_df['id'].isin(val_idx)].reset_index(drop=True)\n",
    "\n",
    "    # Filter processed tabular data by split indices\n",
    "    X_train_split_tabular = X_train_processed.loc[train_idx]\n",
    "    y_train_split = y_train_processed.loc[train_idx]\n",
    "    X_val_split_tabular = X_train_processed.loc[val_idx]\n",
    "    y_val_split = y_train_processed.loc[val_idx]\n",
    "\n",
    "    print(f\"Shape of X_train_split_tabular: {X_train_split_tabular.shape}\")\n",
    "    print(f\"Shape of y_train_split: {y_train_split.shape}\")\n",
    "    print(f\"Shape of X_val_split_tabular: {X_val_split_tabular.shape}\")\n",
    "    print(f\"Shape of y_val_split: {y_val_split.shape}\")\n",
    "\n",
    "    # Image data loading setup (PyTorch Dataset)\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    # Initialize PlantDataset with the appropriate tabular feature dataframes\n",
    "    train_dataset = PlantDataset(train_image_df_split, TRAIN_IMAGES_PATH, transform=image_transform, is_train=True, target_columns=target_columns, tabular_features_df=X_train_split_tabular)\n",
    "    val_dataset = PlantDataset(val_image_df_split, TRAIN_IMAGES_PATH, transform=image_transform, is_train=True, target_columns=target_columns, tabular_features_df=X_val_split_tabular)\n",
    "    test_dataset = PlantDataset(original_test_df, TEST_IMAGES_PATH, transform=image_transform, is_train=False, tabular_features_df=X_test_processed)\n",
    "\n",
    "\n",
    "    # Create DataLoader instances\n",
    "    BATCH_SIZE = 32\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Model Training\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    num_tabular_features = X_train_processed.shape[1] # Use X_train_processed shape for model definition\n",
    "    num_targets = y_train_processed.shape[1] # Use y_train_processed shape for model definition\n",
    "\n",
    "    model = MultiModalModel(num_tabular_features, num_targets).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    num_epochs = 50 # Reduced for faster execution, can be increased\n",
    "    patience = 10 # Early stopping patience\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    print(\"\\n--- Training Multi-Modal Model ---\")\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        # Add progress bar to training loop\n",
    "        for images, tabular_data, targets in tqdm(train_dataloader, desc=f\"Epoch {epoch+1} Training\"):\n",
    "            images, tabular_data, targets = images.to(device), tabular_data.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, tabular_data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_dataloader.dataset)\n",
    "\n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        # Add progress bar to validation loop\n",
    "        with torch.no_grad():\n",
    "            for images, tabular_data, targets in tqdm(val_dataloader, desc=f\"Epoch {epoch+1} Validation\"):\n",
    "                images, tabular_data, targets = images.to(device), tabular_data.to(device), targets.to(device)\n",
    "                outputs = model(images, tabular_data)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_running_loss += loss.item() * images.size(0)\n",
    "\n",
    "        val_epoch_loss = val_running_loss / len(val_dataloader.dataset)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}\")\n",
    "\n",
    "        # Early stopping\n",
    "        if val_epoch_loss < best_val_loss:\n",
    "            best_val_loss = val_epoch_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Save the best model state\n",
    "            torch.save(model.state_dict(), MODEL_PATH) # Save PyTorch model state\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            if epochs_no_improve == patience:\n",
    "                print(f\"Early stopping triggered after {epoch+1} epochs!\")\n",
    "                break\n",
    "\n",
    "    # Load the best model for evaluation\n",
    "    model.load_state_dict(torch.load(MODEL_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    val_predictions = []\n",
    "    val_true = []\n",
    "    with torch.no_grad():\n",
    "        for images, tabular_data, targets in val_dataloader:\n",
    "            images, tabular_data = images.to(device), tabular_data.to(device)\n",
    "            outputs = model(images, tabular_data)\n",
    "            val_predictions.append(outputs.cpu().numpy())\n",
    "            val_true.append(targets.cpu().numpy())\n",
    "\n",
    "    val_predictions = np.vstack(val_predictions)\n",
    "    val_true = np.vstack(val_true)\n",
    "\n",
    "    metrics = {}\n",
    "    overall_r2 = []\n",
    "    per_target_rmse = []             \n",
    "\n",
    "    for i, target_col in enumerate(target_columns):\n",
    "        y_true_target = val_true[:, i]\n",
    "        y_pred_target = val_predictions[:, i]\n",
    "\n",
    "        rmse = np.sqrt(mean_squared_error(y_true_target, y_pred_target))\n",
    "        mae = mean_absolute_error(y_true_target, y_pred_target)\n",
    "        r2  = r2_score(y_true_target, y_pred_target)\n",
    "\n",
    "        metrics[target_col] = {\n",
    "                \"RMSE\": float(rmse),\n",
    "                \"MAE\":  float(mae),\n",
    "                \"R2\":   float(r2)\n",
    "        }\n",
    "        per_target_rmse.append(rmse)  \n",
    "        overall_r2.append(r2)\n",
    "\n",
    "        print(f\"\\nMetrics for {target_col}:\")\n",
    "        print(f\"  RMSE: {rmse:.4f}\")\n",
    "        print(f\"  MAE:  {mae:.4f}\")\n",
    "        print(f\"  R2:   {r2:.4f}\")\n",
    "\n",
    "    overall_mse  = np.mean((val_predictions - val_true) ** 2)\n",
    "    overall_rmse = np.sqrt(overall_mse)\n",
    "    metrics[\"overall_RMSE\"]            = float(overall_rmse)\n",
    "    metrics[\"mean_per_target_RMSE\"]    = float(np.mean(per_target_rmse))\n",
    "    mean_r2_overall = np.mean(overall_r2)\n",
    "    metrics[\"overall_mean_R2\"]         = float(mean_r2_overall)\n",
    "    metrics[\"overall_mean_R2\"] = float(mean_r2_overall) # Convert to standard float\n",
    "    print(f\"\\nOverall Mean R2: {mean_r2_overall:.4f}\")\n",
    "\n",
    "    # Save metrics to JSON\n",
    "    with open(METRICS_PATH, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(f\"Metrics saved to {METRICS_PATH}\")\n",
    "\n",
    "    # Persist the trained model (PyTorch state dict is saved, can also save the whole model)\n",
    "    # For simplicity, we'll return the trained PyTorch model instance.\n",
    "    # The state_dict is already saved to MODEL_PATH.with_suffix('.pth')\n",
    "    # If you need to save the entire model object (e.g., for deployment with specific class definition),\n",
    "    # you would use torch.save(model, MODEL_PATH) and load with model = torch.load(MODEL_PATH)\n",
    "\n",
    "    # For joblib.dump, we would need a scikit-learn compatible model.\n",
    "    # Since we are using PyTorch, saving the state_dict is standard.\n",
    "    # If a LightGBM model was chosen for tabular data, joblib.dump would be appropriate.\n",
    "    # For this multi-modal setup, we'll indicate the PyTorch model is returned.\n",
    "\n",
    "    print(f\"Trained model state saved to {MODEL_PATH}\")\n",
    "\n",
    "    return model # Return the trained PyTorch model instance\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trained_model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ea03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import json\n",
    "import joblib\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim # Added for completeness, though not used in main() of Stage 3\n",
    "from torchvision import models\n",
    "import warnings\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tqdm import tqdm # Import tqdm for progress bar\n",
    "\n",
    "# Suppress specific warnings from LightGBM\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"lightgbm\")\n",
    "\n",
    "# Determine the project root\n",
    "try:\n",
    "    ROOT_DIR = Path(__file__).resolve().parent.parent\n",
    "except NameError:  # __file__ is not defined inside Kaggle/Jupyter\n",
    "    ROOT_DIR = Path.cwd()\n",
    "\n",
    "# Define base path with fallback\n",
    "# The error indicates that the image path is incorrect.\n",
    "# It's trying to find '/kaggle/input/planttraits2024/PlantTraits2024/train_images/192154313.0.jpeg'\n",
    "# The current BASE_PATH logic might be resolving to a path that doesn't include 'kaggle/input'\n",
    "# or the structure is slightly different.\n",
    "# Let's explicitly set the base path to match the Kaggle environment's typical input structure.\n",
    "# Assuming the dataset is mounted at /kaggle/input/planttraits2024\n",
    "BASE_PATH = Path('/kaggle/input/planttraits2024')\n",
    "\n",
    "print(f\"Resolved BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "# File path constants\n",
    "TRAIN_CSV_PATH = BASE_PATH / 'train.csv'\n",
    "TEST_CSV_PATH = BASE_PATH / 'test.csv'\n",
    "TARGET_NAME_META_PATH = BASE_PATH / 'target_name_meta.tsv'\n",
    "SAMPLE_SUBMISSION_PATH = BASE_PATH / 'sample_submission.csv'\n",
    "TRAIN_IMAGES_PATH = BASE_PATH / 'train_images'\n",
    "TEST_IMAGES_PATH = BASE_PATH / 'test_images'\n",
    "DATASET_METADATA_PATH = BASE_PATH / 'PlantTraits2024.json' # Assuming this is the metadata file itself\n",
    "\n",
    "# Model and metrics paths\n",
    "MODEL_PATH = Path(\"./models/PlantTraits2024_model.pth\") # Changed to .pth for PyTorch state_dict\n",
    "METRICS_PATH = Path(\"./outputs/metrics.json\")\n",
    "\n",
    "# Ensure output directories exist\n",
    "MODEL_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "METRICS_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Prediction and submission paths\n",
    "TEST_PROCESSED_PATH = Path(\"./processed/test_processed.csv\")\n",
    "SUBMISSION_PATH = Path(\"./outputs/submission.csv\")\n",
    "TEST_PROCESSED_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "SUBMISSION_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# Image preprocessing constants\n",
    "IMAGE_SIZE = (224, 224)\n",
    "\n",
    "class PlantDataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None, is_train=True, target_columns=None, tabular_features_df=None):\n",
    "        self.dataframe = dataframe # This dataframe is primarily for image IDs and targets if is_train\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.is_train = is_train\n",
    "        self.target_columns = target_columns if target_columns is not None else []\n",
    "        self.tabular_features_df = tabular_features_df # Pre-processed tabular features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # The error message indicates the image name is '192154313.0.jpeg'\n",
    "        # The 'id' column is numeric, and when converted to string, it might append '.0'\n",
    "        # We need to ensure the image name matches the actual file names.\n",
    "        # The metadata states 'id' is an integer, so we should convert it to int before forming the filename.\n",
    "        img_id = int(self.dataframe.iloc[idx]['id'])\n",
    "        img_name = f\"{img_id}.jpeg\"\n",
    "        img_path = self.img_dir / img_name\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get tabular data from the pre-processed dataframe using the same index\n",
    "        # Ensure that the index of self.tabular_features_df matches self.dataframe\n",
    "        # This is crucial for correct alignment of image and tabular data.\n",
    "        # The `tabular_features_df` is indexed by 'id'. We need to use the `img_id` to lookup.\n",
    "        tabular_data_row = self.tabular_features_df.loc[img_id]\n",
    "        tabular_data_tensor = torch.tensor(tabular_data_row.values.astype(np.float32))\n",
    "\n",
    "        if self.is_train:\n",
    "            targets = self.dataframe.iloc[idx][self.target_columns].values.astype(np.float32)\n",
    "            return image, tabular_data_tensor, torch.tensor(targets)\n",
    "        else:\n",
    "            return image, tabular_data_tensor\n",
    "\n",
    "def load_metadata(metadata_path):\n",
    "    with open(metadata_path, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "def preprocess_data():\n",
    "    # Load metadata\n",
    "    metadata = load_metadata(DATASET_METADATA_PATH)\n",
    "    target_columns = metadata['task_definition']['target_columns']\n",
    "\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "\n",
    "    # Separate features and targets for training data\n",
    "    X_train = train_df.drop(columns=target_columns)\n",
    "    y_train = train_df[target_columns]\n",
    "    X_test = test_df.copy() # Test set does not have target columns\n",
    "\n",
    "    # Identify numerical and categorical columns from profiling summary\n",
    "    numerical_cols = []\n",
    "    categorical_cols = [] # No categorical columns identified in profiling summary for this dataset\n",
    "\n",
    "    # Get all columns from train_df and test_df excluding 'id' and target columns\n",
    "    train_feature_cols_no_id = [col for col in X_train.columns if col != 'id']\n",
    "    test_feature_cols_no_id = [col for col in X_test.columns if col != 'id']\n",
    "\n",
    "    # Find common feature columns present in both train and test (excluding 'id')\n",
    "    common_feature_cols = list(set(train_feature_cols_no_id) & set(test_feature_cols_no_id))\n",
    "\n",
    "    for col in common_feature_cols:\n",
    "        if col in metadata['profiling_summary']['variables']:\n",
    "            var_info = metadata['profiling_summary']['variables'][col]\n",
    "            if var_info['type'] == 'Numeric':\n",
    "                numerical_cols.append(col)\n",
    "            # If there were categorical features, they would be added here.\n",
    "            # For this dataset, all relevant features are numeric.\n",
    "\n",
    "    # Sort numerical_cols for consistency (optional but good practice)\n",
    "    numerical_cols.sort()\n",
    "\n",
    "    # Imputation\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    X_train_numerical_imputed = numerical_imputer.fit_transform(X_train[numerical_cols])\n",
    "    X_test_numerical_imputed = numerical_imputer.transform(X_test[numerical_cols])\n",
    "\n",
    "    # Scaling numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_numerical_imputed)\n",
    "    X_test_scaled = scaler.transform(X_test_numerical_imputed)\n",
    "\n",
    "    # Create DataFrames with only the processed numerical columns and original 'id'\n",
    "    # FIX: Ensure X_train_processed and X_test_processed only contain the selected numerical_cols.\n",
    "    X_train_processed = pd.DataFrame(X_train_scaled, columns=numerical_cols, index=X_train['id'])\n",
    "    X_test_processed = pd.DataFrame(X_test_scaled, columns=numerical_cols, index=X_test['id'])\n",
    "\n",
    "    # Ensure y_train index matches X_train_processed index\n",
    "    y_train = y_train.set_index(train_df['id']) # Use original train_df 'id' for y_train index\n",
    "    y_train_processed = y_train.loc[X_train_processed.index] # Align y_train to processed X_train\n",
    "\n",
    "    return X_train_processed, y_train_processed, X_test_processed, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns\n",
    "\n",
    "class MultiModalModel(nn.Module):\n",
    "    def __init__(self, num_tabular_features, num_targets):\n",
    "        super(MultiModalModel, self).__init__()\n",
    "        # Image branch: Pre-trained ResNet\n",
    "        self.resnet = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
    "        self.resnet.fc = nn.Identity() # Remove the final classification layer\n",
    "\n",
    "        # Tabular branch\n",
    "        self.tabular_fc = nn.Sequential(\n",
    "            nn.Linear(num_tabular_features, 128), \n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        # Fusion and output layer\n",
    "        # ResNet18 outputs 512 features\n",
    "        self.fusion_fc = nn.Sequential(\n",
    "            nn.Linear(512 + 128, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_targets)\n",
    "        )\n",
    "\n",
    "    def forward(self, image_input, tabular_input):\n",
    "        image_features = self.resnet(image_input)\n",
    "        tabular_features = self.tabular_fc(tabular_input)\n",
    "\n",
    "        combined_features = torch.cat((image_features, tabular_features), dim=1)\n",
    "        output = self.fusion_fc(combined_features)\n",
    "        return output\n",
    "\n",
    "def main(run_training=False): # Added run_training flag to control execution flow\n",
    "    X_train_processed, y_train_processed, X_test_processed, numerical_cols, categorical_cols, scaler, numerical_imputer, target_columns = preprocess_data()\n",
    "\n",
    "    print(\"\\n--- Preprocessing Summary ---\")\n",
    "    print(f\"Shape of X_train_processed: {X_train_processed.shape}\")\n",
    "    print(f\"Shape of y_train_processed: {y_train_processed.shape}\")\n",
    "    print(f\"Shape of X_test_processed: {X_test_processed.shape}\")\n",
    "    print(f\"Numerical columns processed: {numerical_cols[:5]}...\")\n",
    "    print(f\"Categorical columns processed: {categorical_cols}\") # Expected to be empty for this dataset\n",
    "    print(f\"Missing values in X_train_processed after imputation: {X_train_processed.isnull().sum().sum()}\")\n",
    "    print(f\"Missing values in X_test_processed after imputation: {X_test_processed.isnull().sum().sum()}\")\n",
    "\n",
    "    # Save processed test data for potential later use (e.g., if this script was split)\n",
    "    X_test_processed.to_csv(TEST_PROCESSED_PATH)\n",
    "    print(f\"Processed test features saved to {TEST_PROCESSED_PATH}\")\n",
    "\n",
    "    # Image data loading setup (PyTorch Dataset)\n",
    "    image_transform = transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    class CombinedTestDataset(Dataset):\n",
    "        def __init__(self, X_test_processed_df, img_dir, transform=None):\n",
    "            self.X_test_processed_df = X_test_processed_df\n",
    "            self.img_dir = img_dir\n",
    "            self.transform = transform\n",
    "            self.ids = X_test_processed_df.index.values # Use the IDs from the processed tabular data\n",
    "\n",
    "        def __len__(self):\n",
    "            return len(self.ids)\n",
    "\n",
    "        def __getitem__(self, idx):\n",
    "            current_id = self.ids[idx]\n",
    "\n",
    "            # Load image\n",
    "            # The error was due to the image name format.\n",
    "            # The 'id' column is numeric, and when converted to string, it might append '.0'\n",
    "            # We need to ensure the image name matches the actual file names.\n",
    "            # The metadata states 'id' is an integer, so we should convert it to int before forming the filename.\n",
    "            img_name = f\"{int(current_id)}.jpeg\"\n",
    "            img_path = self.img_dir / img_name\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            # Get tabular data (already processed)\n",
    "            tabular_data = self.X_test_processed_df.loc[current_id].values.astype(np.float32)\n",
    "            tabular_data_tensor = torch.tensor(tabular_data)\n",
    "\n",
    "            return image, tabular_data_tensor\n",
    "\n",
    "    # Create the combined test dataset\n",
    "    # Pass X_test_processed directly, as it contains the IDs as index and the processed tabular features.\n",
    "    test_dataset = CombinedTestDataset(X_test_processed, TEST_IMAGES_PATH, transform=image_transform)\n",
    "\n",
    "    # Create DataLoader instances\n",
    "    BATCH_SIZE = 32\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "\n",
    "    # Model Loading and Prediction\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device for prediction: {device}\")\n",
    "\n",
    "    # Corrected num_tabular_features calculation:\n",
    "    # Ensure that X_train_processed and X_test_processed only contain the features\n",
    "    # that are actually used by the tabular model.\n",
    "    # The `preprocess_data` function needs to be modified to return only these columns.\n",
    "    # For now, let's assume the `preprocess_data` is fixed and `X_train_processed.shape[1]`\n",
    "    # will yield the correct number of features (169).\n",
    "    num_tabular_features = X_train_processed.shape[1] \n",
    "    num_targets = y_train_processed.shape[1] \n",
    "\n",
    "    model = MultiModalModel(num_tabular_features, num_targets).to(device)\n",
    "\n",
    "    # Load the trained model state\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=device))\n",
    "\n",
    "    model.eval() # Set model to evaluation mode\n",
    "\n",
    "    test_predictions = []\n",
    "    # Add progress bar to prediction loop\n",
    "    with torch.no_grad():\n",
    "        for images, tabular_data in tqdm(test_dataloader, desc=\"Predicting on Test Set\"):\n",
    "            images, tabular_data = images.to(device), tabular_data.to(device)\n",
    "            outputs = model(images, tabular_data)\n",
    "            test_predictions.append(outputs.cpu().numpy())\n",
    "\n",
    "    test_predictions = np.vstack(test_predictions)\n",
    "\n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame(test_predictions, columns=target_columns)\n",
    "    submission_df.insert(0, 'id', X_test_processed.index.values) # Add 'id' column from processed test data index\n",
    "\n",
    "    # Save submission file\n",
    "    submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "    print(f\"Submission file generated and saved to {SUBMISSION_PATH}\")\n",
    "\n",
    "    return submission_df\n",
    "\n",
    "# The `main` function in Stage 2 also needs the `tqdm` import and progress bars.\n",
    "# The `main` function in Stage 2 also needs to convert numpy floats to standard floats for JSON serialization.\n",
    "# Since the request is to fix Stage 3, I'll assume Stage 2 is already fixed or will be fixed similarly.\n",
    "# The `TypeError: Object of type float32 is not JSON serializable` was the primary error in the traceback,\n",
    "# which is fixed by `float(rmse)`, `float(mae)`, `float(r2)`, and `float(mean_r2_overall)` in Stage 2.\n",
    "# The `RuntimeError: mat1 and mat2 shapes cannot be multiplied (32x176 and 169x128)` was due to `preprocess_data`\n",
    "# not explicitly selecting only the `numerical_cols` for the final processed dataframes, leading to a mismatch\n",
    "# between the model's expected input features (169) and the actual input features (176).\n",
    "# This is fixed by ensuring `X_train_processed` and `X_test_processed` are created by explicitly selecting `numerical_cols`.\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Set run_training to True to train the model, False to only run prediction using a pre-trained model\n",
    "    # The original traceback was from `main(run_training=True)` in Stage 2, which then tried to save metrics.\n",
    "    # The current Stage 3 `main` function does not train, it only predicts.\n",
    "    # The `run_training` flag is not used in the Stage 3 `main` function, but kept for consistency if it were to be re-integrated.\n",
    "    # For submission, `run_training` should be False.\n",
    "    submission_df = main(run_training=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
