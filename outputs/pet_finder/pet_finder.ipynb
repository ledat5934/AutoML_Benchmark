{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d38e459",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the data loading, cleaning, and preprocessing steps for the PetFinder dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ROOT_DIR = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        ROOT_DIR = Path.cwd()\n",
    "\n",
    "    # Determine BASE_PATH with fallback\n",
    "    BASE_PATH_CANDIDATE = (ROOT_DIR / 'input/Datasets/datasets/pet_finder').resolve()\n",
    "    if BASE_PATH_CANDIDATE.exists():\n",
    "        BASE_PATH = BASE_PATH_CANDIDATE\n",
    "    else:\n",
    "        BASE_PATH = Path('input/Datasets/datasets/pet_finder').resolve()\n",
    "\n",
    "    print(f\"Resolved BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "    # File path constants\n",
    "    TRAIN_CSV_PATH = BASE_PATH / 'train.csv'\n",
    "    TEST_CSV_PATH = BASE_PATH / 'test/test.csv'\n",
    "    BREED_LABELS_PATH = BASE_PATH / 'BreedLabels.csv'\n",
    "    COLOR_LABELS_PATH = BASE_PATH / 'ColorLabels.csv'\n",
    "    STATE_LABELS_PATH = BASE_PATH / 'StateLabels.csv'\n",
    "    SAMPLE_SUBMISSION_PATH = BASE_PATH / 'test/sample_submission.csv'\n",
    "    METADATA_DIR = BASE_PATH / 'train_metadata' # Assuming train_metadata exists for training data\n",
    "    TEST_METADATA_DIR = BASE_PATH / 'test_metadata'\n",
    "\n",
    "    # Load dataset metadata\n",
    "    # NOTE: The provided JSON is a string, not a file path.\n",
    "    # In a real scenario, this would be loaded from a file.\n",
    "    dataset_metadata_json = {\n",
    "      \"dataset_info\": {\n",
    "        \"name\": \"pet_finder\",\n",
    "        \"base_path\": \"input/Datasets/datasets/pet_finder\",\n",
    "        \"description_file\": \"description.txt\",\n",
    "        \"files\": [\n",
    "          {\n",
    "            \"path\": \"BreedLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"breed_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"ColorLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"color_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"StateLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"state_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"train.csv\",\n",
    "            \"role\": \"train\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test/sample_submission.csv\",\n",
    "            \"role\": \"sample\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test/test.csv\",\n",
    "            \"role\": \"test\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"pet_finder.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-2.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-3.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-4.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-2.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-3.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-4.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0073c33d0-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/00bfa5da9-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"<omitted>\",\n",
    "            \"role\": \"bulk_files_summary\",\n",
    "            \"type\": \"summary\",\n",
    "            \"omitted_count\": 72749\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"profiling_summary\": {\n",
    "        \"time_index_analysis\": \"None\",\n",
    "        \"table\": {\n",
    "          \"n\": 11994,\n",
    "          \"n_var\": 24,\n",
    "          \"memory_size\": 2302976,\n",
    "          \"record_size\": 192.010672002668,\n",
    "          \"n_cells_missing\": 1022,\n",
    "          \"p_cells_missing\": 0.0035503863042632426,\n",
    "          \"size_optimized\": true,\n",
    "          \"optimization_level\": \"aggressive\",\n",
    "          \"optimization_note\": \"All value lists removed - only counts and basic statistics retained\",\n",
    "          \"removed_sections\": 129,\n",
    "          \"optimization_strategy\": \"Minimal JSON for maximum compatibility with LLM token limits\"\n",
    "        },\n",
    "        \"variables\": {\n",
    "          \"Type\": {\n",
    "            \"n_distinct\": 2,\n",
    "            \"p_distinct\": 0.00016675004168751042,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.455060863765216,\n",
    "            \"std\": 0.49799713968618003,\n",
    "            \"variance\": 0.24800115113561672,\n",
    "            \"min\": 1,\n",
    "            \"max\": 2,\n",
    "            \"kurtosis\": -1.9677444352623312,\n",
    "            \"skewness\": 0.180509595359183,\n",
    "            \"sum\": 17452,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 1,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 2.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.34225175873229674,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Name\": {\n",
    "            \"n_distinct\": 7433,\n",
    "            \"p_distinct\": 0.6768348206155527,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 6422,\n",
    "            \"p_unique\": 0.5847750865051903,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 1012,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.08437552109388027,\n",
    "            \"count\": 10982,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 47,\n",
    "            \"mean_length\": 9.545255873247132,\n",
    "            \"median_length\": 42,\n",
    "            \"min_length\": 1,\n",
    "            \"n_characters_distinct\": 167,\n",
    "            \"n_characters\": 104826,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Age\": {\n",
    "            \"n_distinct\": 103,\n",
    "            \"p_distinct\": 0.008587627146906788,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 26,\n",
    "            \"p_unique\": 0.0021677505419376354,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 139,\n",
    "            \"mean\": 10.5200100050025,\n",
    "            \"std\": 18.333786187461325,\n",
    "            \"variance\": 336.1277159675477,\n",
    "            \"min\": 0,\n",
    "            \"max\": 255,\n",
    "            \"kurtosis\": 22.350465263684598,\n",
    "            \"skewness\": 3.8602028718592316,\n",
    "            \"sum\": 126177,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 255,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 3.0,\n",
    "            \"75%\": 12.0,\n",
    "            \"95%\": 48.0,\n",
    "            \"iqr\": 10.0,\n",
    "            \"cv\": 1.7427536835747492,\n",
    "            \"p_zeros\": 0.011589127897281974,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Breed1\": {\n",
    "            \"n_distinct\": 166,\n",
    "            \"p_distinct\": 0.013840253460063364,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 38,\n",
    "            \"p_unique\": 0.003168250792062698,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 3,\n",
    "            \"mean\": 265.1770885442721,\n",
    "            \"std\": 60.087706445934444,\n",
    "            \"variance\": 3610.5324659327916,\n",
    "            \"min\": 0,\n",
    "            \"max\": 307,\n",
    "            \"kurtosis\": 4.755229972607767,\n",
    "            \"skewness\": -2.20387682115463,\n",
    "            \"sum\": 3180534,\n",
    "            \"mad\": 41.0,\n",
    "            \"range\": 307,\n",
    "            \"5%\": 109.0,\n",
    "            \"25%\": 265.0,\n",
    "            \"50%\": 266.0,\n",
    "            \"75%\": 307.0,\n",
    "            \"95%\": 307.0,\n",
    "            \"iqr\": 42.0,\n",
    "            \"cv\": 0.2265946382313592,\n",
    "            \"p_zeros\": 0.0002501250625312656,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Breed2\": {\n",
    "            \"n_distinct\": 127,\n",
    "            \"p_distinct\": 0.010588627647156911,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 41,\n",
    "            \"p_unique\": 0.0034183758545939637,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 8572,\n",
    "            \"mean\": 74.59296314824078,\n",
    "            \"std\": 123.21206290146024,\n",
    "            \"variance\": 15181.212444433397,\n",
    "            \"min\": 0,\n",
    "            \"max\": 307,\n",
    "            \"kurtosis\": -0.6290387824541743,\n",
    "            \"skewness\": 1.1256701172233239,\n",
    "            \"sum\": 894668,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 307,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 187.0,\n",
    "            \"95%\": 307.0,\n",
    "            \"iqr\": 187.0,\n",
    "            \"cv\": 1.6517920417854604,\n",
    "            \"p_zeros\": 0.7146906786726697,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Gender\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.7773886943471735,\n",
    "            \"std\": 0.6830625785943093,\n",
    "            \"variance\": 0.46657448627590703,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.8682689723647328,\n",
    "            \"skewness\": 0.3138180442669538,\n",
    "            \"sum\": 21318,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.38430680962848984,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color1\": {\n",
    "            \"n_distinct\": 7,\n",
    "            \"p_distinct\": 0.0005836251459062865,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 2.2389528097382025,\n",
    "            \"std\": 1.7508240664915704,\n",
    "            \"variance\": 3.065384911806079,\n",
    "            \"min\": 1,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": 0.9701360640824226,\n",
    "            \"skewness\": 1.4644120191370003,\n",
    "            \"sum\": 26854,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 6,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 3.0,\n",
    "            \"95%\": 6.0,\n",
    "            \"iqr\": 2.0,\n",
    "            \"cv\": 0.7819834606948646,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color2\": {\n",
    "            \"n_distinct\": 7,\n",
    "            \"p_distinct\": 0.0005836251459062865,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 3600,\n",
    "            \"mean\": 3.2131065532766385,\n",
    "            \"std\": 2.74560357697596,\n",
    "            \"variance\": 7.538339001903187,\n",
    "            \"min\": 0,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": -1.5098445593078604,\n",
    "            \"skewness\": 0.19728631311033176,\n",
    "            \"sum\": 38538,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 7,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 6.0,\n",
    "            \"95%\": 7.0,\n",
    "            \"iqr\": 6.0,\n",
    "            \"cv\": 0.8545012533667979,\n",
    "            \"p_zeros\": 0.3001500750375188,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color3\": {\n",
    "            \"n_distinct\": 6,\n",
    "            \"p_distinct\": 0.0005002501250625312,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 8515,\n",
    "            \"mean\": 1.8660163415040854,\n",
    "            \"std\": 2.9779154359383995,\n",
    "            \"variance\": 8.867980343600188,\n",
    "            \"min\": 0,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": -0.8719163439987785,\n",
    "            \"skewness\": 1.0242005667700744,\n",
    "            \"sum\": 22381,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 7,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 5.0,\n",
    "            \"95%\": 7.0,\n",
    "            \"iqr\": 5.0,\n",
    "            \"cv\": 1.595867822646225,\n",
    "            \"p_zeros\": 0.7099383024845756,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"MaturitySize\": {\n",
    "            \"n_distinct\": 4,\n",
    "            \"p_distinct\": 0.00033350008337502084,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.861347340336835,\n",
    "            \"std\": 0.5451682527705674,\n",
    "            \"variance\": 0.2972084238289132,\n",
    "            \"min\": 1,\n",
    "            \"max\": 4,\n",
    "            \"kurtosis\": 0.4605567339538248,\n",
    "            \"skewness\": -0.0022545629547571404,\n",
    "            \"sum\": 22325,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 3,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.29288904921523784,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"FurLength\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.4688177422044355,\n",
    "            \"std\": 0.5992600732036002,\n",
    "            \"variance\": 0.35911263533598425,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.21261398750180094,\n",
    "            \"skewness\": 0.8873347115703182,\n",
    "            \"sum\": 17617,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.4079880409833673,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Vaccinated\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.7356178089044523,\n",
    "            \"std\": 0.6693143222526211,\n",
    "            \"variance\": 0.4479816619724855,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.8031690089363783,\n",
    "            \"skewness\": 0.36489541999744696,\n",
    "            \"sum\": 20817,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.3856346246384175,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Dewormed\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.5581123895280973,\n",
    "            \"std\": 0.69757926564668,\n",
    "            \"variance\": 0.4866168318601614,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.5278377808281949,\n",
    "            \"skewness\": 0.8528579873444425,\n",
    "            \"sum\": 18688,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.44770792552259636,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Sterilized\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.9144572286143071,\n",
    "            \"std\": 0.5679268514311735,\n",
    "            \"variance\": 0.32254090857652623,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": 0.027778855084581444,\n",
    "            \"skewness\": -0.011743205284064464,\n",
    "            \"sum\": 22962,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.29665162686462393,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Health\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.0363515090878772,\n",
    "            \"std\": 0.19925458145199001,\n",
    "            \"variance\": 0.03970238822960773,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": 36.3757011367912,\n",
    "            \"skewness\": 5.813841143851706,\n",
    "            \"sum\": 12430,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 1.0,\n",
    "            \"95%\": 1.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.19226544247266036,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Quantity\": {\n",
    "            \"n_distinct\": 19,\n",
    "            \"p_distinct\": 0.001584125396031349,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 1,\n",
    "            \"p_unique\": 8.337502084375521e-05,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.5886276471569118,\n",
    "            \"std\": 1.508592604952439,\n",
    "            \"variance\": 2.2758516477171855,\n",
    "            \"min\": 1,\n",
    "            \"max\": 20,\n",
    "            \"kurtosis\": 36.05480385473918,\n",
    "            \"skewness\": 4.736983141694582,\n",
    "            \"sum\": 19054,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 19,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 1.0,\n",
    "            \"95%\": 5.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.9496200117455418,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Fee\": {\n",
    "            \"n_distinct\": 71,\n",
    "            \"p_distinct\": 0.00591962647990662,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 23,\n",
    "            \"p_unique\": 0.00191762547940637,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 10108,\n",
    "            \"mean\": 21.39803234950809,\n",
    "            \"std\": 79.7781620492847,\n",
    "            \"variance\": 6364.555139961931,\n",
    "            \"min\": 0,\n",
    "            \"max\": 3000,\n",
    "            \"kurtosis\": 217.67204897705238,\n",
    "            \"skewness\": 9.610892401231167,\n",
    "            \"sum\": 256648,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 3000,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 0.0,\n",
    "            \"95%\": 150.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 3.7282943004392033,\n",
    "            \"p_zeros\": 0.8427547106886777,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"State\": {\n",
    "            \"n_distinct\": 14,\n",
    "            \"p_distinct\": 0.001167250291812573,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 41345.91270635318,\n",
    "            \"std\": 32.389300021821896,\n",
    "            \"variance\": 1049.0667559035917,\n",
    "            \"min\": 41324,\n",
    "            \"max\": 41415,\n",
    "            \"kurtosis\": -0.7659264365139249,\n",
    "            \"skewness\": 1.0996311768801166,\n",
    "            \"sum\": 495902877,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 91,\n",
    "            \"5%\": 41326.0,\n",
    "            \"25%\": 41326.0,\n",
    "            \"50%\": 41326.0,\n",
    "            \"75%\": 41401.0,\n",
    "            \"95%\": 41401.0,\n",
    "            \"iqr\": 75.0,\n",
    "            \"cv\": 0.0007833736856133057,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"RescuerID\": {\n",
    "            \"n_distinct\": 4789,\n",
    "            \"p_distinct\": 0.3992829748207437,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 3315,\n",
    "            \"p_unique\": 0.2763881940970485,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 32,\n",
    "            \"mean_length\": 32.0,\n",
    "            \"median_length\": 32,\n",
    "            \"min_length\": 32,\n",
    "            \"n_characters_distinct\": 16,\n",
    "            \"n_characters\": 383808,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"VideoAmt\": {\n",
    "            \"n_distinct\": 9,\n",
    "            \"p_distinct\": 0.0007503751875937969,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 2,\n",
    "            \"p_unique\": 0.00016675004168751042,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 11535,\n",
    "            \"mean\": 0.05694513923628481,\n",
    "            \"std\": 0.3443516269990526,\n",
    "            \"variance\": 0.11857804301689463,\n",
    "            \"min\": 0,\n",
    "            \"max\": 8,\n",
    "            \"kurtosis\": 114.37392383368731,\n",
    "            \"skewness\": 9.129144018384311,\n",
    "            \"sum\": 683,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 8,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 0.0,\n",
    "            \"95%\": 0.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 6.04707674118102,\n",
    "            \"p_zeros\": 0.9617308654327164,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Description\": {\n",
    "            \"n_distinct\": 11285,\n",
    "            \"p_distinct\": 0.9416722296395194,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 11041,\n",
    "            \"p_unique\": 0.9213117489986649,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 10,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0008337502084375521,\n",
    "            \"count\": 11984,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 6664,\n",
    "            \"mean_length\": 338.8663217623498,\n",
    "            \"median_length\": 1377,\n",
    "            \"min_length\": 1,\n",
    "            \"n_characters_distinct\": 1448,\n",
    "            \"n_characters\": 4060974,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"PetID\": {\n",
    "            \"n_distinct\": 11994,\n",
    "            \"p_distinct\": 1.0,\n",
    "            \"is_unique\": true,\n",
    "            \"n_unique\": 11994,\n",
    "            \"p_unique\": 1.0,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 9,\n",
    "            \"mean_length\": 9.0,\n",
    "            \"median_length\": 9,\n",
    "            \"min_length\": 9,\n",
    "            \"n_characters_distinct\": 16,\n",
    "            \"n_characters\": 107946,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"PhotoAmt\": {\n",
    "            \"n_distinct\": 31,\n",
    "            \"p_distinct\": 0.0025846256461564115,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 273,\n",
    "            \"mean\": 3.8907787226946806,\n",
    "            \"std\": 3.4946436139785306,\n",
    "            \"variance\": 12.212533988720924,\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 30.0,\n",
    "            \"kurtosis\": 12.896628429989528,\n",
    "            \"skewness\": 2.8883393469750502,\n",
    "            \"sum\": 46666.0,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 30.0,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 3.0,\n",
    "            \"75%\": 5.0,\n",
    "            \"95%\": 10.0,\n",
    "            \"iqr\": 3.0,\n",
    "            \"cv\": 0.8981861635035893,\n",
    "            \"p_zeros\": 0.02276138069034517,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"AdoptionSpeed\": {\n",
    "            \"n_distinct\": 5,\n",
    "            \"p_distinct\": 0.00041687510421877606,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 328,\n",
    "            \"mean\": 2.516341504085376,\n",
    "            \"std\": 1.1772495657598065,\n",
    "            \"variance\": 1.385916540081653,\n",
    "            \"min\": 0,\n",
    "            \"max\": 4,\n",
    "            \"kurtosis\": -1.1393137463852208,\n",
    "            \"skewness\": -0.1549212733703575,\n",
    "            \"sum\": 30181,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 4,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 4.0,\n",
    "            \"95%\": 4.0,\n",
    "            \"iqr\": 2.0,\n",
    "            \"cv\": 0.4678417312787224,\n",
    "            \"p_zeros\": 0.02734700683675171,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          }\n",
    "        },\n",
    "        \"scatter\": {},\n",
    "        \"correlations\": {}\n",
    "      },\n",
    "      \"task_definition\": {\n",
    "        \"description_summary\": \"This dataset contains information about pets listed on PetFinder.my, including tabular data, text descriptions, and image metadata. The goal is to predict the 'AdoptionSpeed' of pets, which indicates how quickly a pet is adopted, to help improve pet profiles and reduce animal suffering.\",\n",
    "        \"note\": \"The target variable 'AdoptionSpeed' is an ordinal categorical variable with 5 possible ratings (0-4). The primary evaluation metric is quadratic weighted kappa, which measures agreement between actual and predicted ratings.\",\n",
    "        \"task_type\": \"multi_class_classification\",\n",
    "        \"target_columns\": [\n",
    "          \"AdoptionSpeed\"\n",
    "        ],\n",
    "        \"evaluation_metric\": \"quadratic_weighted_kappa\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    breed_labels = pd.read_csv(BREED_LABELS_PATH)\n",
    "    color_labels = pd.read_csv(COLOR_LABELS_PATH)\n",
    "    state_labels = pd.read_csv(STATE_LABELS_PATH)\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "\n",
    "    # Identify column types based on metadata and common sense\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    text_cols = []\n",
    "    id_cols = []\n",
    "    target_col = dataset_metadata_json['task_definition']['target_columns'][0]\n",
    "\n",
    "    for col, meta in dataset_metadata_json['profiling_summary']['variables'].items():\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        if meta['type'] == 'Numeric':\n",
    "            # Check for low cardinality numerics that might be categorical\n",
    "            if meta['n_distinct'] < 20 and meta['n_distinct'] / meta['n'] < 0.01: # Heuristic for categorical\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        elif meta['type'] == 'Text':\n",
    "            if meta['is_unique'] or col.endswith('ID'): # PetID, RescuerID\n",
    "                id_cols.append(col)\n",
    "            elif meta['mean_length'] > 50 or col == 'Description': # Heuristic for text\n",
    "                text_cols.append(col)\n",
    "            else: # Short text, treat as categorical (e.g., 'Name' might be too high cardinality for OHE, but let's keep it simple for now)\n",
    "                categorical_cols.append(col)\n",
    "\n",
    "    # Remove 'PetID' and 'RescuerID' from features for now, they are identifiers\n",
    "    # 'RescuerID' could be used for feature engineering later (e.g., count of pets per rescuer)\n",
    "    if 'PetID' in numerical_cols: numerical_cols.remove('PetID')\n",
    "    if 'PetID' in categorical_cols: categorical_cols.remove('PetID')\n",
    "    if 'PetID' in text_cols: text_cols.remove('PetID')\n",
    "    if 'RescuerID' in numerical_cols: numerical_cols.remove('RescuerID')\n",
    "    if 'RescuerID' in categorical_cols: categorical_cols.remove('RescuerID')\n",
    "    if 'RescuerID' in text_cols: text_cols.remove('RescuerID')\n",
    "\n",
    "    # Ensure target column is not in feature lists\n",
    "    if target_col in numerical_cols: numerical_cols.remove(target_col)\n",
    "    if target_col in categorical_cols: categorical_cols.remove(target_col)\n",
    "    if target_col in text_cols: text_cols.remove(target_col)\n",
    "\n",
    "    print(f\"Numerical columns: {numerical_cols}\")\n",
    "    print(f\"Categorical columns: {categorical_cols}\")\n",
    "    print(f\"Text columns: {text_cols}\")\n",
    "    print(f\"ID columns: {id_cols}\")\n",
    "    print(f\"Target column: {target_col}\")\n",
    "\n",
    "    # Impute missing values\n",
    "    # Numerical: Median imputation\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    train_df[numerical_cols] = numerical_imputer.fit_transform(train_df[numerical_cols])\n",
    "    test_df[numerical_cols] = numerical_imputer.transform(test_df[numerical_cols])\n",
    "\n",
    "    # Categorical: Mode imputation (or constant 'missing')\n",
    "    # For 'Name', which has many missing values, we'll impute with a constant.\n",
    "    # For other categorical columns, mode imputation is fine.\n",
    "    for col in categorical_cols:\n",
    "        if col == 'Name':\n",
    "            train_df[col].fillna('missing', inplace=True)\n",
    "            test_df[col].fillna('missing', inplace=True)\n",
    "        else:\n",
    "            categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "            train_df[col] = categorical_imputer.fit_transform(train_df[[col]])\n",
    "            test_df[col] = categorical_imputer.transform(test_df[[col]])\n",
    "\n",
    "    # Text: Fill NaN with empty string\n",
    "    for col in text_cols:\n",
    "        train_df[col].fillna('', inplace=True)\n",
    "        test_df[col].fillna('', inplace=True)\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first') # drop='first' to avoid multicollinearity\n",
    "    encoded_train_cols = encoder.fit_transform(train_df[categorical_cols])\n",
    "    encoded_test_cols = encoder.transform(test_df[categorical_cols])\n",
    "\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    encoded_train_df = pd.DataFrame(encoded_train_cols, columns=encoded_feature_names, index=train_df.index)\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_cols, columns=encoded_feature_names, index=test_df.index)\n",
    "\n",
    "    train_df = pd.concat([train_df.drop(columns=categorical_cols), encoded_train_df], axis=1)\n",
    "    test_df = pd.concat([test_df.drop(columns=categorical_cols), encoded_test_df], axis=1)\n",
    "\n",
    "    # TF-IDF for text columns\n",
    "    tfidf_vectorizers = {}\n",
    "    for col in text_cols:\n",
    "        tfidf = TfidfVectorizer(max_features=5000, stop_words='english') # Limit features to manage dimensionality\n",
    "        train_text_features = tfidf.fit_transform(train_df[col])\n",
    "        test_text_features = tfidf.transform(test_df[col])\n",
    "\n",
    "        train_text_df = pd.DataFrame(train_text_features.toarray(), columns=[f'{col}_tfidf_{i}' for i in range(train_text_features.shape[1])], index=train_df.index)\n",
    "        test_text_df = pd.DataFrame(test_text_features.toarray(), columns=[f'{col}_tfidf_{i}' for i in range(test_text_features.shape[1])], index=test_df.index)\n",
    "\n",
    "        train_df = pd.concat([train_df.drop(columns=[col]), train_text_df], axis=1)\n",
    "        test_df = pd.concat([test_df.drop(columns=[col]), test_text_df], axis=1)\n",
    "        tfidf_vectorizers[col] = tfidf # Store for potential reuse\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "    test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "    # --- Image Preprocessing (Feature Extraction) ---\n",
    "    # This part assumes image files are organized by PetID.\n",
    "    # We'll extract features using a pre-trained EfficientNetV2B0 model from TensorFlow Hub.\n",
    "\n",
    "    # Load the pre-trained model for feature extraction\n",
    "    # Using a smaller model for efficiency, can be changed to a larger one if needed.\n",
    "    # Ensure you have internet access or the model cached if running offline.\n",
    "    try:\n",
    "        image_feature_extractor = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\",\n",
    "            trainable=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load TensorFlow Hub model. Skipping image feature extraction: {e}\")\n",
    "        image_feature_extractor = None\n",
    "\n",
    "    IMG_SIZE = (224, 224) # Standard input size for many pre-trained models\n",
    "\n",
    "    def load_and_preprocess_image(image_path):\n",
    "        \"\"\"Loads, resizes, and normalizes an image.\"\"\"\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = tf.cast(img, tf.float32) / 255.0 # Normalize to [0,1]\n",
    "        return img\n",
    "\n",
    "    def get_image_paths(pet_id, base_dir, photo_amt):\n",
    "        \"\"\"Generates potential image paths for a given PetID.\"\"\"\n",
    "        paths = []\n",
    "        for i in range(photo_amt):\n",
    "            # Assuming image names are like PetID-1.jpg, PetID-2.jpg, etc.\n",
    "            # This is a common pattern in such datasets.\n",
    "            img_path = base_dir / pet_id / f\"{pet_id}-{i+1}.jpg\"\n",
    "            if img_path.exists():\n",
    "                paths.append(str(img_path))\n",
    "        return paths\n",
    "\n",
    "    def extract_image_features(df, base_image_dir, image_feature_extractor):\n",
    "        \"\"\"Extracts image features for each pet.\"\"\"\n",
    "        if image_feature_extractor is None:\n",
    "            return pd.DataFrame(index=df.index) # Return empty if extractor not loaded\n",
    "\n",
    "        all_pet_features = []\n",
    "        pet_ids_with_features = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            pet_id = row['PetID']\n",
    "            photo_amt = int(row['PhotoAmt']) # Ensure PhotoAmt is integer\n",
    "            image_paths = get_image_paths(pet_id, base_image_dir, photo_amt)\n",
    "\n",
    "            if image_paths:\n",
    "                # Load all images for the pet\n",
    "                images = [load_and_preprocess_image(path) for path in image_paths]\n",
    "                images_tensor = tf.stack(images) # Stack into a batch\n",
    "\n",
    "                # Extract features\n",
    "                features = image_feature_extractor(images_tensor)\n",
    "                # Aggregate features (e.g., mean pooling across images for a single pet)\n",
    "                aggregated_features = tf.reduce_mean(features, axis=0).numpy()\n",
    "                all_pet_features.append(aggregated_features)\n",
    "                pet_ids_with_features.append(pet_id)\n",
    "            else:\n",
    "                # If no images found, append NaNs or zeros, or handle as missing\n",
    "                # For simplicity, we'll append zeros if no images are found.\n",
    "                # The feature vector size for EfficientNetB0 is 1280.\n",
    "                all_pet_features.append(np.zeros(1280))\n",
    "                pet_ids_with_features.append(pet_id)\n",
    "\n",
    "        # Create a DataFrame from extracted features\n",
    "        feature_df = pd.DataFrame(all_pet_features, index=pet_ids_with_features)\n",
    "        feature_df.columns = [f'img_feat_{i}' for i in range(feature_df.shape[1])]\n",
    "        return feature_df.set_index(df['PetID']) # Set PetID as index for merging\n",
    "\n",
    "    # Assuming image files are in `BASE_PATH / 'train_images'` and `BASE_PATH / 'test_images'`\n",
    "    # The metadata JSON only lists `test_metadata` and `pet_finder.json`, not image paths directly.\n",
    "    # We'll assume a common structure for image files based on PetID.\n",
    "    TRAIN_IMAGE_DIR = BASE_PATH / 'train_images'\n",
    "    TEST_IMAGE_DIR = BASE_PATH / 'test_images'\n",
    "\n",
    "    # Check if image directories exist before attempting feature extraction\n",
    "    if TRAIN_IMAGE_DIR.exists() and TEST_IMAGE_DIR.exists() and image_feature_extractor is not None:\n",
    "        print(\"Extracting image features for training data...\")\n",
    "        train_image_features_df = extract_image_features(train_df[['PetID', 'PhotoAmt']], TRAIN_IMAGE_DIR, image_feature_extractor)\n",
    "        train_df = train_df.set_index('PetID').join(train_image_features_df, how='left').reset_index()\n",
    "\n",
    "        print(\"Extracting image features for test data...\")\n",
    "        test_image_features_df = extract_image_features(test_df[['PetID', 'PhotoAmt']], TEST_IMAGE_DIR, image_feature_extractor)\n",
    "        test_df = test_df.set_index('PetID').join(test_image_features_df, how='left').reset_index()\n",
    "    else:\n",
    "        print(\"Image directories not found or TensorFlow Hub model not loaded. Skipping image feature extraction.\")\n",
    "        # Add dummy columns if image features are skipped to maintain consistent columns\n",
    "        # This is important if the model expects these columns.\n",
    "        # For now, we'll just proceed without them. If a model expects them,\n",
    "        # you'd need to add zero-filled columns here.\n",
    "\n",
    "    # Drop PetID and RescuerID as they are identifiers and not direct features\n",
    "    # unless specific feature engineering is done on them (e.g., counts for RescuerID)\n",
    "    if 'PetID' in train_df.columns:\n",
    "        train_df = train_df.drop(columns=['PetID'])\n",
    "    if 'PetID' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['PetID'])\n",
    "\n",
    "    if 'RescuerID' in train_df.columns:\n",
    "        train_df = train_df.drop(columns=['RescuerID'])\n",
    "    if 'RescuerID' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['RescuerID'])\n",
    "\n",
    "\n",
    "    # Align columns between train and test after all transformations\n",
    "    # This is crucial for consistent feature sets, especially after OHE and TF-IDF\n",
    "    train_cols = set(train_df.columns)\n",
    "    test_cols = set(test_df.columns)\n",
    "\n",
    "    # Columns unique to train (should only be target_col)\n",
    "    missing_in_test = list(train_cols - test_cols)\n",
    "    if target_col in missing_in_test:\n",
    "        missing_in_test.remove(target_col) # Target column is expected to be missing in test\n",
    "\n",
    "    for col in missing_in_test:\n",
    "        test_df[col] = 0 # Add missing columns to test_df, fill with 0 (or appropriate default)\n",
    "\n",
    "    # Columns unique to test\n",
    "    missing_in_train = list(test_cols - train_cols)\n",
    "    for col in missing_in_train:\n",
    "        train_df[col] = 0 # Add missing columns to train_df, fill with 0 (or appropriate default)\n",
    "\n",
    "    # Ensure column order is the same\n",
    "    test_df = test_df[train_df.drop(columns=[target_col]).columns]\n",
    "\n",
    "\n",
    "    print(\"\\nPreprocessing complete.\")\n",
    "    print(f\"Train data shape: {train_df.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\")\n",
    "    print(f\"Train columns: {train_df.columns.tolist()}\")\n",
    "    print(f\"Test columns: {test_df.columns.tolist()}\")\n",
    "\n",
    "    # Return preprocessed dataframes and target\n",
    "    X_train = train_df.drop(columns=[target_col])\n",
    "    y_train = train_df[target_col]\n",
    "    X_test = test_df\n",
    "\n",
    "    return X_train, y_train, X_test, scaler, encoder, tfidf_vectorizers, image_feature_extractor\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    X_train_processed, y_train_processed, X_test_processed, scaler, encoder, tfidf_vectorizers, image_feature_extractor = main()\n",
    "    # You can now use X_train_processed, y_train_processed, X_test_processed for model training\n",
    "    print(\"\\nSample of preprocessed X_train:\")\n",
    "    print(X_train_processed.head())\n",
    "    print(\"\\nSample of preprocessed y_train:\")\n",
    "    print(y_train_processed.head())\n",
    "    print(\"\\nSample of preprocessed X_test:\")\n",
    "    print(X_test_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7e23ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from pathlib import Path\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import cv2\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss, roc_auc_score, cohen_kappa_score\n",
    "import joblib\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the data loading, cleaning, and preprocessing steps for the PetFinder dataset.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ROOT_DIR = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        ROOT_DIR = Path.cwd()\n",
    "\n",
    "    # Determine BASE_PATH with fallback\n",
    "    BASE_PATH_CANDIDATE = (ROOT_DIR / 'input/Datasets/datasets/pet_finder').resolve()\n",
    "    if BASE_PATH_CANDIDATE.exists():\n",
    "        BASE_PATH = BASE_PATH_CANDIDATE\n",
    "    else:\n",
    "        BASE_PATH = Path('input/Datasets/datasets/pet_finder').resolve()\n",
    "\n",
    "    print(f\"Resolved BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "    # File path constants\n",
    "    TRAIN_CSV_PATH = BASE_PATH / 'train.csv'\n",
    "    TEST_CSV_PATH = BASE_PATH / 'test/test.csv'\n",
    "    BREED_LABELS_PATH = BASE_PATH / 'BreedLabels.csv'\n",
    "    COLOR_LABELS_PATH = BASE_PATH / 'ColorLabels.csv'\n",
    "    STATE_LABELS_PATH = BASE_PATH / 'StateLabels.csv'\n",
    "    SAMPLE_SUBMISSION_PATH = BASE_PATH / 'test/sample_submission.csv'\n",
    "    METADATA_DIR = BASE_PATH / 'train_metadata' # Assuming train_metadata exists for training data\n",
    "    TEST_METADATA_DIR = BASE_PATH / 'test_metadata'\n",
    "\n",
    "    # Output paths\n",
    "    OUTPUTS_DIR = ROOT_DIR / 'outputs'\n",
    "    OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    METRICS_PATH = OUTPUTS_DIR / \"metrics.json\"\n",
    "    MODEL_PATH = ROOT_DIR / \"models/pet_finder_model.pkl\"\n",
    "\n",
    "    # Load dataset metadata\n",
    "    # NOTE: The provided JSON is a string, not a file path.\n",
    "    # In a real scenario, this would be loaded from a file.\n",
    "    dataset_metadata_json = {\n",
    "      \"dataset_info\": {\n",
    "        \"name\": \"pet_finder\",\n",
    "        \"base_path\": \"input/Datasets/datasets/pet_finder\",\n",
    "        \"description_file\": \"description.txt\",\n",
    "        \"files\": [\n",
    "          {\n",
    "            \"path\": \"BreedLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"breed_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"ColorLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"color_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"StateLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"state_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"train.csv\",\n",
    "            \"role\": \"train\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test/sample_submission.csv\",\n",
    "            \"role\": \"sample\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test/test.csv\",\n",
    "            \"role\": \"test\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"pet_finder.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-2.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-3.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-4.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-2.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-3.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-4.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0073c33d0-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/00bfa5da9-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"<omitted>\",\n",
    "            \"role\": \"bulk_files_summary\",\n",
    "            \"type\": \"summary\",\n",
    "            \"omitted_count\": 72749\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"profiling_summary\": {\n",
    "        \"time_index_analysis\": \"None\",\n",
    "        \"table\": {\n",
    "          \"n\": 11994,\n",
    "          \"n_var\": 24,\n",
    "          \"memory_size\": 2302976,\n",
    "          \"record_size\": 192.010672002668,\n",
    "          \"n_cells_missing\": 1022,\n",
    "          \"p_cells_missing\": 0.0035503863042632426,\n",
    "          \"size_optimized\": true,\n",
    "          \"optimization_level\": \"aggressive\",\n",
    "          \"optimization_note\": \"All value lists removed - only counts and basic statistics retained\",\n",
    "          \"removed_sections\": 129,\n",
    "          \"optimization_strategy\": \"Minimal JSON for maximum compatibility with LLM token limits\"\n",
    "        },\n",
    "        \"variables\": {\n",
    "          \"Type\": {\n",
    "            \"n_distinct\": 2,\n",
    "            \"p_distinct\": 0.00016675004168751042,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.455060863765216,\n",
    "            \"std\": 0.49799713968618003,\n",
    "            \"variance\": 0.24800115113561672,\n",
    "            \"min\": 1,\n",
    "            \"max\": 2,\n",
    "            \"kurtosis\": -1.9677444352623312,\n",
    "            \"skewness\": 0.180509595359183,\n",
    "            \"sum\": 17452,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 1,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 2.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.34225175873229674,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Name\": {\n",
    "            \"n_distinct\": 7433,\n",
    "            \"p_distinct\": 0.6768348206155527,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 6422,\n",
    "            \"p_unique\": 0.5847750865051903,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 1012,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.08437552109388027,\n",
    "            \"count\": 10982,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 47,\n",
    "            \"mean_length\": 9.545255873247132,\n",
    "            \"median_length\": 42,\n",
    "            \"min_length\": 1,\n",
    "            \"n_characters_distinct\": 167,\n",
    "            \"n_characters\": 104826,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Age\": {\n",
    "            \"n_distinct\": 103,\n",
    "            \"p_distinct\": 0.008587627146906788,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 26,\n",
    "            \"p_unique\": 0.0021677505419376354,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 139,\n",
    "            \"mean\": 10.5200100050025,\n",
    "            \"std\": 18.333786187461325,\n",
    "            \"variance\": 336.1277159675477,\n",
    "            \"min\": 0,\n",
    "            \"max\": 255,\n",
    "            \"kurtosis\": 22.350465263684598,\n",
    "            \"skewness\": 3.8602028718592316,\n",
    "            \"sum\": 126177,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 255,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 3.0,\n",
    "            \"75%\": 12.0,\n",
    "            \"95%\": 48.0,\n",
    "            \"iqr\": 10.0,\n",
    "            \"cv\": 1.7427536835747492,\n",
    "            \"p_zeros\": 0.011589127897281974,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Breed1\": {\n",
    "            \"n_distinct\": 166,\n",
    "            \"p_distinct\": 0.013840253460063364,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 38,\n",
    "            \"p_unique\": 0.003168250792062698,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 3,\n",
    "            \"mean\": 265.1770885442721,\n",
    "            \"std\": 60.087706445934444,\n",
    "            \"variance\": 3610.5324659327916,\n",
    "            \"min\": 0,\n",
    "            \"max\": 307,\n",
    "            \"kurtosis\": 4.755229972607767,\n",
    "            \"skewness\": -2.20387682115463,\n",
    "            \"sum\": 3180534,\n",
    "            \"mad\": 41.0,\n",
    "            \"range\": 307,\n",
    "            \"5%\": 109.0,\n",
    "            \"25%\": 265.0,\n",
    "            \"50%\": 266.0,\n",
    "            \"75%\": 307.0,\n",
    "            \"95%\": 307.0,\n",
    "            \"iqr\": 42.0,\n",
    "            \"cv\": 0.2265946382313592,\n",
    "            \"p_zeros\": 0.0002501250625312656,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Breed2\": {\n",
    "            \"n_distinct\": 127,\n",
    "            \"p_distinct\": 0.010588627647156911,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 41,\n",
    "            \"p_unique\": 0.0034183758545939637,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 8572,\n",
    "            \"mean\": 74.59296314824078,\n",
    "            \"std\": 123.21206290146024,\n",
    "            \"variance\": 15181.212444433397,\n",
    "            \"min\": 0,\n",
    "            \"max\": 307,\n",
    "            \"kurtosis\": -0.6290387824541743,\n",
    "            \"skewness\": 1.1256701172233239,\n",
    "            \"sum\": 894668,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 307,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 187.0,\n",
    "            \"95%\": 307.0,\n",
    "            \"iqr\": 187.0,\n",
    "            \"cv\": 1.6517920417854604,\n",
    "            \"p_zeros\": 0.7146906786726697,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Gender\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.7773886943471735,\n",
    "            \"std\": 0.6830625785943093,\n",
    "            \"variance\": 0.46657448627590703,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.8682689723647328,\n",
    "            \"skewness\": 0.3138180442669538,\n",
    "            \"sum\": 21318,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.38430680962848984,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color1\": {\n",
    "            \"n_distinct\": 7,\n",
    "            \"p_distinct\": 0.0005836251459062865,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 2.2389528097382025,\n",
    "            \"std\": 1.7508240664915704,\n",
    "            \"variance\": 3.065384911806079,\n",
    "            \"min\": 1,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": 0.9701360640824226,\n",
    "            \"skewness\": 1.4644120191370003,\n",
    "            \"sum\": 26854,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 6,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 3.0,\n",
    "            \"95%\": 6.0,\n",
    "            \"iqr\": 2.0,\n",
    "            \"cv\": 0.7819834606948646,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color2\": {\n",
    "            \"n_distinct\": 7,\n",
    "            \"p_distinct\": 0.0005836251459062865,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 3600,\n",
    "            \"mean\": 3.2131065532766385,\n",
    "            \"std\": 2.74560357697596,\n",
    "            \"variance\": 7.538339001903187,\n",
    "            \"min\": 0,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": -1.5098445593078604,\n",
    "            \"skewness\": 0.19728631311033176,\n",
    "            \"sum\": 38538,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 7,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 6.0,\n",
    "            \"95%\": 7.0,\n",
    "            \"iqr\": 6.0,\n",
    "            \"cv\": 0.8545012533667979,\n",
    "            \"p_zeros\": 0.3001500750375188,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color3\": {\n",
    "            \"n_distinct\": 6,\n",
    "            \"p_distinct\": 0.0005002501250625312,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 8515,\n",
    "            \"mean\": 1.8660163415040854,\n",
    "            \"std\": 2.9779154359383995,\n",
    "            \"variance\": 8.867980343600188,\n",
    "            \"min\": 0,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": -0.8719163439987785,\n",
    "            \"skewness\": 1.0242005667700744,\n",
    "            \"sum\": 22381,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 7,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 5.0,\n",
    "            \"95%\": 7.0,\n",
    "            \"iqr\": 5.0,\n",
    "            \"cv\": 1.595867822646225,\n",
    "            \"p_zeros\": 0.7099383024845756,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"MaturitySize\": {\n",
    "            \"n_distinct\": 4,\n",
    "            \"p_distinct\": 0.00033350008337502084,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.861347340336835,\n",
    "            \"std\": 0.5451682527705674,\n",
    "            \"variance\": 0.2972084238289132,\n",
    "            \"min\": 1,\n",
    "            \"max\": 4,\n",
    "            \"kurtosis\": 0.4605567339538248,\n",
    "            \"skewness\": -0.0022545629547571404,\n",
    "            \"sum\": 22325,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 3,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.29288904921523784,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"FurLength\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.4688177422044355,\n",
    "            \"std\": 0.5992600732036002,\n",
    "            \"variance\": 0.35911263533598425,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.21261398750180094,\n",
    "            \"skewness\": 0.8873347115703182,\n",
    "            \"sum\": 17617,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.4079880409833673,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Vaccinated\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.7356178089044523,\n",
    "            \"std\": 0.6693143222526211,\n",
    "            \"variance\": 0.4479816619724855,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.8031690089363783,\n",
    "            \"skewness\": 0.36489541999744696,\n",
    "            \"sum\": 20817,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.3856346246384175,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Dewormed\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.5581123895280973,\n",
    "            \"std\": 0.69757926564668,\n",
    "            \"variance\": 0.4866168318601614,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.5278377808281949,\n",
    "            \"skewness\": 0.8528579873444425,\n",
    "            \"sum\": 18688,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.44770792552259636,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Sterilized\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.9144572286143071,\n",
    "            \"std\": 0.5679268514311735,\n",
    "            \"variance\": 0.32254090857652623,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": 0.027778855084581444,\n",
    "            \"skewness\": -0.011743205284064464,\n",
    "            \"sum\": 22962,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.29665162686462393,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Health\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.0363515090878772,\n",
    "            \"std\": 0.19925458145199001,\n",
    "            \"variance\": 0.03970238822960773,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": 36.3757011367912,\n",
    "            \"skewness\": 5.813841143851706,\n",
    "            \"sum\": 12430,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 1.0,\n",
    "            \"95%\": 1.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.19226544247266036,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Quantity\": {\n",
    "            \"n_distinct\": 19,\n",
    "            \"p_distinct\": 0.001584125396031349,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 1,\n",
    "            \"p_unique\": 8.337502084375521e-05,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.5886276471569118,\n",
    "            \"std\": 1.508592604952439,\n",
    "            \"variance\": 2.2758516477171855,\n",
    "            \"min\": 1,\n",
    "            \"max\": 20,\n",
    "            \"kurtosis\": 36.05480385473918,\n",
    "            \"skewness\": 4.736983141694582,\n",
    "            \"sum\": 19054,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 19,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 1.0,\n",
    "            \"95%\": 5.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.9496200117455418,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Fee\": {\n",
    "            \"n_distinct\": 71,\n",
    "            \"p_distinct\": 0.00591962647990662,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 23,\n",
    "            \"p_unique\": 0.00191762547940637,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 10108,\n",
    "            \"mean\": 21.39803234950809,\n",
    "            \"std\": 79.7781620492847,\n",
    "            \"variance\": 6364.555139961931,\n",
    "            \"min\": 0,\n",
    "            \"max\": 3000,\n",
    "            \"kurtosis\": 217.67204897705238,\n",
    "            \"skewness\": 9.610892401231167,\n",
    "            \"sum\": 256648,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 3000,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 0.0,\n",
    "            \"95%\": 150.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 3.7282943004392033,\n",
    "            \"p_zeros\": 0.8427547106886777,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"State\": {\n",
    "            \"n_distinct\": 14,\n",
    "            \"p_distinct\": 0.001167250291812573,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 41345.91270635318,\n",
    "            \"std\": 32.389300021821896,\n",
    "            \"variance\": 1049.0667559035917,\n",
    "            \"min\": 41324,\n",
    "            \"max\": 41415,\n",
    "            \"kurtosis\": -0.7659264365139249,\n",
    "            \"skewness\": 1.0996311768801166,\n",
    "            \"sum\": 495902877,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 91,\n",
    "            \"5%\": 41326.0,\n",
    "            \"25%\": 41326.0,\n",
    "            \"50%\": 41326.0,\n",
    "            \"75%\": 41401.0,\n",
    "            \"95%\": 41401.0,\n",
    "            \"iqr\": 75.0,\n",
    "            \"cv\": 0.0007833736856133057,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"RescuerID\": {\n",
    "            \"n_distinct\": 4789,\n",
    "            \"p_distinct\": 0.3992829748207437,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 3315,\n",
    "            \"p_unique\": 0.2763881940970485,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 32,\n",
    "            \"mean_length\": 32.0,\n",
    "            \"median_length\": 32,\n",
    "            \"min_length\": 32,\n",
    "            \"n_characters_distinct\": 16,\n",
    "            \"n_characters\": 383808,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"VideoAmt\": {\n",
    "            \"n_distinct\": 9,\n",
    "            \"p_distinct\": 0.0007503751875937969,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 2,\n",
    "            \"p_unique\": 0.00016675004168751042,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 11535,\n",
    "            \"mean\": 0.05694513923628481,\n",
    "            \"std\": 0.3443516269990526,\n",
    "            \"variance\": 0.11857804301689463,\n",
    "            \"min\": 0,\n",
    "            \"max\": 8,\n",
    "            \"kurtosis\": 114.37392383368731,\n",
    "            \"skewness\": 9.129144018384311,\n",
    "            \"sum\": 683,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 8,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 0.0,\n",
    "            \"95%\": 0.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 6.04707674118102,\n",
    "            \"p_zeros\": 0.9617308654327164,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Description\": {\n",
    "            \"n_distinct\": 11285,\n",
    "            \"p_distinct\": 0.9416722296395194,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 11041,\n",
    "            \"p_unique\": 0.9213117489986649,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 10,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0008337502084375521,\n",
    "            \"count\": 11984,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 6664,\n",
    "            \"mean_length\": 338.8663217623498,\n",
    "            \"median_length\": 1377,\n",
    "            \"min_length\": 1,\n",
    "            \"n_characters_distinct\": 1448,\n",
    "            \"n_characters\": 4060974,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"PetID\": {\n",
    "            \"n_distinct\": 11994,\n",
    "            \"p_distinct\": 1.0,\n",
    "            \"is_unique\": true,\n",
    "            \"n_unique\": 11994,\n",
    "            \"p_unique\": 1.0,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 9,\n",
    "            \"mean_length\": 9.0,\n",
    "            \"median_length\": 9,\n",
    "            \"min_length\": 9,\n",
    "            \"n_characters_distinct\": 16,\n",
    "            \"n_characters\": 107946,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"PhotoAmt\": {\n",
    "            \"n_distinct\": 31,\n",
    "            \"p_distinct\": 0.0025846256461564115,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 273,\n",
    "            \"mean\": 3.8907787226946806,\n",
    "            \"std\": 3.4946436139785306,\n",
    "            \"variance\": 12.212533988720924,\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 30.0,\n",
    "            \"kurtosis\": 12.896628429989528,\n",
    "            \"skewness\": 2.8883393469750502,\n",
    "            \"sum\": 46666.0,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 30.0,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 3.0,\n",
    "            \"75%\": 5.0,\n",
    "            \"95%\": 10.0,\n",
    "            \"iqr\": 3.0,\n",
    "            \"cv\": 0.8981861635035893,\n",
    "            \"p_zeros\": 0.02276138069034517,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"AdoptionSpeed\": {\n",
    "            \"n_distinct\": 5,\n",
    "            \"p_distinct\": 0.00041687510421877606,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 328,\n",
    "            \"mean\": 2.516341504085376,\n",
    "            \"std\": 1.1772495657598065,\n",
    "            \"variance\": 1.385916540081653,\n",
    "            \"min\": 0,\n",
    "            \"max\": 4,\n",
    "            \"kurtosis\": -1.1393137463852208,\n",
    "            \"skewness\": -0.1549212733703575,\n",
    "            \"sum\": 30181,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 4,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 4.0,\n",
    "            \"95%\": 4.0,\n",
    "            \"iqr\": 2.0,\n",
    "            \"cv\": 0.4678417312787224,\n",
    "            \"p_zeros\": 0.02734700683675171,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          }\n",
    "        },\n",
    "        \"scatter\": {},\n",
    "        \"correlations\": {}\n",
    "      },\n",
    "      \"task_definition\": {\n",
    "        \"description_summary\": \"This dataset contains information about pets listed on PetFinder.my, including tabular data, text descriptions, and image metadata. The goal is to predict the 'AdoptionSpeed' of pets, which indicates how quickly a pet is adopted, to help improve pet profiles and reduce animal suffering.\",\n",
    "        \"note\": \"The target variable 'AdoptionSpeed' is an ordinal categorical variable with 5 possible ratings (0-4). The primary evaluation metric is quadratic weighted kappa, which measures agreement between actual and predicted ratings.\",\n",
    "        \"task_type\": \"multi_class_classification\",\n",
    "        \"target_columns\": [\n",
    "          \"AdoptionSpeed\"\n",
    "        ],\n",
    "        \"evaluation_metric\": \"quadratic_weighted_kappa\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "\n",
    "    # Load datasets\n",
    "    train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    breed_labels = pd.read_csv(BREED_LABELS_PATH)\n",
    "    color_labels = pd.read_csv(COLOR_LABELS_PATH)\n",
    "    state_labels = pd.read_csv(STATE_LABELS_PATH)\n",
    "\n",
    "    # --- Preprocessing ---\n",
    "\n",
    "    # Identify column types based on metadata and common sense\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    text_cols = []\n",
    "    id_cols = []\n",
    "    target_col = dataset_metadata_json['task_definition']['target_columns'][0]\n",
    "\n",
    "    for col, meta in dataset_metadata_json['profiling_summary']['variables'].items():\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        if meta['type'] == 'Numeric':\n",
    "            # Check for low cardinality numerics that might be categorical\n",
    "            if meta['n_distinct'] < 20 and meta['n_distinct'] / meta['n'] < 0.01: # Heuristic for categorical\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        elif meta['type'] == 'Text':\n",
    "            if meta['is_unique'] or col.endswith('ID'): # PetID, RescuerID\n",
    "                id_cols.append(col)\n",
    "            elif meta['mean_length'] > 50 or col == 'Description': # Heuristic for text\n",
    "                text_cols.append(col)\n",
    "            else: # Short text, treat as categorical (e.g., 'Name' might be too high cardinality for OHE, but let's keep it simple for now)\n",
    "                categorical_cols.append(col)\n",
    "\n",
    "    # Remove 'PetID' and 'RescuerID' from features for now, they are identifiers\n",
    "    # 'RescuerID' could be used for feature engineering later (e.g., count of pets per rescuer)\n",
    "    # Keep PetID for image feature merging, then drop\n",
    "\n",
    "    # Ensure target column is not in feature lists\n",
    "    if target_col in numerical_cols: numerical_cols.remove(target_col)\n",
    "    if target_col in categorical_cols: categorical_cols.remove(target_col)\n",
    "    if target_col in text_cols: text_cols.remove(target_col)\n",
    "\n",
    "    # Handle 'Name' as a text column if its mean length is high, otherwise categorical\n",
    "    # Based on metadata, mean_length is 9.54, median is 42. Max is 47.\n",
    "    # It has 7433 distinct values out of 11994, so it's high cardinality.\n",
    "    # Let's treat 'Name' as a text column for TF-IDF.\n",
    "    if 'Name' in categorical_cols:\n",
    "        categorical_cols.remove('Name')\n",
    "        text_cols.append('Name')\n",
    "\n",
    "    print(f\"Numerical columns: {numerical_cols}\")\n",
    "    print(f\"Categorical columns: {categorical_cols}\")\n",
    "    print(f\"Text columns: {text_cols}\")\n",
    "    print(f\"ID columns: {id_cols}\")\n",
    "    print(f\"Target column: {target_col}\")\n",
    "\n",
    "    # Impute missing values\n",
    "    # Numerical: Median imputation\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    train_df[numerical_cols] = numerical_imputer.fit_transform(train_df[numerical_cols])\n",
    "    test_df[numerical_cols] = numerical_imputer.transform(test_df[numerical_cols])\n",
    "\n",
    "    # Categorical: Mode imputation (or constant 'missing')\n",
    "    for col in categorical_cols:\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        train_df[col] = categorical_imputer.fit_transform(train_df[[col]])\n",
    "        test_df[col] = categorical_imputer.transform(test_df[[col]])\n",
    "\n",
    "    # Text: Fill NaN with empty string\n",
    "    for col in text_cols:\n",
    "        train_df[col].fillna('', inplace=True)\n",
    "        test_df[col].fillna('', inplace=True)\n",
    "\n",
    "    # One-hot encode categorical columns\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first') # drop='first' to avoid multicollinearity\n",
    "    encoded_train_cols = encoder.fit_transform(train_df[categorical_cols])\n",
    "    encoded_test_cols = encoder.transform(test_df[categorical_cols])\n",
    "\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    encoded_train_df = pd.DataFrame(encoded_train_cols, columns=encoded_feature_names, index=train_df.index)\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_cols, columns=encoded_feature_names, index=test_df.index)\n",
    "\n",
    "    train_df = pd.concat([train_df.drop(columns=categorical_cols), encoded_train_df], axis=1)\n",
    "    test_df = pd.concat([test_df.drop(columns=categorical_cols), encoded_test_df], axis=1)\n",
    "\n",
    "    # TF-IDF for text columns\n",
    "    tfidf_vectorizers = {}\n",
    "    for col in text_cols:\n",
    "        tfidf = TfidfVectorizer(max_features=5000, stop_words='english') # Limit features to manage dimensionality\n",
    "        train_text_features = tfidf.fit_transform(train_df[col])\n",
    "        test_text_features = tfidf.transform(test_df[col])\n",
    "\n",
    "        train_text_df = pd.DataFrame(train_text_features.toarray(), columns=[f'{col}_tfidf_{i}' for i in range(train_text_features.shape[1])], index=train_df.index)\n",
    "        test_text_df = pd.DataFrame(test_text_features.toarray(), columns=[f'{col}_tfidf_{i}' for i in range(test_text_features.shape[1])], index=test_df.index)\n",
    "\n",
    "        train_df = pd.concat([train_df.drop(columns=[col]), train_text_df], axis=1)\n",
    "        test_df = pd.concat([test_df.drop(columns=[col]), test_text_df], axis=1)\n",
    "        tfidf_vectorizers[col] = tfidf # Store for potential reuse\n",
    "\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    train_df[numerical_cols] = scaler.fit_transform(train_df[numerical_cols])\n",
    "    test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "    # --- Image Preprocessing (Feature Extraction) ---\n",
    "    # This part assumes image files are organized by PetID.\n",
    "    # We'll extract features using a pre-trained EfficientNetV2B0 model from TensorFlow Hub.\n",
    "\n",
    "    # Load the pre-trained model for feature extraction\n",
    "    try:\n",
    "        image_feature_extractor = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\",\n",
    "            trainable=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load TensorFlow Hub model. Skipping image feature extraction: {e}\")\n",
    "        image_feature_extractor = None\n",
    "\n",
    "    IMG_SIZE = (224, 224) # Standard input size for many pre-trained models\n",
    "\n",
    "    def load_and_preprocess_image(image_path):\n",
    "        \"\"\"Loads, resizes, and normalizes an image.\"\"\"\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = tf.cast(img, tf.float32) / 255.0 # Normalize to [0,1]\n",
    "        return img\n",
    "\n",
    "    def get_image_paths(pet_id, base_dir, photo_amt):\n",
    "        \"\"\"Generates potential image paths for a given PetID.\"\"\"\n",
    "        paths = []\n",
    "        # The dataset structure implies images are in subdirectories named by PetID\n",
    "        # and then named PetID-1.jpg, PetID-2.jpg etc.\n",
    "        # However, the metadata only lists test_metadata/*.json, not image files.\n",
    "        # A common structure for this dataset is images in `train_images/PetID-X.jpg`\n",
    "        # Let's assume images are directly in `train_images` and `test_images`\n",
    "        # with names like `PetID-1.jpg`.\n",
    "        # The original Kaggle competition had images in `train_images/PetID-X.jpg`\n",
    "        # and `test_images/PetID-X.jpg`.\n",
    "\n",
    "        # Adjusting path generation based on common Kaggle PetFinder structure\n",
    "        # Images are typically in `train_images/PetID-1.jpg`, `train_images/PetID-2.jpg`, etc.\n",
    "        # and similarly for test.\n",
    "\n",
    "        # Check for both PetID/PetID-X.jpg and PetID-X.jpg directly in base_dir\n",
    "        # The metadata implies `test_metadata/002230dea-1.json` which suggests\n",
    "        # metadata files are per image, not per pet.\n",
    "        # For image features, we need the actual image files.\n",
    "        # Let's assume the images are in `BASE_PATH / 'train_images'` and `BASE_PATH / 'test_images'`\n",
    "        # and named `PetID-X.jpg`.\n",
    "\n",
    "        # The original competition had images in `train_images/` and `test_images/`\n",
    "        # and named `PetID-1.jpg`, `PetID-2.jpg`, etc.\n",
    "\n",
    "        # Let's try to find images in the common structure:\n",
    "        # BASE_PATH / 'train_images' / f'{pet_id}-{i+1}.jpg'\n",
    "        # BASE_PATH / 'test_images' / f'{pet_id}-{i+1}.jpg'\n",
    "\n",
    "        for i in range(photo_amt):\n",
    "            img_path = base_dir / f\"{pet_id}-{i+1}.jpg\"\n",
    "            if img_path.exists():\n",
    "                paths.append(str(img_path))\n",
    "        return paths\n",
    "\n",
    "    def extract_image_features(df, base_image_dir, image_feature_extractor):\n",
    "        \"\"\"Extracts image features for each pet.\"\"\"\n",
    "        if image_feature_extractor is None:\n",
    "            # Return a DataFrame with PetID as index and zero-filled columns\n",
    "            # to ensure consistent feature set even if image features are skipped.\n",
    "            # The feature vector size for EfficientNetB0 is 1280.\n",
    "            dummy_features = np.zeros((len(df), 1280))\n",
    "            feature_df = pd.DataFrame(dummy_features, index=df['PetID'])\n",
    "            feature_df.columns = [f'img_feat_{i}' for i in range(feature_df.shape[1])]\n",
    "            return feature_df\n",
    "\n",
    "        all_pet_features = []\n",
    "        pet_ids_with_features = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            pet_id = row['PetID']\n",
    "            photo_amt = int(row['PhotoAmt']) # Ensure PhotoAmt is integer\n",
    "            image_paths = get_image_paths(pet_id, base_image_dir, photo_amt)\n",
    "\n",
    "            if image_paths:\n",
    "                # Load all images for the pet\n",
    "                images = []\n",
    "                for path in image_paths:\n",
    "                    try:\n",
    "                        images.append(load_and_preprocess_image(path))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {path}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                if images:\n",
    "                    images_tensor = tf.stack(images) # Stack into a batch\n",
    "                    # Extract features\n",
    "                    features = image_feature_extractor(images_tensor)\n",
    "                    # Aggregate features (e.g., mean pooling across images for a single pet)\n",
    "                    aggregated_features = tf.reduce_mean(features, axis=0).numpy()\n",
    "                    all_pet_features.append(aggregated_features)\n",
    "                    pet_ids_with_features.append(pet_id)\n",
    "                else:\n",
    "                    # If no images could be loaded, append zeros\n",
    "                    all_pet_features.append(np.zeros(1280))\n",
    "                    pet_ids_with_features.append(pet_id)\n",
    "            else:\n",
    "                # If no images found, append zeros\n",
    "                all_pet_features.append(np.zeros(1280))\n",
    "                pet_ids_with_features.append(pet_id)\n",
    "\n",
    "        # Create a DataFrame from extracted features\n",
    "        feature_df = pd.DataFrame(all_pet_features, index=pet_ids_with_features)\n",
    "        feature_df.columns = [f'img_feat_{i}' for i in range(feature_df.shape[1])]\n",
    "        return feature_df\n",
    "\n",
    "    # Assuming image files are in `BASE_PATH / 'train_images'` and `BASE_PATH / 'test_images'`\n",
    "    TRAIN_IMAGE_DIR = BASE_PATH / 'train_images'\n",
    "    TEST_IMAGE_DIR = BASE_PATH / 'test_images'\n",
    "\n",
    "    # Temporarily store PetID for merging image features\n",
    "    train_pet_ids = train_df['PetID']\n",
    "    test_pet_ids = test_df['PetID']\n",
    "\n",
    "    # Extract image features\n",
    "    print(\"Extracting image features for training data...\")\n",
    "    train_image_features_df = extract_image_features(train_df[['PetID', 'PhotoAmt']], TRAIN_IMAGE_DIR, image_feature_extractor)\n",
    "    train_df = train_df.set_index('PetID').join(train_image_features_df, how='left').reset_index()\n",
    "\n",
    "    print(\"Extracting image features for test data...\")\n",
    "    test_image_features_df = extract_image_features(test_df[['PetID', 'PhotoAmt']], TEST_IMAGE_DIR, image_feature_extractor)\n",
    "    test_df = test_df.set_index('PetID').join(test_image_features_df, how='left').reset_index()\n",
    "\n",
    "    # Drop PetID and RescuerID as they are identifiers and not direct features\n",
    "    if 'PetID' in train_df.columns:\n",
    "        train_df = train_df.drop(columns=['PetID'])\n",
    "    if 'PetID' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['PetID'])\n",
    "\n",
    "    if 'RescuerID' in train_df.columns:\n",
    "        train_df = train_df.drop(columns=['RescuerID'])\n",
    "    if 'RescuerID' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['RescuerID'])\n",
    "\n",
    "    # Align columns between train and test after all transformations\n",
    "    train_cols = set(train_df.columns)\n",
    "    test_cols = set(test_df.columns)\n",
    "\n",
    "    # Columns unique to train (should only be target_col)\n",
    "    missing_in_test = list(train_cols - test_cols)\n",
    "    if target_col in missing_in_test:\n",
    "        missing_in_test.remove(target_col) # Target column is expected to be missing in test\n",
    "\n",
    "    for col in missing_in_test:\n",
    "        test_df[col] = 0 # Add missing columns to test_df, fill with 0 (or appropriate default)\n",
    "\n",
    "    # Columns unique to test\n",
    "    missing_in_train = list(test_cols - train_cols)\n",
    "    for col in missing_in_train:\n",
    "        train_df[col] = 0 # Add missing columns to train_df, fill with 0 (or appropriate default)\n",
    "\n",
    "    # Ensure column order is the same\n",
    "    # Drop target column from train_df before aligning columns with test_df\n",
    "    X_train_full = train_df.drop(columns=[target_col])\n",
    "    y_train_full = train_df[target_col]\n",
    "\n",
    "    test_df = test_df[X_train_full.columns]\n",
    "\n",
    "\n",
    "    print(\"\\nPreprocessing complete.\")\n",
    "    print(f\"Train data shape: {X_train_full.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\")\n",
    "    print(f\"Train columns: {X_train_full.columns.tolist()}\")\n",
    "    print(f\"Test columns: {test_df.columns.tolist()}\")\n",
    "\n",
    "    # --- Model Training ---\n",
    "    # Perform an 80/20 stratified split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train_full, y_train_full, test_size=0.2, random_state=42, stratify=y_train_full\n",
    "    )\n",
    "\n",
    "    print(f\"\\nTraining data split into X_train: {X_train.shape}, X_val: {X_val.shape}\")\n",
    "\n",
    "    # LightGBM Classifier for multi-class classification\n",
    "    # Using 'multiclass' objective for ordinal target, num_class=5 (0-4)\n",
    "    lgb_params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 5,\n",
    "        'metric': 'multi_logloss',\n",
    "        'n_estimators': 2000, # Large number, will use early stopping\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.8,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 1,\n",
    "        'lambda_l1': 0.1,\n",
    "        'lambda_l2': 0.1,\n",
    "        'num_leaves': 31,\n",
    "        'verbose': -1, # Suppress verbose output\n",
    "        'n_jobs': -1,\n",
    "        'seed': 42,\n",
    "        'boosting_type': 'gbdt',\n",
    "    }\n",
    "\n",
    "    model = lgb.LGBMClassifier(**lgb_params)\n",
    "\n",
    "    print(\"\\nStarting model training...\")\n",
    "    model.fit(X_train, y_train,\n",
    "              eval_set=[(X_val, y_val)],\n",
    "              eval_metric='multi_logloss',\n",
    "              callbacks=[lgb.early_stopping(100, verbose=False)]) # Early stopping after 100 rounds\n",
    "\n",
    "    print(\"Model training complete.\")\n",
    "\n",
    "    # --- Evaluation ---\n",
    "    print(\"\\nEvaluating model on validation set...\")\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    y_proba_val = model.predict_proba(X_val)\n",
    "\n",
    "    metrics = {}\n",
    "    metrics['accuracy'] = accuracy_score(y_val, y_pred_val)\n",
    "    metrics['f1_macro'] = f1_score(y_val, y_pred_val, average='macro')\n",
    "    metrics['log_loss'] = log_loss(y_val, y_proba_val)\n",
    "\n",
    "    # ROC AUC for multi-class is typically calculated 'ovr' or 'ovo'\n",
    "    # For ordinal classification, quadratic weighted kappa is the primary metric.\n",
    "    # ROC AUC requires binary classification or one-vs-rest/one-vs-one for multi-class.\n",
    "    # Given the target is ordinal, ROC_AUC might not be the most intuitive metric.\n",
    "    # Let's calculate it using 'ovr' if possible, but prioritize kappa.\n",
    "    try:\n",
    "        metrics['roc_auc_ovr'] = roc_auc_score(y_val, y_proba_val, multi_class='ovr')\n",
    "    except ValueError as e:\n",
    "        metrics['roc_auc_ovr'] = f\"Not applicable or error: {e}\"\n",
    "        print(f\"Warning: Could not calculate ROC_AUC_OVR: {e}\")\n",
    "\n",
    "    # Quadratic Weighted Kappa (QWK) - primary evaluation metric for this dataset\n",
    "    metrics['quadratic_weighted_kappa'] = cohen_kappa_score(y_val, y_pred_val, weights='quadratic')\n",
    "\n",
    "    print(\"\\nValidation Metrics:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "    # Persist metrics to JSON file\n",
    "    with open(METRICS_PATH, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "    print(f\"Metrics saved to {METRICS_PATH}\")\n",
    "\n",
    "    # --- Model Persistence ---\n",
    "    print(f\"\\nSaving trained model to {MODEL_PATH}...\")\n",
    "    joblib.dump(model, MODEL_PATH)\n",
    "    print(\"Model saved successfully.\")\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    trained_model = main()\n",
    "    print(\"\\nScript finished. Trained model instance returned.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16803fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Orchestrates the prediction generation for the PetFinder dataset.\n",
    "    Loads the trained model and preprocessed test data, then generates\n",
    "    and saves the submission file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        ROOT_DIR = Path(__file__).resolve().parent.parent\n",
    "    except NameError:\n",
    "        ROOT_DIR = Path.cwd()\n",
    "\n",
    "    # Determine BASE_PATH with fallback\n",
    "    BASE_PATH_CANDIDATE = (ROOT_DIR / 'input/Datasets/datasets/pet_finder').resolve()\n",
    "    if BASE_PATH_CANDIDATE.exists():\n",
    "        BASE_PATH = BASE_PATH_CANDIDATE\n",
    "    else:\n",
    "        BASE_PATH = Path('input/Datasets/datasets/pet_finder').resolve()\n",
    "\n",
    "    print(f\"Resolved BASE_PATH: {BASE_PATH}\")\n",
    "\n",
    "    # File path constants\n",
    "    TEST_CSV_PATH = BASE_PATH / 'test/test.csv'\n",
    "    BREED_LABELS_PATH = BASE_PATH / 'BreedLabels.csv'\n",
    "    COLOR_LABELS_PATH = BASE_PATH / 'ColorLabels.csv'\n",
    "    STATE_LABELS_PATH = BASE_PATH / 'StateLabels.csv'\n",
    "    SAMPLE_SUBMISSION_PATH = BASE_PATH / 'test/sample_submission.csv'\n",
    "    TEST_IMAGE_DIR = BASE_PATH / 'test_images' # Assuming test images are here\n",
    "\n",
    "    # Output paths\n",
    "    OUTPUTS_DIR = ROOT_DIR / 'outputs'\n",
    "    OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    MODEL_PATH = ROOT_DIR / \"models/pet_finder_model.pkl\"\n",
    "    SUBMISSION_PATH = OUTPUTS_DIR / \"submission.csv\"\n",
    "\n",
    "    # Load dataset metadata (as a string, as provided in the prompt)\n",
    "    dataset_metadata_json = {\n",
    "      \"dataset_info\": {\n",
    "        \"name\": \"pet_finder\",\n",
    "        \"base_path\": \"input/Datasets/datasets/pet_finder\",\n",
    "        \"description_file\": \"description.txt\",\n",
    "        \"files\": [\n",
    "          {\n",
    "            \"path\": \"BreedLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"breed_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"ColorLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"color_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"StateLabels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"state_labels.csv\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"train.csv\",\n",
    "            \"role\": \"train\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test/sample_submission.csv\",\n",
    "            \"role\": \"sample\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test/test.csv\",\n",
    "            \"role\": \"test\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"pet_finder.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-2.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-3.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/002230dea-4.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-2.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-3.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0063f83c9-4.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/0073c33d0-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"test_metadata/00bfa5da9-1.json\",\n",
    "            \"role\": \"data\",\n",
    "            \"type\": \"tabular\"\n",
    "          },\n",
    "          {\n",
    "            \"path\": \"<omitted>\",\n",
    "            \"role\": \"bulk_files_summary\",\n",
    "            \"type\": \"summary\",\n",
    "            \"omitted_count\": 72749\n",
    "          }\n",
    "        ]\n",
    "      },\n",
    "      \"profiling_summary\": {\n",
    "        \"time_index_analysis\": \"None\",\n",
    "        \"table\": {\n",
    "          \"n\": 11994,\n",
    "          \"n_var\": 24,\n",
    "          \"memory_size\": 2302976,\n",
    "          \"record_size\": 192.010672002668,\n",
    "          \"n_cells_missing\": 1022,\n",
    "          \"p_cells_missing\": 0.0035503863042632426,\n",
    "          \"size_optimized\": true,\n",
    "          \"optimization_level\": \"aggressive\",\n",
    "          \"optimization_note\": \"All value lists removed - only counts and basic statistics retained\",\n",
    "          \"removed_sections\": 129,\n",
    "          \"optimization_strategy\": \"Minimal JSON for maximum compatibility with LLM token limits\"\n",
    "        },\n",
    "        \"variables\": {\n",
    "          \"Type\": {\n",
    "            \"n_distinct\": 2,\n",
    "            \"p_distinct\": 0.00016675004168751042,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.455060863765216,\n",
    "            \"std\": 0.49799713968618003,\n",
    "            \"variance\": 0.24800115113561672,\n",
    "            \"min\": 1,\n",
    "            \"max\": 2,\n",
    "            \"kurtosis\": -1.9677444352623312,\n",
    "            \"skewness\": 0.180509595359183,\n",
    "            \"sum\": 17452,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 1,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 2.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.34225175873229674,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Name\": {\n",
    "            \"n_distinct\": 7433,\n",
    "            \"p_distinct\": 0.6768348206155527,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 6422,\n",
    "            \"p_unique\": 0.5847750865051903,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 1012,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.08437552109388027,\n",
    "            \"count\": 10982,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 47,\n",
    "            \"mean_length\": 9.545255873247132,\n",
    "            \"median_length\": 42,\n",
    "            \"min_length\": 1,\n",
    "            \"n_characters_distinct\": 167,\n",
    "            \"n_characters\": 104826,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Age\": {\n",
    "            \"n_distinct\": 103,\n",
    "            \"p_distinct\": 0.008587627146906788,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 26,\n",
    "            \"p_unique\": 0.0021677505419376354,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 139,\n",
    "            \"mean\": 10.5200100050025,\n",
    "            \"std\": 18.333786187461325,\n",
    "            \"variance\": 336.1277159675477,\n",
    "            \"min\": 0,\n",
    "            \"max\": 255,\n",
    "            \"kurtosis\": 22.350465263684598,\n",
    "            \"skewness\": 3.8602028718592316,\n",
    "            \"sum\": 126177,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 255,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 3.0,\n",
    "            \"75%\": 12.0,\n",
    "            \"95%\": 48.0,\n",
    "            \"iqr\": 10.0,\n",
    "            \"cv\": 1.7427536835747492,\n",
    "            \"p_zeros\": 0.011589127897281974,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Breed1\": {\n",
    "            \"n_distinct\": 166,\n",
    "            \"p_distinct\": 0.013840253460063364,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 38,\n",
    "            \"p_unique\": 0.003168250792062698,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 3,\n",
    "            \"mean\": 265.1770885442721,\n",
    "            \"std\": 60.087706445934444,\n",
    "            \"variance\": 3610.5324659327916,\n",
    "            \"min\": 0,\n",
    "            \"max\": 307,\n",
    "            \"kurtosis\": 4.755229972607767,\n",
    "            \"skewness\": -2.20387682115463,\n",
    "            \"sum\": 3180534,\n",
    "            \"mad\": 41.0,\n",
    "            \"range\": 307,\n",
    "            \"5%\": 109.0,\n",
    "            \"25%\": 265.0,\n",
    "            \"50%\": 266.0,\n",
    "            \"75%\": 307.0,\n",
    "            \"95%\": 307.0,\n",
    "            \"iqr\": 42.0,\n",
    "            \"cv\": 0.2265946382313592,\n",
    "            \"p_zeros\": 0.0002501250625312656,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Breed2\": {\n",
    "            \"n_distinct\": 127,\n",
    "            \"p_distinct\": 0.010588627647156911,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 41,\n",
    "            \"p_unique\": 0.0034183758545939637,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 8572,\n",
    "            \"mean\": 74.59296314824078,\n",
    "            \"std\": 123.21206290146024,\n",
    "            \"variance\": 15181.212444433397,\n",
    "            \"min\": 0,\n",
    "            \"max\": 307,\n",
    "            \"kurtosis\": -0.6290387824541743,\n",
    "            \"skewness\": 1.1256701172233239,\n",
    "            \"sum\": 894668,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 307,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 187.0,\n",
    "            \"95%\": 307.0,\n",
    "            \"iqr\": 187.0,\n",
    "            \"cv\": 1.6517920417854604,\n",
    "            \"p_zeros\": 0.7146906786726697,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Gender\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.7773886943471735,\n",
    "            \"std\": 0.6830625785943093,\n",
    "            \"variance\": 0.46657448627590703,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.8682689723647328,\n",
    "            \"skewness\": 0.3138180442669538,\n",
    "            \"sum\": 21318,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.38430680962848984,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color1\": {\n",
    "            \"n_distinct\": 7,\n",
    "            \"p_distinct\": 0.0005836251459062865,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 2.2389528097382025,\n",
    "            \"std\": 1.7508240664915704,\n",
    "            \"variance\": 3.065384911806079,\n",
    "            \"min\": 1,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": 0.9701360640824226,\n",
    "            \"skewness\": 1.4644120191370003,\n",
    "            \"sum\": 26854,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 6,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 3.0,\n",
    "            \"95%\": 6.0,\n",
    "            \"iqr\": 2.0,\n",
    "            \"cv\": 0.7819834606948646,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color2\": {\n",
    "            \"n_distinct\": 7,\n",
    "            \"p_distinct\": 0.0005836251459062865,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 3600,\n",
    "            \"mean\": 3.2131065532766385,\n",
    "            \"std\": 2.74560357697596,\n",
    "            \"variance\": 7.538339001903187,\n",
    "            \"min\": 0,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": -1.5098445593078604,\n",
    "            \"skewness\": 0.19728631311033176,\n",
    "            \"sum\": 38538,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 7,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 6.0,\n",
    "            \"95%\": 7.0,\n",
    "            \"iqr\": 6.0,\n",
    "            \"cv\": 0.8545012533667979,\n",
    "            \"p_zeros\": 0.3001500750375188,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Color3\": {\n",
    "            \"n_distinct\": 6,\n",
    "            \"p_distinct\": 0.0005002501250625312,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 8515,\n",
    "            \"mean\": 1.8660163415040854,\n",
    "            \"std\": 2.9779154359383995,\n",
    "            \"variance\": 8.867980343600188,\n",
    "            \"min\": 0,\n",
    "            \"max\": 7,\n",
    "            \"kurtosis\": -0.8719163439987785,\n",
    "            \"skewness\": 1.0242005667700744,\n",
    "            \"sum\": 22381,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 7,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 5.0,\n",
    "            \"95%\": 7.0,\n",
    "            \"iqr\": 5.0,\n",
    "            \"cv\": 1.595867822646225,\n",
    "            \"p_zeros\": 0.7099383024845756,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"MaturitySize\": {\n",
    "            \"n_distinct\": 4,\n",
    "            \"p_distinct\": 0.00033350008337502084,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.861347340336835,\n",
    "            \"std\": 0.5451682527705674,\n",
    "            \"variance\": 0.2972084238289132,\n",
    "            \"min\": 1,\n",
    "            \"max\": 4,\n",
    "            \"kurtosis\": 0.4605567339538248,\n",
    "            \"skewness\": -0.0022545629547571404,\n",
    "            \"sum\": 22325,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 3,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.29288904921523784,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"FurLength\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.4688177422044355,\n",
    "            \"std\": 0.5992600732036002,\n",
    "            \"variance\": 0.35911263533598425,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.21261398750180094,\n",
    "            \"skewness\": 0.8873347115703182,\n",
    "            \"sum\": 17617,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.4079880409833673,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Vaccinated\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.7356178089044523,\n",
    "            \"std\": 0.6693143222526211,\n",
    "            \"variance\": 0.4479816619724855,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.8031690089363783,\n",
    "            \"skewness\": 0.36489541999744696,\n",
    "            \"sum\": 20817,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.3856346246384175,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Dewormed\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.5581123895280973,\n",
    "            \"std\": 0.69757926564668,\n",
    "            \"variance\": 0.4866168318601614,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": -0.5278377808281949,\n",
    "            \"skewness\": 0.8528579873444425,\n",
    "            \"sum\": 18688,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 1.0,\n",
    "            \"cv\": 0.44770792552259636,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Sterilized\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.9144572286143071,\n",
    "            \"std\": 0.5679268514311735,\n",
    "            \"variance\": 0.32254090857652623,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": 0.027778855084581444,\n",
    "            \"skewness\": -0.011743205284064464,\n",
    "            \"sum\": 22962,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 2.0,\n",
    "            \"95%\": 3.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.29665162686462393,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Health\": {\n",
    "            \"n_distinct\": 3,\n",
    "            \"p_distinct\": 0.0002501250625312656,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.0363515090878772,\n",
    "            \"std\": 0.19925458145199001,\n",
    "            \"variance\": 0.03970238822960773,\n",
    "            \"min\": 1,\n",
    "            \"max\": 3,\n",
    "            \"kurtosis\": 36.3757011367912,\n",
    "            \"skewness\": 5.813841143851706,\n",
    "            \"sum\": 12430,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 2,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 1.0,\n",
    "            \"95%\": 1.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.19226544247266036,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Quantity\": {\n",
    "            \"n_distinct\": 19,\n",
    "            \"p_distinct\": 0.001584125396031349,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 1,\n",
    "            \"p_unique\": 8.337502084375521e-05,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 1.5886276471569118,\n",
    "            \"std\": 1.508592604952439,\n",
    "            \"variance\": 2.2758516477171855,\n",
    "            \"min\": 1,\n",
    "            \"max\": 20,\n",
    "            \"kurtosis\": 36.05480385473918,\n",
    "            \"skewness\": 4.736983141694582,\n",
    "            \"sum\": 19054,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 19,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 1.0,\n",
    "            \"50%\": 1.0,\n",
    "            \"75%\": 1.0,\n",
    "            \"95%\": 5.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 0.9496200117455418,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Fee\": {\n",
    "            \"n_distinct\": 71,\n",
    "            \"p_distinct\": 0.00591962647990662,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 23,\n",
    "            \"p_unique\": 0.00191762547940637,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 10108,\n",
    "            \"mean\": 21.39803234950809,\n",
    "            \"std\": 79.7781620492847,\n",
    "            \"variance\": 6364.555139961931,\n",
    "            \"min\": 0,\n",
    "            \"max\": 3000,\n",
    "            \"kurtosis\": 217.67204897705238,\n",
    "            \"skewness\": 9.610892401231167,\n",
    "            \"sum\": 256648,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 3000,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 0.0,\n",
    "            \"95%\": 150.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 3.7282943004392033,\n",
    "            \"p_zeros\": 0.8427547106886777,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"State\": {\n",
    "            \"n_distinct\": 14,\n",
    "            \"p_distinct\": 0.001167250291812573,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 0,\n",
    "            \"mean\": 41345.91270635318,\n",
    "            \"std\": 32.389300021821896,\n",
    "            \"variance\": 1049.0667559035917,\n",
    "            \"min\": 41324,\n",
    "            \"max\": 41415,\n",
    "            \"kurtosis\": -0.7659264365139249,\n",
    "            \"skewness\": 1.0996311768801166,\n",
    "            \"sum\": 495902877,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 91,\n",
    "            \"5%\": 41326.0,\n",
    "            \"25%\": 41326.0,\n",
    "            \"50%\": 41326.0,\n",
    "            \"75%\": 41401.0,\n",
    "            \"95%\": 41401.0,\n",
    "            \"iqr\": 75.0,\n",
    "            \"cv\": 0.0007833736856133057,\n",
    "            \"p_zeros\": 0.0,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"RescuerID\": {\n",
    "            \"n_distinct\": 4789,\n",
    "            \"p_distinct\": 0.3992829748207437,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 3315,\n",
    "            \"p_unique\": 0.2763881940970485,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 32,\n",
    "            \"mean_length\": 32.0,\n",
    "            \"median_length\": 32,\n",
    "            \"min_length\": 32,\n",
    "            \"n_characters_distinct\": 16,\n",
    "            \"n_characters\": 383808,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"VideoAmt\": {\n",
    "            \"n_distinct\": 9,\n",
    "            \"p_distinct\": 0.0007503751875937969,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 2,\n",
    "            \"p_unique\": 0.00016675004168751042,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 11535,\n",
    "            \"mean\": 0.05694513923628481,\n",
    "            \"std\": 0.3443516269990526,\n",
    "            \"variance\": 0.11857804301689463,\n",
    "            \"min\": 0,\n",
    "            \"max\": 8,\n",
    "            \"kurtosis\": 114.37392383368731,\n",
    "            \"skewness\": 9.129144018384311,\n",
    "            \"sum\": 683,\n",
    "            \"mad\": 0.0,\n",
    "            \"range\": 8,\n",
    "            \"5%\": 0.0,\n",
    "            \"25%\": 0.0,\n",
    "            \"50%\": 0.0,\n",
    "            \"75%\": 0.0,\n",
    "            \"95%\": 0.0,\n",
    "            \"iqr\": 0.0,\n",
    "            \"cv\": 6.04707674118102,\n",
    "            \"p_zeros\": 0.9617308654327164,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"Description\": {\n",
    "            \"n_distinct\": 11285,\n",
    "            \"p_distinct\": 0.9416722296395194,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 11041,\n",
    "            \"p_unique\": 0.9213117489986649,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 10,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0008337502084375521,\n",
    "            \"count\": 11984,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 6664,\n",
    "            \"mean_length\": 338.8663217623498,\n",
    "            \"median_length\": 1377,\n",
    "            \"min_length\": 1,\n",
    "            \"n_characters_distinct\": 1448,\n",
    "            \"n_characters\": 4060974,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"PetID\": {\n",
    "            \"n_distinct\": 11994,\n",
    "            \"p_distinct\": 1.0,\n",
    "            \"is_unique\": true,\n",
    "            \"n_unique\": 11994,\n",
    "            \"p_unique\": 1.0,\n",
    "            \"type\": \"Text\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"max_length\": 9,\n",
    "            \"mean_length\": 9.0,\n",
    "            \"median_length\": 9,\n",
    "            \"min_length\": 9,\n",
    "            \"n_characters_distinct\": 16,\n",
    "            \"n_characters\": 107946,\n",
    "            \"n_block_alias\": 1,\n",
    "            \"n_scripts\": 1,\n",
    "            \"n_category\": 1,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"PhotoAmt\": {\n",
    "            \"n_distinct\": 31,\n",
    "            \"p_distinct\": 0.0025846256461564115,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 273,\n",
    "            \"mean\": 3.8907787226946806,\n",
    "            \"std\": 3.4946436139785306,\n",
    "            \"variance\": 12.212533988720924,\n",
    "            \"min\": 0.0,\n",
    "            \"max\": 30.0,\n",
    "            \"kurtosis\": 12.896628429989528,\n",
    "            \"skewness\": 2.8883393469750502,\n",
    "            \"sum\": 46666.0,\n",
    "            \"mad\": 2.0,\n",
    "            \"range\": 30.0,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 3.0,\n",
    "            \"75%\": 5.0,\n",
    "            \"95%\": 10.0,\n",
    "            \"iqr\": 3.0,\n",
    "            \"cv\": 0.8981861635035893,\n",
    "            \"p_zeros\": 0.02276138069034517,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          },\n",
    "          \"AdoptionSpeed\": {\n",
    "            \"n_distinct\": 5,\n",
    "            \"p_distinct\": 0.00041687510421877606,\n",
    "            \"is_unique\": false,\n",
    "            \"n_unique\": 0,\n",
    "            \"p_unique\": 0.0,\n",
    "            \"type\": \"Numeric\",\n",
    "            \"hashable\": true,\n",
    "            \"ordering\": true,\n",
    "            \"n_missing\": 0,\n",
    "            \"n\": 11994,\n",
    "            \"p_missing\": 0.0,\n",
    "            \"count\": 11994,\n",
    "            \"memory_size\": 96080,\n",
    "            \"n_negative\": 0,\n",
    "            \"p_negative\": 0.0,\n",
    "            \"n_infinite\": 0,\n",
    "            \"n_zeros\": 328,\n",
    "            \"mean\": 2.516341504085376,\n",
    "            \"std\": 1.1772495657598065,\n",
    "            \"variance\": 1.385916540081653,\n",
    "            \"min\": 0,\n",
    "            \"max\": 4,\n",
    "            \"kurtosis\": -1.1393137463852208,\n",
    "            \"skewness\": -0.1549212733703575,\n",
    "            \"sum\": 30181,\n",
    "            \"mad\": 1.0,\n",
    "            \"range\": 4,\n",
    "            \"5%\": 1.0,\n",
    "            \"25%\": 2.0,\n",
    "            \"50%\": 2.0,\n",
    "            \"75%\": 4.0,\n",
    "            \"95%\": 4.0,\n",
    "            \"iqr\": 2.0,\n",
    "            \"cv\": 0.4678417312787224,\n",
    "            \"p_zeros\": 0.02734700683675171,\n",
    "            \"p_infinite\": 0.0,\n",
    "            \"monotonic_increase\": false,\n",
    "            \"monotonic_decrease\": false,\n",
    "            \"monotonic_increase_strict\": false,\n",
    "            \"monotonic_decrease_strict\": false,\n",
    "            \"monotonic\": 0,\n",
    "            \"cast_type\": \"None\"\n",
    "          }\n",
    "        },\n",
    "        \"scatter\": {},\n",
    "        \"correlations\": {}\n",
    "      },\n",
    "      \"task_definition\": {\n",
    "        \"description_summary\": \"This dataset contains information about pets listed on PetFinder.my, including tabular data, text descriptions, and image metadata. The goal is to predict the 'AdoptionSpeed' of pets, which indicates how quickly a pet is adopted, to help improve pet profiles and reduce animal suffering.\",\n",
    "        \"note\": \"The target variable 'AdoptionSpeed' is an ordinal categorical variable with 5 possible ratings (0-4). The primary evaluation metric is quadratic weighted kappa, which measures agreement between actual and predicted ratings.\",\n",
    "        \"task_type\": \"multi_class_classification\",\n",
    "        \"target_columns\": [\n",
    "          \"AdoptionSpeed\"\n",
    "        ],\n",
    "        \"evaluation_metric\": \"quadratic_weighted_kappa\"\n",
    "      }\n",
    "    }\n",
    "\n",
    "    # Load the trained model\n",
    "    trained_model = None\n",
    "    if MODEL_PATH.exists():\n",
    "        try:\n",
    "            trained_model = joblib.load(MODEL_PATH)\n",
    "            print(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model from {MODEL_PATH}: {e}\")\n",
    "            print(\"Attempting to re-train the model for prediction (this might take time)...\")\n",
    "            # If model loading fails, re-run the training part of the previous stage\n",
    "            # This is a fallback for robustness, but ideally, the model should be loaded.\n",
    "            from __main__ import main as train_main # Assuming the training main is accessible\n",
    "            trained_model = train_main()\n",
    "    else:\n",
    "        print(f\"Model file not found at {MODEL_PATH}. Attempting to re-train the model for prediction (this might take time)...\")\n",
    "        from __main__ import main as train_main\n",
    "        trained_model = train_main()\n",
    "\n",
    "    if trained_model is None:\n",
    "        raise RuntimeError(\"Failed to load or train a model. Cannot proceed with prediction.\")\n",
    "\n",
    "    # Load test data\n",
    "    test_df = pd.read_csv(TEST_CSV_PATH)\n",
    "    sample_submission_df = pd.read_csv(SAMPLE_SUBMISSION_PATH)\n",
    "\n",
    "    # --- Re-apply Preprocessing steps to test_df ---\n",
    "    # This section must mirror the preprocessing logic in the training script.\n",
    "    # It's crucial to use the *same* scalers, encoders, and TF-IDF vectorizers\n",
    "    # that were fitted on the training data. In a real pipeline, these would be\n",
    "    # saved and loaded alongside the model. For this exercise, we'll re-initialize\n",
    "    # and re-fit on the training data (which is available in the main function\n",
    "    # of the previous stage if called as a fallback).\n",
    "\n",
    "    # Identify column types based on metadata and common sense\n",
    "    numerical_cols = []\n",
    "    categorical_cols = []\n",
    "    text_cols = []\n",
    "    id_cols = []\n",
    "    target_col = dataset_metadata_json['task_definition']['target_columns'][0]\n",
    "\n",
    "    # Load train_df to fit preprocessors\n",
    "    train_df_for_preprocessors = pd.read_csv(BASE_PATH / 'train.csv')\n",
    "\n",
    "    for col, meta in dataset_metadata_json['profiling_summary']['variables'].items():\n",
    "        if col == target_col:\n",
    "            continue\n",
    "        if meta['type'] == 'Numeric':\n",
    "            if meta['n_distinct'] < 20 and meta['n_distinct'] / meta['n'] < 0.01:\n",
    "                categorical_cols.append(col)\n",
    "            else:\n",
    "                numerical_cols.append(col)\n",
    "        elif meta['type'] == 'Text':\n",
    "            if meta['is_unique'] or col.endswith('ID'):\n",
    "                id_cols.append(col)\n",
    "            elif meta['mean_length'] > 50 or col == 'Description':\n",
    "                text_cols.append(col)\n",
    "            else:\n",
    "                categorical_cols.append(col)\n",
    "\n",
    "    # Handle 'Name' as a text column if its mean length is high, otherwise categorical\n",
    "    if 'Name' in categorical_cols:\n",
    "        categorical_cols.remove('Name')\n",
    "        text_cols.append('Name')\n",
    "\n",
    "    # Ensure target column is not in feature lists for preprocessor fitting\n",
    "    if target_col in numerical_cols: numerical_cols.remove(target_col)\n",
    "    if target_col in categorical_cols: categorical_cols.remove(target_col)\n",
    "    if target_col in text_cols: text_cols.remove(target_col)\n",
    "\n",
    "    # Impute missing values (fit on train, transform on test)\n",
    "    numerical_imputer = SimpleImputer(strategy='median')\n",
    "    train_df_for_preprocessors[numerical_cols] = numerical_imputer.fit_transform(train_df_for_preprocessors[numerical_cols])\n",
    "    test_df[numerical_cols] = numerical_imputer.transform(test_df[numerical_cols])\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        categorical_imputer = SimpleImputer(strategy='most_frequent')\n",
    "        # Fit on a copy to avoid modifying the original train_df_for_preprocessors if it's used elsewhere\n",
    "        train_df_for_preprocessors[col] = categorical_imputer.fit_transform(train_df_for_preprocessors[[col]])\n",
    "        test_df[col] = categorical_imputer.transform(test_df[[col]])\n",
    "\n",
    "    for col in text_cols:\n",
    "        train_df_for_preprocessors[col].fillna('', inplace=True)\n",
    "        test_df[col].fillna('', inplace=True)\n",
    "\n",
    "    # One-hot encode categorical columns (fit on train, transform on test)\n",
    "    encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False, drop='first')\n",
    "    encoded_train_cols = encoder.fit_transform(train_df_for_preprocessors[categorical_cols])\n",
    "    encoded_test_cols = encoder.transform(test_df[categorical_cols])\n",
    "\n",
    "    encoded_feature_names = encoder.get_feature_names_out(categorical_cols)\n",
    "    encoded_train_df = pd.DataFrame(encoded_train_cols, columns=encoded_feature_names, index=train_df_for_preprocessors.index)\n",
    "    encoded_test_df = pd.DataFrame(encoded_test_cols, columns=encoded_feature_names, index=test_df.index)\n",
    "\n",
    "    train_df_for_preprocessors = pd.concat([train_df_for_preprocessors.drop(columns=categorical_cols), encoded_train_df], axis=1)\n",
    "    test_df = pd.concat([test_df.drop(columns=categorical_cols), encoded_test_df], axis=1)\n",
    "\n",
    "    # TF-IDF for text columns (fit on train, transform on test)\n",
    "    tfidf_vectorizers = {}\n",
    "    for col in text_cols:\n",
    "        tfidf = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "        train_text_features = tfidf.fit_transform(train_df_for_preprocessors[col])\n",
    "        test_text_features = tfidf.transform(test_df[col])\n",
    "\n",
    "        train_text_df = pd.DataFrame(train_text_features.toarray(), columns=[f'{col}_tfidf_{i}' for i in range(train_text_features.shape[1])], index=train_df_for_preprocessors.index)\n",
    "        test_text_df = pd.DataFrame(test_text_features.toarray(), columns=[f'{col}_tfidf_{i}' for i in range(test_text_features.shape[1])], index=test_df.index)\n",
    "\n",
    "        train_df_for_preprocessors = pd.concat([train_df_for_preprocessors.drop(columns=[col]), train_text_df], axis=1)\n",
    "        test_df = pd.concat([test_df.drop(columns=[col]), test_text_df], axis=1)\n",
    "        tfidf_vectorizers[col] = tfidf\n",
    "\n",
    "    # Scale numerical features (fit on train, transform on test)\n",
    "    scaler = StandardScaler()\n",
    "    train_df_for_preprocessors[numerical_cols] = scaler.fit_transform(train_df_for_preprocessors[numerical_cols])\n",
    "    test_df[numerical_cols] = scaler.transform(test_df[numerical_cols])\n",
    "\n",
    "    # --- Image Preprocessing (Feature Extraction) ---\n",
    "    # This part must also mirror the training script.\n",
    "    try:\n",
    "        image_feature_extractor = hub.KerasLayer(\n",
    "            \"https://tfhub.dev/google/efficientnet/b0/feature-vector/1\",\n",
    "            trainable=False\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load TensorFlow Hub model for prediction. Skipping image feature extraction: {e}\")\n",
    "        image_feature_extractor = None\n",
    "\n",
    "    IMG_SIZE = (224, 224)\n",
    "\n",
    "    def load_and_preprocess_image(image_path):\n",
    "        img = tf.io.read_file(image_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = tf.cast(img, tf.float32) / 255.0\n",
    "        return img\n",
    "\n",
    "    def get_image_paths(pet_id, base_dir, photo_amt):\n",
    "        paths = []\n",
    "        for i in range(photo_amt):\n",
    "            img_path = base_dir / f\"{pet_id}-{i+1}.jpg\"\n",
    "            if img_path.exists():\n",
    "                paths.append(str(img_path))\n",
    "        return paths\n",
    "\n",
    "    def extract_image_features(df, base_image_dir, image_feature_extractor):\n",
    "        if image_feature_extractor is None:\n",
    "            dummy_features = np.zeros((len(df), 1280))\n",
    "            feature_df = pd.DataFrame(dummy_features, index=df['PetID'])\n",
    "            feature_df.columns = [f'img_feat_{i}' for i in range(feature_df.shape[1])]\n",
    "            return feature_df\n",
    "\n",
    "        all_pet_features = []\n",
    "        pet_ids_with_features = []\n",
    "\n",
    "        for index, row in df.iterrows():\n",
    "            pet_id = row['PetID']\n",
    "            photo_amt = int(row['PhotoAmt'])\n",
    "            image_paths = get_image_paths(pet_id, base_image_dir, photo_amt)\n",
    "\n",
    "            if image_paths:\n",
    "                images = []\n",
    "                for path in image_paths:\n",
    "                    try:\n",
    "                        images.append(load_and_preprocess_image(path))\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error loading image {path}: {e}\")\n",
    "                        continue\n",
    "\n",
    "                if images:\n",
    "                    images_tensor = tf.stack(images)\n",
    "                    features = image_feature_extractor(images_tensor)\n",
    "                    aggregated_features = tf.reduce_mean(features, axis=0).numpy()\n",
    "                    all_pet_features.append(aggregated_features)\n",
    "                    pet_ids_with_features.append(pet_id)\n",
    "                else:\n",
    "                    all_pet_features.append(np.zeros(1280))\n",
    "                    pet_ids_with_features.append(pet_id)\n",
    "            else:\n",
    "                all_pet_features.append(np.zeros(1280))\n",
    "                pet_ids_with_features.append(pet_id)\n",
    "\n",
    "        feature_df = pd.DataFrame(all_pet_features, index=pet_ids_with_features)\n",
    "        feature_df.columns = [f'img_feat_{i}' for i in range(feature_df.shape[1])]\n",
    "        return feature_df\n",
    "\n",
    "    # Temporarily store PetID for merging image features\n",
    "    test_pet_ids_original = test_df['PetID']\n",
    "\n",
    "    # Extract image features for test data\n",
    "    print(\"Extracting image features for test data...\")\n",
    "    test_image_features_df = extract_image_features(test_df[['PetID', 'PhotoAmt']], TEST_IMAGE_DIR, image_feature_extractor)\n",
    "    test_df = test_df.set_index('PetID').join(test_image_features_df, how='left').reset_index()\n",
    "\n",
    "    # Drop PetID and RescuerID as they are identifiers and not direct features\n",
    "    if 'PetID' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['PetID'])\n",
    "    if 'RescuerID' in test_df.columns:\n",
    "        test_df = test_df.drop(columns=['RescuerID'])\n",
    "    if 'PetID' in train_df_for_preprocessors.columns: # Also drop from train_df_for_preprocessors for column alignment\n",
    "        train_df_for_preprocessors = train_df_for_preprocessors.drop(columns=['PetID'])\n",
    "    if 'RescuerID' in train_df_for_preprocessors.columns:\n",
    "        train_df_for_preprocessors = train_df_for_preprocessors.drop(columns=['RescuerID'])\n",
    "\n",
    "    # Align columns between train and test after all transformations\n",
    "    # This is crucial for consistent feature sets, especially after OHE and TF-IDF\n",
    "    X_train_full_cols = set(train_df_for_preprocessors.drop(columns=[target_col]).columns)\n",
    "    X_test_processed_cols = set(test_df.columns)\n",
    "\n",
    "    # Add missing columns to test_df, fill with 0\n",
    "    missing_in_test = list(X_train_full_cols - X_test_processed_cols)\n",
    "    for col in missing_in_test:\n",
    "        test_df[col] = 0\n",
    "\n",
    "    # Remove extra columns from test_df that are not in X_train_full_cols\n",
    "    extra_in_test = list(X_test_processed_cols - X_train_full_cols)\n",
    "    test_df = test_df.drop(columns=extra_in_test)\n",
    "\n",
    "    # Ensure column order is the same\n",
    "    test_df_processed = test_df[list(X_train_full_cols)]\n",
    "\n",
    "    print(\"\\nTest data preprocessing complete.\")\n",
    "    print(f\"Processed test data shape: {test_df_processed.shape}\")\n",
    "    print(f\"Processed test columns: {test_df_processed.columns.tolist()}\")\n",
    "\n",
    "    # Generate predictions\n",
    "    print(\"\\nGenerating predictions...\")\n",
    "    # For multi-class classification, predict_proba is often preferred for submission\n",
    "    # if the competition uses metrics like logloss or requires probabilities.\n",
    "    # For quadratic weighted kappa, direct class predictions are needed.\n",
    "    # Let's generate class predictions as the primary output.\n",
    "    predictions = trained_model.predict(test_df_processed)\n",
    "\n",
    "    # Create submission DataFrame\n",
    "    submission_df = pd.DataFrame({'PetID': test_pet_ids_original, 'AdoptionSpeed': predictions})\n",
    "\n",
    "    # Save submission file\n",
    "    submission_df.to_csv(SUBMISSION_PATH, index=False)\n",
    "    print(f\"Submission file saved to {SUBMISSION_PATH}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
