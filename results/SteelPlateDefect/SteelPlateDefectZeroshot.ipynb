{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRpMi1o4qG9m",
        "outputId": "8d83b84b-2d51-407e-b63d-220eb15e7be7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting the Multi-Label Steel Plate Fault Prediction task...\n",
            "Data loaded successfully from 'train.csv'.\n",
            "Dataset shape: (19219, 35)\n",
            "First 5 rows of the dataset:\n",
            "   id  X_Minimum  X_Maximum  Y_Minimum  Y_Maximum  Pixels_Areas  X_Perimeter  \\\n",
            "0   0        584        590     909972     909977            16            8   \n",
            "1   1        808        816     728350     728372           433           20   \n",
            "2   2         39        192    2212076    2212144         11388          705   \n",
            "3   3        781        789    3353146    3353173           210           16   \n",
            "4   4       1540       1560     618457     618502           521           72   \n",
            "\n",
            "   Y_Perimeter  Sum_of_Luminosity  Minimum_of_Luminosity  ...  \\\n",
            "0            5               2274                    113  ...   \n",
            "1           54              44478                     70  ...   \n",
            "2          420            1311391                     29  ...   \n",
            "3           29               3202                    114  ...   \n",
            "4           67              48231                     82  ...   \n",
            "\n",
            "   Orientation_Index  Luminosity_Index  SigmoidOfAreas  Pastry  Z_Scratch  \\\n",
            "0            -0.5000           -0.0104          0.1417       0          0   \n",
            "1             0.7419           -0.2997          0.9491       0          0   \n",
            "2            -0.0105           -0.0944          1.0000       0          0   \n",
            "3             0.6667           -0.0402          0.4025       0          0   \n",
            "4             0.9158           -0.2455          0.9998       0          0   \n",
            "\n",
            "   K_Scatch  Stains  Dirtiness  Bumps  Other_Faults  \n",
            "0         0       1          0      0             0  \n",
            "1         0       0          0      0             1  \n",
            "2         1       0          0      0             0  \n",
            "3         1       0          0      0             0  \n",
            "4         0       0          0      0             1  \n",
            "\n",
            "[5 rows x 35 columns]\n",
            "Numerical features scaled using StandardScaler.\n",
            "Data split into training (15375 samples) and testing (3844 samples) sets.\n",
            "Training the Multi-Output Logistic Regression model...\n",
            "Model training complete.\n",
            "\n",
            "--- Evaluation Metrics ---\n",
            "ROC AUC for Pastry: 0.8656\n",
            "ROC AUC for Z_Scratch: 0.9194\n",
            "ROC AUC for K_Scatch: 0.9821\n",
            "ROC AUC for Stains: 0.9860\n",
            "ROC AUC for Dirtiness: 0.8499\n",
            "ROC AUC for Bumps: 0.7609\n",
            "ROC AUC for Other_Faults: 0.6832\n",
            "\n",
            "Average ROC AUC across all defect categories: 0.8639\n",
            "Accuracy (Exact Match Ratio): 0.3392\n",
            "Log Loss: 0.2344\n",
            "F1-macro: 0.3780\n",
            "F1-weighted: 0.3944\n",
            "ROC AUC (macro average): 0.8639\n",
            "ROC AUC (weighted average): 0.7998\n",
            "\n",
            "--- Program finished successfully ---\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.multioutput import MultiOutputClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    roc_auc_score,\n",
        "    accuracy_score,\n",
        "    log_loss,\n",
        "    f1_score\n",
        ")\n",
        "import warnings\n",
        "\n",
        "# Suppress all warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "def run_ml_task():\n",
        "    \"\"\"\n",
        "    Executes the end-to-end machine learning task for steel plate fault prediction.\n",
        "    \"\"\"\n",
        "    print(\"Starting the Multi-Label Steel Plate Fault Prediction task...\")\n",
        "\n",
        "    # Define the target columns\n",
        "    target_columns = ['Pastry', 'Z_Scratch', 'K_Scatch', 'Stains', 'Dirtiness', 'Bumps', 'Other_Faults']\n",
        "\n",
        "    # --- 1. Load Data ---\n",
        "    try:\n",
        "        df = pd.read_csv('train.csv')\n",
        "        print(\"Data loaded successfully from 'train.csv'.\")\n",
        "        print(f\"Dataset shape: {df.shape}\")\n",
        "        print(\"First 5 rows of the dataset:\")\n",
        "        print(df.head())\n",
        "    except FileNotFoundError:\n",
        "        print(\"Error: 'train.csv' not found. Please ensure the file is in the same directory.\")\n",
        "        return\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return\n",
        "\n",
        "    # Separate features (X) and targets (y)\n",
        "    X = df.drop(columns=target_columns)\n",
        "    y = df[target_columns]\n",
        "\n",
        "    # --- 2. Data Preprocessing ---\n",
        "    # Identify numerical and categorical features (assuming all other columns are numerical for now)\n",
        "    # [Suy luận] Based on the problem description, features are numerical and/or categorical.\n",
        "    # For simplicity, we'll assume all non-target columns are numerical and need scaling.\n",
        "    # If there were explicit categorical columns, one-hot encoding would be needed.\n",
        "    numerical_features = X.select_dtypes(include=np.number).columns.tolist()\n",
        "    # categorical_features = X.select_dtypes(include='object').columns.tolist() # Uncomment and use if you have categorical features\n",
        "\n",
        "    # Handle missing values (simple imputation for numerical features)\n",
        "    # [Suy luận] If there are missing values, a simple strategy like mean imputation is used.\n",
        "    # For robust solutions, more sophisticated imputation methods or handling would be needed.\n",
        "    for col in numerical_features:\n",
        "        if X[col].isnull().any():\n",
        "            X[col] = X[col].fillna(X[col].mean())\n",
        "            print(f\"Missing values in column '{col}' imputed with mean.\")\n",
        "\n",
        "    # Scale numerical features\n",
        "    scaler = StandardScaler()\n",
        "    X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
        "    print(\"Numerical features scaled using StandardScaler.\")\n",
        "\n",
        "    # --- 3. Split Data ---\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    print(f\"Data split into training ({X_train.shape[0]} samples) and testing ({X_test.shape[0]} samples) sets.\")\n",
        "\n",
        "    # --- 4. Model Training ---\n",
        "    # Using Logistic Regression with MultiOutputClassifier for multi-label classification\n",
        "    # Logistic Regression is a good baseline and provides probability estimates.\n",
        "    # Using 'liblinear' solver for smaller datasets or L1 regularization.\n",
        "    # 'ovr' (One-vs-Rest) strategy is default for MultiOutputClassifier when underlying\n",
        "    # classifier doesn't natively support multi-label.\n",
        "    base_classifier = LogisticRegression(solver='liblinear', random_state=42, n_jobs=-1)\n",
        "    model = MultiOutputClassifier(base_classifier)\n",
        "\n",
        "    print(\"Training the Multi-Output Logistic Regression model...\")\n",
        "    model.fit(X_train, y_train)\n",
        "    print(\"Model training complete.\")\n",
        "\n",
        "    # --- 5. Prediction ---\n",
        "    # Predict probabilities for each defect type\n",
        "    y_pred_proba = model.predict_proba(X_test)\n",
        "\n",
        "    # predict_proba returns a list of arrays for MultiOutputClassifier\n",
        "    # We need to reshape it into a single 2D array (n_samples, n_labels)\n",
        "    # Each inner array is (n_samples, n_classes), we need the probability of the positive class (index 1)\n",
        "    y_pred_proba_combined = np.column_stack([p[:, 1] for p in y_pred_proba])\n",
        "\n",
        "    # For other metrics that require binary predictions, we need to threshold probabilities (e.g., at 0.5)\n",
        "    y_pred_binary = (y_pred_proba_combined > 0.5).astype(int)\n",
        "\n",
        "    # --- 6. Evaluation ---\n",
        "    print(\"\\n--- Evaluation Metrics ---\")\n",
        "\n",
        "    # Primary Evaluation Metric: Average ROC AUC across all 7 defect categories\n",
        "    # roc_auc_score for multilabel: use average='macro' or 'weighted'\n",
        "    # 'macro' computes the metric independently for each class, and then takes the average (unweighted).\n",
        "    # 'weighted' accounts for label imbalance by weighting the average by the support (true instances for each label).\n",
        "    # Since the problem statement doesn't specify weighting, 'macro' is a common default for unweighted average.\n",
        "    # However, 'roc_auc_ovr_weighted' suggests we should try weighted.\n",
        "\n",
        "    # AUC score for each label\n",
        "    auc_scores_per_label = []\n",
        "    for i, label in enumerate(target_columns):\n",
        "        try:\n",
        "            auc_score = roc_auc_score(y_test[label], y_pred_proba_combined[:, i])\n",
        "            auc_scores_per_label.append(auc_score)\n",
        "            print(f\"ROC AUC for {label}: {auc_score:.4f}\")\n",
        "        except ValueError as e:\n",
        "            # [Chưa xác minh] This can happen if a class has only one label in y_test\n",
        "            print(f\"[Warning] Could not calculate ROC AUC for '{label}': {e}. Skipping this label for individual AUC.\")\n",
        "            # Append NaN or 0 to not skew the average if it's truly not calculable\n",
        "            # For robust averaging, it's better to exclude or handle these cases.\n",
        "            # For simplicity, we'll append 0 here, but a more robust approach might be to filter.\n",
        "            auc_scores_per_label.append(np.nan) # Append NaN to exclude from mean later\n",
        "\n",
        "    # Calculate the average ROC AUC (excluding NaNs)\n",
        "    average_roc_auc = np.nanmean(auc_scores_per_label)\n",
        "    print(f\"\\nAverage ROC AUC across all defect categories: {average_roc_auc:.4f}\")\n",
        "\n",
        "    # Additional Metrics\n",
        "    # Accuracy (Exact Match Ratio for multi-label)\n",
        "    # accuracy_score with normalize=True gives exact match ratio\n",
        "    accuracy = accuracy_score(y_test, y_pred_binary)\n",
        "    print(f\"Accuracy (Exact Match Ratio): {accuracy:.4f}\")\n",
        "\n",
        "    # Log Loss\n",
        "    # log_loss is computed for each label and then averaged\n",
        "    # [Suy luận] For multilabel, sklearn's log_loss requires flattened arrays or iterating over labels.\n",
        "    # MultiOutputClassifier's predict_proba often gives a list of arrays.\n",
        "    logloss_per_label = []\n",
        "    for i, label in enumerate(target_columns):\n",
        "        # Flatten y_test[label] to match the expected 1D input for log_loss\n",
        "        logloss_per_label.append(log_loss(y_test[label], y_pred_proba_combined[:, i]))\n",
        "    average_log_loss = np.mean(logloss_per_label)\n",
        "    print(f\"Log Loss: {average_log_loss:.4f}\")\n",
        "\n",
        "    # F1-macro and F1-weighted\n",
        "    # 'macro': Calculate metrics for each label, and find their unweighted mean.\n",
        "    # 'weighted': Calculate metrics for each label, and find their average weighted by support.\n",
        "    f1_macro = f1_score(y_test, y_pred_binary, average='macro', zero_division=0)\n",
        "    f1_weighted = f1_score(y_test, y_pred_binary, average='weighted', zero_division=0)\n",
        "    print(f\"F1-macro: {f1_macro:.4f}\")\n",
        "    print(f\"F1-weighted: {f1_weighted:.4f}\")\n",
        "\n",
        "    # ROC AUC OvR and ROC AUC OvR weighted\n",
        "    # For multi-label, 'roc_auc_score' with 'multi_class=\"ovr\"' is not directly applicable\n",
        "    # as it's meant for multi-class where each sample belongs to only one class.\n",
        "    # For multi-label, we typically calculate AUC for each binary problem and then average.\n",
        "    # The 'average' parameter in roc_auc_score already handles this for multi-label y_true and y_score.\n",
        "    roc_auc_ovr = roc_auc_score(y_test, y_pred_proba_combined, average='macro')\n",
        "    roc_auc_ovr_weighted = roc_auc_score(y_test, y_pred_proba_combined, average='weighted')\n",
        "    print(f\"ROC AUC (macro average): {roc_auc_ovr:.4f}\")\n",
        "    print(f\"ROC AUC (weighted average): {roc_auc_ovr_weighted:.4f}\")\n",
        "\n",
        "    print(\"\\n--- Program finished successfully ---\")\n",
        "\n",
        "# Execute the program\n",
        "if __name__ == \"__main__\":\n",
        "    run_ml_task()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNM58k_yqR9A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
