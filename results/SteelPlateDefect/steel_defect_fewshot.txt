You are an expert programmer with years of experience in writing codes for machine learning (ML) tasks on Kaggle. Your goal is to write an end-to-end executable program that can solve the ML task based on the provided instructions. The user is trying to create a Python program for a supervised machine learning task. Your goal is to assist the user in creating the program. The user might provide the following information for the task:

The user is trying to create a Python program for a supervised machine learning task. Your goal is to assist the user in creating the program. The user might provide the following information for the task:

1. A description of the input data:-- The input data is tabular, consisting of a set of numerical and/or categorical features generated from a model trained on the original Steel Plates Faults dataset. These features describe the characteristics of steel plates.

2. A description of the output data:-- The output consists of 7 independent probability values,one for each of the 7 possible defect types. The 7 defect types are: Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, and Other_Faults. Each of these is a binary target (1 if the defect is present, 0 if not).

3. The task objective:-- For each steel plate sample, predict the probability of each of the 7 defect types occurring. Since a single plate can have multiple defects simultaneously, this is a multi-label classification problem.

4. The evaluation metrics:-- The evaluation metric is the average Area Under the ROC Curve (AUC) across all 7 defect categories.

5. A description of the available files:--
- `train.csv`: The training dataset, which contains the input features and the 7 binary target columns (Pastry, Z_Scratch, K_Scatch, Stains, Dirtiness, Bumps, Other_Faults).
- `test.csv`: The test dataset, which contains the input features but not the target columns. The goal is to predict the probabilities for these samples.
- `sample_submission.csv`: An example submission file showing the required format, which includes an `id` column and a probability column for each of the 7 defects.
Run on Kaggle, GPU T4x2
split the train to evaluate by these folowing metrics: accuracy log_loss f1_macro f1_weighted roc_auc_ovr roc_auc_ovr_weighted
Example: 
import numpy as np
import pandas as pd
import tensorflow_decision_forests as tfdf
import tensorflow as tf
import matplotlib.pyplot as plt
print(f"TensorFlow Decision Forests version: {tfdf.__version__}")
train_pd = pd.read_csv("/kaggle/input/playground-series-s3e18/train.csv")
test_pd = pd.read_csv("/kaggle/input/playground-series-s3e18/test.csv")
primary_labels = ["EC1", "EC2"]
secondary_labels = ["EC3", "EC4", "EC5", "EC6"]
non_feature_columns = ["id"]
def to_tf_dataset(pd_dataset: pd.DataFrame, label_keys: list[str], droped_features: list[str]) -> tf.data.Dataset:
    features = dict(pd_dataset.drop(label_keys + droped_features, axis=1))
    labels = dict(pd_dataset[label_keys])
    return tf.data.Dataset.from_tensor_slices((features, labels)).batch(100)

train_tf = to_tf_dataset(train_pd, label_keys=primary_labels, droped_features=non_feature_columns + secondary_labels)
test_tf = to_tf_dataset(test_pd, label_keys=[], droped_features=non_feature_columns)
model = tfdf.keras.GradientBoostedTreesModel(
    multitask=[tfdf.keras.MultiTaskItem(label=l, task=tfdf.keras.Task.CLASSIFICATION) for l in primary_labels],
    verbose=1,
)
model.fit(train_tf)
prediction = model.predict(test_tf)

prediction
prediction_pd = pd.DataFrame({
    "id": test_pd["id"],
    "EC1": prediction["EC1"].flatten(),
    "EC2": prediction["EC2"].flatten(),
})

prediction_pd.to_csv("submission.csv",index=False)

prediction_pd