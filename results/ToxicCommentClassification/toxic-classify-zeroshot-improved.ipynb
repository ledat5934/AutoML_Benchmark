{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":19018,"databundleVersionId":2703900,"sourceType":"competition"}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:07:11.855517Z","iopub.execute_input":"2025-07-01T13:07:11.855790Z","iopub.status.idle":"2025-07-01T13:07:13.794442Z","shell.execute_reply.started":"2025-07-01T13:07:11.855765Z","shell.execute_reply":"2025-07-01T13:07:13.793682Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test_labels.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation-processed-seqlen128.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test-processed-seqlen128.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train-processed-seqlen128.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\n/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train-processed-seqlen128.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -*- coding: utf-8 -*-\n\"\"\"\nEnd-to-end script for Jigsaw Multilingual Toxic Comment Classification.\n\nThis script trains a multilingual model (XLM-RoBERTa) on English-only data\nand evaluates its ability to classify toxic comments in other languages.\n\nStrategy:\n1.  Combine the two provided English training datasets.\n2.  Use the KerasNLP library to build a classifier with a pre-trained\n    multilingual backbone (XLM-RoBERTa).\n3.  Train the model on all available English data.\n4.  Use the provided non-English `validation.csv` to monitor the primary\n    metric (AUC) during training and save the best performing model.\n5.  Evaluate the best model's performance on the validation set using a\n    range of metrics.\n6.  Predict on the unseen test set and generate a submission file.\n\"\"\"\n\nimport os\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport keras_nlp\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score, accuracy_score, log_loss, f1_score\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Suppress verbose logs\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\ntf.get_logger().setLevel('ERROR')\n\nprint(\"--- Library Versions ---\")\nprint(f\"TensorFlow: {tf.__version__}\")\nprint(f\"Keras: {tf.keras.__version__}\")\nprint(f\"KerasNLP: {keras_nlp.__version__}\")\nprint(f\"Pandas: {pd.__version__}\")\nprint(f\"NumPy: {np.__version__}\")\nprint(\"-\" * 25)\n\n# --- 1. Configuration ---\nclass Config:\n    \"\"\"Configuration class for hyperparameters and file paths.\"\"\"\n    # Data Paths\n    BASE_PATH = '/kaggle/input/jigsaw-multilingual-toxic-comment-classification'\n    TRAIN_TOXIC_PATH = os.path.join(BASE_PATH, 'jigsaw-toxic-comment-train.csv')\n    TRAIN_BIAS_PATH = os.path.join(BASE_PATH, 'jigsaw-unintended-bias-train.csv')\n    VALIDATION_PATH = os.path.join(BASE_PATH, 'validation.csv')\n    TEST_PATH = os.path.join(BASE_PATH, 'test.csv')\n\n    # Model Configuration\n    PRESET = \"xlm_roberta_base_multi\" # State-of-the-art for multilingual tasks\n    SEQUENCE_LENGTH = 192 # Max sequence length for the model\n    BATCH_SIZE = 32 # Adjust based on GPU memory (T4x2 can handle 32)\n    EPOCHS = 3 # Transformers fine-tune quickly, more epochs risk overfitting\n    LEARNING_RATE = 1e-5\n\n    # Target column\n    TARGET_COL = 'toxic'\n    \ncfg = Config()\n\n\n# --- 2. Data Loading and Preprocessing ---\nprint(\"\\n--- 2. Loading and Preparing Data ---\")\n\n# Load primary training data\nprint(\"Loading jigsaw-toxic-comment-train.csv...\")\ndf_toxic = pd.read_csv(cfg.TRAIN_TOXIC_PATH, usecols=['comment_text', 'toxic'])\n\n# Load and process unintended bias data\n# The 'toxic' column is a float score from 0.0 to 1.0. We binarize it.\nprint(\"Loading jigsaw-unintended-bias-train.csv...\")\ndf_bias = pd.read_csv(cfg.TRAIN_BIAS_PATH, usecols=['comment_text', 'toxic'])\ndf_bias['toxic'] = (df_bias['toxic'] >= 0.5).astype(int)\n\n# Combine the two English training datasets\ntrain_df = pd.concat([df_toxic, df_bias], ignore_index=True).drop_duplicates()\nprint(f\"Combined English training data shape: {train_df.shape}\")\nprint(\"Class distribution in combined training data:\")\nprint(train_df[cfg.TARGET_COL].value_counts(normalize=True))\n\n# Load validation and test data\nprint(\"\\nLoading validation and test data...\")\nval_df = pd.read_csv(cfg.VALIDATION_PATH)\ntest_df = pd.read_csv(cfg.TEST_PATH)\n\nprint(f\"Validation data shape: {val_df.shape}\")\nprint(f\"Test data shape: {test_df.shape}\")\n\n# Prepare data for the model\nX_train = train_df['comment_text']\ny_train = train_df[cfg.TARGET_COL]\n\nX_val = val_df['comment_text']\ny_val = val_df[cfg.TARGET_COL]\n\nX_test = test_df['content'] # Note the different column name in test.csv\n\n# --- 3. Model Building with KerasNLP ---\nprint(\"\\n--- 3. Building the KerasNLP Model ---\")\n\n# Set up the preprocessor and classifier from the same multilingual preset\n# The preprocessor handles tokenization, padding, etc., automatically.\npreprocessor = keras_nlp.models.XlmRobertaPreprocessor.from_preset(\n    cfg.PRESET,\n    sequence_length=cfg.SEQUENCE_LENGTH\n)\n\n# The classifier includes the pre-trained backbone and a new classification head\nclassifier = keras_nlp.models.XlmRobertaClassifier.from_preset(\n    cfg.PRESET,\n    preprocessor=preprocessor,\n    num_classes=1, # Binary classification -> 1 output neuron with sigmoid\n)\n\n# You can print the summary to see the architecture\n# Note: The output layer is a single neuron with a linear activation.\n# We will use `from_logits=True` in our loss function.\n# classifier.summary()\n\n# --- 4. Model Training ---\nprint(\"\\n--- 4. Training the Model ---\")\n\n# Compile the model\n# We use AdamW optimizer, a standard choice for Transformers.\n# BinaryCrossentropy with from_logits=True is the correct loss for this setup.\n# AUC is our primary evaluation metric.\nclassifier.compile(\n    optimizer=tf.keras.optimizers.AdamW(learning_rate=cfg.LEARNING_RATE),\n    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[\n        tf.keras.metrics.BinaryAccuracy(name=\"accuracy\"),\n        tf.keras.metrics.AUC(name=\"auc\"),\n    ],\n    jit_compile=True # Enable XLA compilation for performance boost on GPUs\n)\n\n# Callbacks for training\n# ModelCheckpoint saves the best model based on the validation AUC.\n# This is crucial as we want the model that generalizes best to other languages.\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    'best_model.keras',\n    monitor='val_auc',\n    mode='max',\n    save_best_only=True,\n    save_weights_only=False, # Save the full model\n    verbose=1\n)\n\n# EarlyStopping prevents wasting resources and overfitting.\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_auc',\n    patience=1, # Stop if val_auc doesn't improve for 1 epoch\n    mode='max',\n    restore_best_weights=True,\n    verbose=1\n)\n\n# Train the model\n# We use the full English dataset for training and the non-English validation\n# set for the `validation_data` argument. This directly optimizes for the\n# competition's cross-lingual objective.\nprint(\"\\nStarting training...\")\nprint(f\"Training on {len(X_train)} English comments.\")\nprint(f\"Validating on {len(X_val)} non-English comments.\")\n\nhistory = classifier.fit(\n    x=X_train,\n    y=y_train,\n    batch_size=cfg.BATCH_SIZE,\n    epochs=cfg.EPOCHS,\n    validation_data=(X_val, y_val),\n    callbacks=[model_checkpoint, early_stopping]\n)\n\nprint(\"Training finished.\")\n\n# --- 5. Model Evaluation ---\nprint(\"\\n--- 5. Evaluating the Best Model ---\")\n\n# Load the best model saved by ModelCheckpoint\nprint(\"Loading the best model from training...\")\nbest_model = tf.keras.models.load_model('best_model.keras')\n\n# Generate predictions on the non-English validation set\nprint(\"Generating predictions on the validation set...\")\nval_predictions_logits = best_model.predict(X_val, batch_size=cfg.BATCH_SIZE)\n# Apply sigmoid to convert logits to probabilities\nval_predictions_probs = tf.nn.sigmoid(val_predictions_logits).numpy().flatten()\nval_predictions_binary = (val_predictions_probs >= 0.5).astype(int)\n\n# Define an evaluation function for the requested metrics\ndef evaluate_classification(y_true, y_pred_prob, y_pred_binary):\n    \"\"\"Calculates and prints a suite of classification metrics.\"\"\"\n    print(\"\\n--- Detailed Evaluation Metrics ---\")\n    \n    # AUC (the main competition metric)\n    auc = roc_auc_score(y_true, y_pred_prob)\n    print(f\"ROC AUC Score: {auc:.5f}\")\n    \n    # Accuracy\n    accuracy = accuracy_score(y_true, y_pred_binary)\n    print(f\"Accuracy: {accuracy:.5f}\")\n    \n    # Log Loss\n    logloss = log_loss(y_true, y_pred_prob)\n    print(f\"Log Loss: {logloss:.5f}\")\n    \n    # F1-Score (Macro and Weighted)\n    f1_macro = f1_score(y_true, y_pred_binary, average='macro')\n    f1_weighted = f1_score(y_true, y_pred_binary, average='weighted')\n    print(f\"F1-Score (Macro): {f1_macro:.5f}\")\n    print(f\"F1-Score (Weighted): {f1_weighted:.5f}\")\n    \n    # Note: roc_auc_ovr is for multi-class problems. For binary, it's equivalent\n    # to the standard roc_auc_score, so we report that one.\n    \n    print(\"-\" * 33)\n    return auc\n\n# Run the evaluation\nval_auc = evaluate_classification(y_val, val_predictions_probs, val_predictions_binary)\n\n# Plot training history\ndef plot_history(history):\n    plt.figure(figsize=(12, 5))\n\n    # Plot AUC\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history['auc'], label='Training AUC')\n    plt.plot(history.history['val_auc'], label='Validation AUC')\n    plt.title('AUC Over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('AUC')\n    plt.legend()\n    plt.grid(True)\n\n    # Plot Loss\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history['loss'], label='Training Loss')\n    plt.plot(history.history['val_loss'], label='Validation Loss')\n    plt.title('Loss Over Epochs')\n    plt.xlabel('Epoch')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    plt.tight_layout()\n    plt.savefig('training_history.png')\n    plt.show()\n\nprint(\"\\nPlotting training history...\")\nplot_history(history)\n\n\n# --- 6. Prediction and Submission ---\nprint(\"\\n--- 6. Generating Submission File ---\")\n\nprint(\"Predicting on the test set...\")\ntest_predictions_logits = best_model.predict(X_test, batch_size=cfg.BATCH_SIZE)\ntest_predictions_probs = tf.nn.sigmoid(test_predictions_logits).numpy().flatten()\n\nprint(\"Creating submission dataframe...\")\nsubmission_df = pd.DataFrame({\n    'id': test_df['id'],\n    'toxic': test_predictions_probs\n})\n\n# Save the submission file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"\\nSubmission file 'submission.csv' created successfully!\")\nprint(\"Final Validation AUC:\", val_auc)\nprint(\"Script finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-01T13:07:47.190008Z","iopub.execute_input":"2025-07-01T13:07:47.190695Z","iopub.status.idle":"2025-07-01T13:08:29.770869Z","shell.execute_reply.started":"2025-07-01T13:07:47.190669Z","shell.execute_reply":"2025-07-01T13:08:29.769888Z"}},"outputs":[{"name":"stderr","text":"2025-07-01 13:07:49.003484: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1751375269.239950      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1751375269.309168      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"--- Library Versions ---\nTensorFlow: 2.18.0\nKeras: 3.8.0\nKerasNLP: 0.18.1\nPandas: 2.2.3\nNumPy: 1.26.4\n-------------------------\n\n--- 2. Loading and Preparing Data ---\nLoading jigsaw-toxic-comment-train.csv...\nLoading jigsaw-unintended-bias-train.csv...\nCombined English training data shape: (2100579, 2)\nClass distribution in combined training data:\ntoxic\n0    0.918207\n1    0.081793\nName: proportion, dtype: float64\n\nLoading validation and test data...\nValidation data shape: (8000, 4)\nTest data shape: (63812, 3)\n\n--- 3. Building the KerasNLP Model ---\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3893567822.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;31m# Set up the preprocessor and classifier from the same multilingual preset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;31m# The preprocessor handles tokenization, padding, etc., automatically.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m preprocessor = keras_nlp.models.XlmRobertaPreprocessor.from_preset(\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRESET\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSEQUENCE_LENGTH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'keras_hub.api.models' has no attribute 'XlmRobertaPreprocessor'"],"ename":"AttributeError","evalue":"module 'keras_hub.api.models' has no attribute 'XlmRobertaPreprocessor'","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}